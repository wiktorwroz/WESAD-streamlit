{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Klasyfikacja Emocji z SMOTE - WESAD Dataset\n",
        "\n",
        "## Plan analizy\n",
        "\n",
        "Ten notebook wykonuje kompletnƒÖ analizƒô klasyfikacji emocji z danych WESAD zgodnie z nastƒôpujƒÖcym planem:\n",
        "\n",
        "1. **Import bibliotek** - numpy, pandas, matplotlib, seaborn, scikit-learn, imblearn\n",
        "2. **Wczytanie danych** - CSV/PKL z WESAD, sprawdzenie rozk≈Çadu klas\n",
        "3. **Segmentacja danych** - sliding windows z ekstrakcjƒÖ cech (mean, std, min, max, range, RMS, kurtosis, skewness, RMSSD, slope, respiration rate)\n",
        "4. **Encoding i skalowanie** - LabelEncoder dla targetu, StandardScaler dla cech\n",
        "5. **Podzia≈Ç Train/Test** - **Subject-wise split** (ca≈Çe osoby do train/test, nie dzielimy okien)\n",
        "6. **Balansowanie** - SMOTE na train, weryfikacja balansu\n",
        "7. **Trenowanie modeli** - Logistic Regression, Random Forest, SVM, XGBoost\n",
        "8. **Ewaluacja** - confusion matrix, accuracy, balanced accuracy, macro F1, per-class metrics\n",
        "9. **Por√≥wnanie z baseline** - DummyClassifier\n",
        "10. **Wnioski i raport** - wyb√≥r najlepszego modelu, analiza wynik√≥w\n",
        "11. **Wizualizacje** - wykresy rozk≈Çadu klas, metryk, confusion matrices\n",
        "\n",
        "## ‚ö†Ô∏è WA≈ªNE: Subject-wise Split\n",
        "\n",
        "- **Ca≈Çe dane jednej osoby** trafiajƒÖ albo do train, albo do test\n",
        "- **Nigdy nie dzielimy** okien z tej samej osoby miƒôdzy train i test\n",
        "- To zapewnia **realistycznƒÖ generalizacjƒô** na nowych osobach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 1: IMPORT BIBLIOTEK\n",
        "# ============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    balanced_accuracy_score, f1_score, precision_score, recall_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# XGBoost (opcjonalnie)\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è XGBoost niedostƒôpny - pomijam w analizie\")\n",
        "\n",
        "# Imbalanced-learn (SMOTE)\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    IMBLEARN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    IMBLEARN_AVAILABLE = False\n",
        "    print(\"‚ùå imbalanced-learn niedostƒôpny - zainstaluj: pip install imbalanced-learn\")\n",
        "\n",
        "# Scipy dla sygna≈Ç√≥w\n",
        "from scipy.signal import resample\n",
        "from scipy import stats\n",
        "\n",
        "# TensorFlow/Keras dla modeli time series (LSTM)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(\"‚úÖ TensorFlow/Keras dostƒôpny - modele time series bƒôdƒÖ dostƒôpne\")\n",
        "except ImportError:\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è TensorFlow/Keras niedostƒôpny - modele time series nie bƒôdƒÖ dostƒôpne\")\n",
        "    print(\"   Zainstaluj: pip install tensorflow\")\n",
        "\n",
        "print(\"‚úÖ Wszystkie biblioteki zaimportowane pomy≈õlnie!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 2: WCZYTYWANIE DANYCH\n",
        "\n",
        "Wczytujemy dane WESAD z plik√≥w CSV i PKL. Sprawdzamy rozk≈Çad klas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 2: WCZYTYWANIE DANYCH\n",
            "================================================================================\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S2...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Fazy: {'unknown': 75098, 'Base': 616, 'TSST': 344, 'Medi 1': 221, 'Medi 2': 216, 'Fun': 200, 'sRead': 53, 'fRead': 52}\n",
            "    Klasy: {'unknown': 75098, 'baseline': 1053, 'stress': 449, 'amusement': 200}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S3...\n",
            "    Fazy: {'unknown': 75040, 'Base': 627, 'TSST': 352, 'Medi 1': 225, 'Medi 2': 217, 'Fun': 203, 'bRead': 55, 'fRead': 41, 'sRead': 40}\n",
            "    Klasy: {'unknown': 75095, 'baseline': 1069, 'stress': 433, 'amusement': 203}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S4...\n",
            "    Fazy: {'unknown': 75009, 'Base': 633, 'TSST': 350, 'Medi 1': 239, 'Medi 2': 223, 'Fun': 215, 'fRead': 49, 'bRead': 48, 'sRead': 34}\n",
            "    Klasy: {'unknown': 75057, 'baseline': 1095, 'stress': 433, 'amusement': 215}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S5...\n",
            "    Fazy: {'unknown': 75032, 'Base': 646, 'TSST': 354, 'Medi 1': 223, 'Medi 2': 223, 'Fun': 203, 'bRead': 43, 'fRead': 42, 'sRead': 34}\n",
            "    Klasy: {'unknown': 75075, 'baseline': 1092, 'stress': 430, 'amusement': 203}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S6...\n",
            "    Fazy: {'unknown': 75045, 'Base': 640, 'TSST': 355, 'Medi 1': 223, 'Medi 2': 208, 'Fun': 202, 'fRead': 54, 'bRead': 37, 'sRead': 36}\n",
            "    Klasy: {'unknown': 75082, 'baseline': 1071, 'stress': 445, 'amusement': 202}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "üìÇ Wczytujƒô dane dla S7...\n",
            "    Fazy: {'unknown': 75055, 'Base': 642, 'TSST': 352, 'Medi 1': 223, 'Medi 2': 221, 'Fun': 202, 'fRead': 36, 'bRead': 35, 'sRead': 34}\n",
            "    Klasy: {'unknown': 75090, 'baseline': 1086, 'stress': 422, 'amusement': 202}\n",
            "  ‚úÖ Wczytano 76800 pr√≥bek\n",
            "\n",
            "================================================================================\n",
            "PODSUMOWANIE WCZYTYWANIA DANYCH\n",
            "================================================================================\n",
            "‚úÖ Wczytano dane dla 6 subject√≥w\n",
            "   ≈ÅƒÖczna liczba pr√≥bek: 460800\n",
            "\n",
            "üìä SZCZEG√ì≈ÅOWY ROZK≈ÅAD KLAS PER SUBJECT:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  S2:\n",
            "    unknown     :  75098 pr√≥bek ( 97.78%)\n",
            "    baseline    :   1053 pr√≥bek (  1.37%)\n",
            "    stress      :    449 pr√≥bek (  0.58%)\n",
            "    amusement   :    200 pr√≥bek (  0.26%)\n",
            "\n",
            "  S3:\n",
            "    unknown     :  75095 pr√≥bek ( 97.78%)\n",
            "    baseline    :   1069 pr√≥bek (  1.39%)\n",
            "    stress      :    433 pr√≥bek (  0.56%)\n",
            "    amusement   :    203 pr√≥bek (  0.26%)\n",
            "\n",
            "  S4:\n",
            "    unknown     :  75057 pr√≥bek ( 97.73%)\n",
            "    baseline    :   1095 pr√≥bek (  1.43%)\n",
            "    stress      :    433 pr√≥bek (  0.56%)\n",
            "    amusement   :    215 pr√≥bek (  0.28%)\n",
            "\n",
            "  S5:\n",
            "    unknown     :  75075 pr√≥bek ( 97.75%)\n",
            "    baseline    :   1092 pr√≥bek (  1.42%)\n",
            "    stress      :    430 pr√≥bek (  0.56%)\n",
            "    amusement   :    203 pr√≥bek (  0.26%)\n",
            "\n",
            "  S6:\n",
            "    unknown     :  75082 pr√≥bek ( 97.76%)\n",
            "    baseline    :   1071 pr√≥bek (  1.39%)\n",
            "    stress      :    445 pr√≥bek (  0.58%)\n",
            "    amusement   :    202 pr√≥bek (  0.26%)\n",
            "\n",
            "  S7:\n",
            "    unknown     :  75090 pr√≥bek ( 97.77%)\n",
            "    baseline    :   1086 pr√≥bek (  1.41%)\n",
            "    stress      :    422 pr√≥bek (  0.55%)\n",
            "    amusement   :    202 pr√≥bek (  0.26%)\n",
            "\n",
            "üìä ROZK≈ÅAD FAZ PER SUBJECT:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  S2:\n",
            "    unknown        :  75098 pr√≥bek ( 97.78%)\n",
            "    Base           :    616 pr√≥bek (  0.80%)\n",
            "    TSST           :    344 pr√≥bek (  0.45%)\n",
            "    Medi 1         :    221 pr√≥bek (  0.29%)\n",
            "    Medi 2         :    216 pr√≥bek (  0.28%)\n",
            "    Fun            :    200 pr√≥bek (  0.26%)\n",
            "    sRead          :     53 pr√≥bek (  0.07%)\n",
            "    fRead          :     52 pr√≥bek (  0.07%)\n",
            "\n",
            "  S3:\n",
            "    unknown        :  75040 pr√≥bek ( 97.71%)\n",
            "    Base           :    627 pr√≥bek (  0.82%)\n",
            "    TSST           :    352 pr√≥bek (  0.46%)\n",
            "    Medi 1         :    225 pr√≥bek (  0.29%)\n",
            "    Medi 2         :    217 pr√≥bek (  0.28%)\n",
            "    Fun            :    203 pr√≥bek (  0.26%)\n",
            "    bRead          :     55 pr√≥bek (  0.07%)\n",
            "    fRead          :     41 pr√≥bek (  0.05%)\n",
            "    sRead          :     40 pr√≥bek (  0.05%)\n",
            "\n",
            "  S4:\n",
            "    unknown        :  75009 pr√≥bek ( 97.67%)\n",
            "    Base           :    633 pr√≥bek (  0.82%)\n",
            "    TSST           :    350 pr√≥bek (  0.46%)\n",
            "    Medi 1         :    239 pr√≥bek (  0.31%)\n",
            "    Medi 2         :    223 pr√≥bek (  0.29%)\n",
            "    Fun            :    215 pr√≥bek (  0.28%)\n",
            "    fRead          :     49 pr√≥bek (  0.06%)\n",
            "    bRead          :     48 pr√≥bek (  0.06%)\n",
            "    sRead          :     34 pr√≥bek (  0.04%)\n",
            "\n",
            "  S5:\n",
            "    unknown        :  75032 pr√≥bek ( 97.70%)\n",
            "    Base           :    646 pr√≥bek (  0.84%)\n",
            "    TSST           :    354 pr√≥bek (  0.46%)\n",
            "    Medi 1         :    223 pr√≥bek (  0.29%)\n",
            "    Medi 2         :    223 pr√≥bek (  0.29%)\n",
            "    Fun            :    203 pr√≥bek (  0.26%)\n",
            "    bRead          :     43 pr√≥bek (  0.06%)\n",
            "    fRead          :     42 pr√≥bek (  0.05%)\n",
            "    sRead          :     34 pr√≥bek (  0.04%)\n",
            "\n",
            "  S6:\n",
            "    unknown        :  75045 pr√≥bek ( 97.71%)\n",
            "    Base           :    640 pr√≥bek (  0.83%)\n",
            "    TSST           :    355 pr√≥bek (  0.46%)\n",
            "    Medi 1         :    223 pr√≥bek (  0.29%)\n",
            "    Medi 2         :    208 pr√≥bek (  0.27%)\n",
            "    Fun            :    202 pr√≥bek (  0.26%)\n",
            "    fRead          :     54 pr√≥bek (  0.07%)\n",
            "    bRead          :     37 pr√≥bek (  0.05%)\n",
            "    sRead          :     36 pr√≥bek (  0.05%)\n",
            "\n",
            "  S7:\n",
            "    unknown        :  75055 pr√≥bek ( 97.73%)\n",
            "    Base           :    642 pr√≥bek (  0.84%)\n",
            "    TSST           :    352 pr√≥bek (  0.46%)\n",
            "    Medi 1         :    223 pr√≥bek (  0.29%)\n",
            "    Medi 2         :    221 pr√≥bek (  0.29%)\n",
            "    Fun            :    202 pr√≥bek (  0.26%)\n",
            "    fRead          :     36 pr√≥bek (  0.05%)\n",
            "    bRead          :     35 pr√≥bek (  0.05%)\n",
            "    sRead          :     34 pr√≥bek (  0.04%)\n",
            "\n",
            "üìä GLOBALNY ROZK≈ÅAD KLAS (wszystkie subjecty):\n",
            "--------------------------------------------------------------------------------\n",
            "   unknown     : 450497 pr√≥bek ( 97.76%)\n",
            "   baseline    :   6466 pr√≥bek (  1.40%)\n",
            "   stress      :   2612 pr√≥bek (  0.57%)\n",
            "   amusement   :   1225 pr√≥bek (  0.27%)\n",
            "\n",
            "üìä GLOBALNY ROZK≈ÅAD FAZ (wszystkie subjecty):\n",
            "--------------------------------------------------------------------------------\n",
            "   unknown        : 450279 pr√≥bek ( 97.72%)\n",
            "   Base           :   3804 pr√≥bek (  0.83%)\n",
            "   TSST           :   2107 pr√≥bek (  0.46%)\n",
            "   Medi 1         :   1354 pr√≥bek (  0.29%)\n",
            "   Medi 2         :   1308 pr√≥bek (  0.28%)\n",
            "   Fun            :   1225 pr√≥bek (  0.27%)\n",
            "   fRead          :    274 pr√≥bek (  0.06%)\n",
            "   sRead          :    231 pr√≥bek (  0.05%)\n",
            "   bRead          :    218 pr√≥bek (  0.05%)\n",
            "\n",
            "üìä KOLUMNY W DANYCH:\n",
            "--------------------------------------------------------------------------------\n",
            "   Kolumny sygna≈Ç√≥w: ['acc_x', 'acc_y', 'acc_z', 'eda', 'temp', 'bvp']\n",
            "   Liczba kolumn sygna≈Ç√≥w: 6\n",
            "\n",
            "üìä KILKA PIERWSZYCH WIERSZY:\n",
            "--------------------------------------------------------------------------------\n",
            "                         timestamp      acc_x     acc_y      acc_z       eda  \\\n",
            "0        2017-05-22 07:15:25+00:00  36.105569 -1.364183  35.009419  0.044153   \n",
            "1 2017-05-22 07:15:25.031250+00:00  26.316537 -7.202927  60.482867 -0.019435   \n",
            "2 2017-05-22 07:15:25.062500+00:00  29.005282 -5.356751  51.961562  0.018904   \n",
            "3 2017-05-22 07:15:25.093750+00:00  27.298289 -6.443141  57.051682 -0.027230   \n",
            "4 2017-05-22 07:15:25.125000+00:00  28.541884 -5.626367  54.142321  0.085999   \n",
            "5 2017-05-22 07:15:25.156250+00:00  27.551146 -7.019067  57.345194  0.346878   \n",
            "6 2017-05-22 07:15:25.187500+00:00  28.396960 -6.161212  54.945361  0.318954   \n",
            "7 2017-05-22 07:15:25.218750+00:00  27.611405 -6.020648  56.162192  0.333228   \n",
            "8 2017-05-22 07:15:25.250000+00:00  29.062081 -5.958930  54.863570  0.324991   \n",
            "9 2017-05-22 07:15:25.281250+00:00  28.105329 -6.042779  56.119721  0.329423   \n",
            "\n",
            "         temp        bvp    phase    label subject  \n",
            "0  294.632817 -12.314163  unknown  unknown      S2  \n",
            "1  406.853331   3.445876  unknown  unknown      S2  \n",
            "2  368.033795  -1.926511  unknown  unknown      S2  \n",
            "3  392.239604   1.326628  unknown  unknown      S2  \n",
            "4  374.243482  -1.009724  unknown  unknown      S2  \n",
            "5  388.836579   0.816193  unknown  unknown      S2  \n",
            "6  376.365636  -0.671574  unknown  unknown      S2  \n",
            "7  387.409255   0.559902  unknown  unknown      S2  \n",
            "8  377.370749  -0.566550  unknown  unknown      S2  \n",
            "9  386.682986   0.591522  unknown  unknown      S2  \n",
            "\n",
            "üìä STATYSTYKI CZASOWE:\n",
            "--------------------------------------------------------------------------------\n",
            "   Najwcze≈õniejszy timestamp: 2017-05-22 07:15:25+00:00\n",
            "   Najp√≥≈∫niejszy timestamp: 2017-07-06 11:51:03.968750+00:00\n",
            "   Czas trwania: 65075.65 minut\n",
            "\n",
            "‚úÖ WCZYTYWANIE DANYCH ZAKO≈ÉCZONE POMY≈öLNIE!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 2: WCZYTYWANIE DANYCH\n",
        "# ============================================================================\n",
        "\n",
        "# ≈öcie≈ºki\n",
        "RAW_ROOT = Path(\"/Users/turfian/Downloads/archive (4)/WESAD\")\n",
        "PROJECT_ROOT = Path(\"/Users/turfian/Downloads/archive (4)/WESAD/wesad-prep\")\n",
        "\n",
        "# Parametry\n",
        "TARGET_FS = 32.0\n",
        "MAX_DURATION = pd.Timedelta(minutes=40)\n",
        "DEFAULT_SUBJECTS = [\"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\"]\n",
        "\n",
        "# Mapowanie faz do klas (zgodnie z rzeczywistymi nazwami faz w WESAD)\n",
        "PHASE_TO_CLASS = {\n",
        "    \"Base\": \"baseline\",\n",
        "    \"Medi 1\": \"baseline\",\n",
        "    \"Medi 2\": \"baseline\",\n",
        "    \"TSST\": \"stress\",\n",
        "    \"sRead\": \"stress\",\n",
        "    \"fRead\": \"stress\",\n",
        "    \"Fun\": \"amusement\",\n",
        "    # Alternatywne nazwy (na wypadek r√≥≈ºnic w plikach)\n",
        "    \"Stress\": \"stress\",\n",
        "    \"Amusement\": \"amusement\",\n",
        "    \"Meditation\": \"baseline\",\n",
        "}\n",
        "\n",
        "# Funkcje pomocnicze do parsowania\n",
        "def build_time_index(length: int, start_ts: float, fs: float) -> pd.Series:\n",
        "    \"\"\"Buduje indeks czasowy dla sygna≈Çu\"\"\"\n",
        "    start = pd.to_datetime(start_ts, unit=\"s\", utc=True)\n",
        "    offsets = pd.to_timedelta(np.arange(length) / fs, unit=\"s\")\n",
        "    return start + offsets\n",
        "\n",
        "def load_sensor_for_subject(subject_path: Path, sensor_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Wczytuje dane z sensora (CSV)\"\"\"\n",
        "    file_path = subject_path / f\"{sensor_name}.csv\"\n",
        "    if not file_path.exists():\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    header = pd.read_csv(file_path, nrows=2, header=None)\n",
        "    start_ts = float(header.iloc[0, 0])\n",
        "    fs = float(header.iloc[1, 0])\n",
        "    \n",
        "    column_names = {\n",
        "        \"ACC\": [\"acc_x\", \"acc_y\", \"acc_z\"],\n",
        "        \"EDA\": [\"eda\"],\n",
        "        \"BVP\": [\"bvp\"],\n",
        "        \"TEMP\": [\"temp\"],\n",
        "        \"HR\": [\"hr\"],\n",
        "    }.get(sensor_name, [sensor_name.lower()])\n",
        "    \n",
        "    data = pd.read_csv(file_path, skiprows=2, header=None, names=column_names)\n",
        "    data.insert(0, \"timestamp\", build_time_index(len(data), start_ts, fs))\n",
        "    data.attrs.update({\"start_ts\": start_ts, \"fs\": fs})\n",
        "    return data\n",
        "\n",
        "def load_wesad_pickle(subject: str, raw_root: Path = RAW_ROOT) -> dict:\n",
        "    \"\"\"Wczytuje dane z pliku PKL\"\"\"\n",
        "    pkl_path = raw_root / subject / f\"{subject}.pkl\"\n",
        "    if not pkl_path.exists():\n",
        "        raise FileNotFoundError(f\"Brak pliku {pkl_path}\")\n",
        "    with pkl_path.open(\"rb\") as handle:\n",
        "        return pickle.load(handle, encoding=\"latin1\")\n",
        "\n",
        "def load_tags_for_subject(subject_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Wczytuje tagi (etykiety) dla subjecta\"\"\"\n",
        "    path = subject_path / \"tags.csv\"\n",
        "    if not path.exists() or path.stat().st_size == 0:\n",
        "        return pd.DataFrame(columns=[\"timestamp\", \"tag\"])\n",
        "    tags = pd.read_csv(path, header=None, names=[\"timestamp\"])\n",
        "    tags[\"timestamp\"] = pd.to_datetime(tags[\"timestamp\"], unit=\"s\", utc=True)\n",
        "    tags[\"tag\"] = 1\n",
        "    return tags\n",
        "\n",
        "def build_phase_protocol_for_subject(subject: str, session_start: pd.Timestamp, raw_root: Path = RAW_ROOT) -> pd.DataFrame:\n",
        "    \"\"\"Buduje protok√≥≈Ç faz dla subjecta z pliku *_quest.csv\"\"\"\n",
        "    quest_path = raw_root / subject / f\"{subject}_quest.csv\"\n",
        "    if not quest_path.exists():\n",
        "        return pd.DataFrame(columns=[\"phase\", \"start\", \"end\", \"duration_s\"])\n",
        "    \n",
        "    lines = [line.strip() for line in quest_path.read_text().splitlines() if line.strip()]\n",
        "    \n",
        "    def _extract_values(lines, prefix):\n",
        "        for line in lines:\n",
        "            if line.startswith(prefix):\n",
        "                return [token for token in line.split(\";\")[1:] if token]\n",
        "        return []\n",
        "    \n",
        "    names = _extract_values(lines, \"# ORDER\")\n",
        "    starts = _extract_values(lines, \"# START\")\n",
        "    ends = _extract_values(lines, \"# END\")\n",
        "    \n",
        "    phases = []\n",
        "    limit = min(len(names), len(starts), len(ends))\n",
        "    for idx in range(limit):\n",
        "        try:\n",
        "            start_sec = float(starts[idx])\n",
        "            end_sec = float(ends[idx])\n",
        "            phase_name = names[idx].strip()\n",
        "            phases.append({\n",
        "                \"phase\": phase_name,\n",
        "                \"start\": session_start + pd.to_timedelta(start_sec, unit=\"s\"),\n",
        "                \"end\": session_start + pd.to_timedelta(end_sec, unit=\"s\"),\n",
        "                \"duration_s\": end_sec - start_sec\n",
        "            })\n",
        "        except (ValueError, IndexError):\n",
        "            continue\n",
        "    \n",
        "    return pd.DataFrame(phases)\n",
        "\n",
        "def assign_phase_labels(timestamps: pd.Series, phases: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"Przypisuje etykiety faz do timestamp√≥w\"\"\"\n",
        "    if phases.empty:\n",
        "        return pd.Series([\"unknown\"] * len(timestamps), index=timestamps.index)\n",
        "    intervals = pd.IntervalIndex.from_arrays(phases[\"start\"], phases[\"end\"], closed=\"left\")\n",
        "    labels = phases[\"phase\"].to_list()\n",
        "    idx = intervals.get_indexer(timestamps)\n",
        "    label_array = np.array(labels, dtype=object)\n",
        "    mapped = np.where(idx >= 0, label_array[idx], \"unknown\")\n",
        "    return pd.Series(mapped, index=timestamps.index)\n",
        "\n",
        "def resample_signal(array, src_fs: float, target_fs: float, target_len: int) -> np.ndarray:\n",
        "    \"\"\"Resampluje sygna≈Ç do docelowej czƒôstotliwo≈õci\"\"\"\n",
        "    if array.ndim == 1:\n",
        "        array = array[:, None]\n",
        "    expected_len = int(src_fs * MAX_DURATION.total_seconds())\n",
        "    trimmed = array[:expected_len]\n",
        "    if len(trimmed) == 0:\n",
        "        return np.full((target_len, array.shape[1]), np.nan)\n",
        "    return resample(trimmed, target_len, axis=0)\n",
        "\n",
        "# Wczytanie danych dla wszystkich subject√≥w\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 2: WCZYTYWANIE DANYCH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "all_subjects_data = []\n",
        "\n",
        "for subject in DEFAULT_SUBJECTS:\n",
        "    print(f\"\\nüìÇ Wczytujƒô dane dla {subject}...\")\n",
        "    subject_path = RAW_ROOT / subject / f\"{subject}_E4_Data\"\n",
        "    \n",
        "    if not subject_path.exists():\n",
        "        print(f\"  ‚ö†Ô∏è Brak folderu {subject_path} - pomijam\")\n",
        "        continue\n",
        "    \n",
        "    # Wczytaj sygna≈Çy z nadgarstka (CSV)\n",
        "    wrist_data = {}\n",
        "    for sensor in [\"ACC\", \"EDA\", \"BVP\", \"TEMP\"]:\n",
        "        sensor_df = load_sensor_for_subject(subject_path, sensor)\n",
        "        if not sensor_df.empty:\n",
        "            wrist_data[sensor.lower()] = sensor_df\n",
        "    \n",
        "    # Sprawd≈∫ czy mamy dane\n",
        "    if not wrist_data:\n",
        "        print(f\"  ‚ö†Ô∏è Brak danych z nadgarstka - pomijam\")\n",
        "        continue\n",
        "    \n",
        "    # U≈ºyj timestamp z pierwszego sensora jako session_start\n",
        "    first_sensor = list(wrist_data.values())[0]\n",
        "    if len(first_sensor) == 0:\n",
        "        print(f\"  ‚ö†Ô∏è Pusty sensor - pomijam\")\n",
        "        continue\n",
        "    \n",
        "    session_start = first_sensor[\"timestamp\"].iloc[0]\n",
        "    \n",
        "    # Wczytaj protok√≥≈Ç faz\n",
        "    phases = build_phase_protocol_for_subject(subject, session_start)\n",
        "    \n",
        "    # Po≈ÇƒÖcz dane nadgarstka\n",
        "    if wrist_data:\n",
        "        # U≈ºyj BVP jako referencji czasowej\n",
        "        if \"bvp\" in wrist_data:\n",
        "            base_df = wrist_data[\"bvp\"][[\"timestamp\"]].copy()\n",
        "            for sensor_name, sensor_df in wrist_data.items():\n",
        "                if sensor_name != \"bvp\":\n",
        "                    # Resample do czƒôstotliwo≈õci BVP\n",
        "                    merged = pd.merge_asof(\n",
        "                        base_df.sort_values(\"timestamp\"),\n",
        "                        sensor_df[[\"timestamp\"] + [col for col in sensor_df.columns if col != \"timestamp\"]].sort_values(\"timestamp\"),\n",
        "                        on=\"timestamp\",\n",
        "                        direction=\"nearest\",\n",
        "                        tolerance=pd.Timedelta(seconds=1)\n",
        "                    )\n",
        "                    for col in sensor_df.columns:\n",
        "                        if col != \"timestamp\":\n",
        "                            base_df[col] = merged[col].values\n",
        "            \n",
        "            # Dodaj pozosta≈Çe kolumny z BVP\n",
        "            for col in wrist_data[\"bvp\"].columns:\n",
        "                if col != \"timestamp\" and col not in base_df.columns:\n",
        "                    base_df[col] = wrist_data[\"bvp\"][col].values\n",
        "            \n",
        "            # Resample do docelowej czƒôstotliwo≈õci\n",
        "            target_len = int(MAX_DURATION.total_seconds() * TARGET_FS)\n",
        "            timestamps = session_start + pd.to_timedelta(np.arange(target_len) / TARGET_FS, unit=\"s\")\n",
        "            \n",
        "            # Resample ka≈ºdej kolumny\n",
        "            resampled_data = {}\n",
        "            for col in base_df.columns:\n",
        "                if col != \"timestamp\":\n",
        "                    original_values = base_df[col].values\n",
        "                    if len(original_values) > 0:\n",
        "                        resampled = resample_signal(original_values, wrist_data[\"bvp\"].attrs[\"fs\"], TARGET_FS, target_len)\n",
        "                        resampled_data[col] = resampled.flatten() if resampled.ndim > 1 else resampled\n",
        "                    else:\n",
        "                        resampled_data[col] = np.full(target_len, np.nan)\n",
        "            \n",
        "            # Stw√≥rz DataFrame\n",
        "            subject_df = pd.DataFrame(resampled_data)\n",
        "            subject_df.insert(0, \"timestamp\", timestamps)\n",
        "            \n",
        "            # Dodaj etykiety faz\n",
        "            subject_df[\"phase\"] = assign_phase_labels(subject_df[\"timestamp\"], phases)\n",
        "            subject_df[\"label\"] = subject_df[\"phase\"].map(PHASE_TO_CLASS).fillna(\"unknown\")\n",
        "            subject_df[\"subject\"] = subject\n",
        "            \n",
        "            # Sprawd≈∫ rozk≈Çad faz i klas dla tego subjecta\n",
        "            phase_dist = subject_df[\"phase\"].value_counts()\n",
        "            label_dist = subject_df[\"label\"].value_counts()\n",
        "            print(f\"    Fazy: {dict(phase_dist)}\")\n",
        "            print(f\"    Klasy: {dict(label_dist)}\")\n",
        "            \n",
        "            all_subjects_data.append(subject_df)\n",
        "            print(f\"  ‚úÖ Wczytano {len(subject_df)} pr√≥bek\")\n",
        "\n",
        "# Po≈ÇƒÖcz wszystkie dane\n",
        "if all_subjects_data:\n",
        "    full_data = pd.concat(all_subjects_data, ignore_index=True)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"PODSUMOWANIE WCZYTYWANIA DANYCH\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"‚úÖ Wczytano dane dla {len(all_subjects_data)} subject√≥w\")\n",
        "    print(f\"   ≈ÅƒÖczna liczba pr√≥bek: {len(full_data)}\")\n",
        "    \n",
        "    print(f\"\\nüìä SZCZEG√ì≈ÅOWY ROZK≈ÅAD KLAS PER SUBJECT:\")\n",
        "    print(\"-\" * 80)\n",
        "    for subject in full_data[\"subject\"].unique():\n",
        "        subject_data = full_data[full_data[\"subject\"] == subject]\n",
        "        print(f\"\\n  {subject}:\")\n",
        "        label_dist = subject_data[\"label\"].value_counts()\n",
        "        for label in label_dist.index:\n",
        "            count = label_dist[label]\n",
        "            pct = (count / len(subject_data) * 100) if len(subject_data) > 0 else 0\n",
        "            print(f\"    {label:12s}: {count:6d} pr√≥bek ({pct:6.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nüìä ROZK≈ÅAD FAZ PER SUBJECT:\")\n",
        "    print(\"-\" * 80)\n",
        "    for subject in full_data[\"subject\"].unique():\n",
        "        subject_data = full_data[full_data[\"subject\"] == subject]\n",
        "        print(f\"\\n  {subject}:\")\n",
        "        phase_dist = subject_data[\"phase\"].value_counts()\n",
        "        for phase in phase_dist.index:\n",
        "            count = phase_dist[phase]\n",
        "            pct = (count / len(subject_data) * 100) if len(subject_data) > 0 else 0\n",
        "            print(f\"    {phase:15s}: {count:6d} pr√≥bek ({pct:6.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nüìä GLOBALNY ROZK≈ÅAD KLAS (wszystkie subjecty):\")\n",
        "    print(\"-\" * 80)\n",
        "    class_dist = full_data[\"label\"].value_counts()\n",
        "    for label in class_dist.index:\n",
        "        count = class_dist[label]\n",
        "        pct = (count / len(full_data) * 100) if len(full_data) > 0 else 0\n",
        "        print(f\"   {label:12s}: {count:6d} pr√≥bek ({pct:6.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nüìä GLOBALNY ROZK≈ÅAD FAZ (wszystkie subjecty):\")\n",
        "    print(\"-\" * 80)\n",
        "    phase_dist = full_data[\"phase\"].value_counts()\n",
        "    for phase in phase_dist.index:\n",
        "        count = phase_dist[phase]\n",
        "        pct = (count / len(full_data) * 100) if len(full_data) > 0 else 0\n",
        "        print(f\"   {phase:15s}: {count:6d} pr√≥bek ({pct:6.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nüìä KOLUMNY W DANYCH:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"   Kolumny sygna≈Ç√≥w: {[col for col in full_data.columns if col not in ['timestamp', 'phase', 'label', 'subject']]}\")\n",
        "    print(f\"   Liczba kolumn sygna≈Ç√≥w: {len([col for col in full_data.columns if col not in ['timestamp', 'phase', 'label', 'subject']])}\")\n",
        "    \n",
        "    print(f\"\\nüìä KILKA PIERWSZYCH WIERSZY:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(full_data.head(10))\n",
        "    \n",
        "    print(f\"\\nüìä STATYSTYKI CZASOWE:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"   Najwcze≈õniejszy timestamp: {full_data['timestamp'].min()}\")\n",
        "    print(f\"   Najp√≥≈∫niejszy timestamp: {full_data['timestamp'].max()}\")\n",
        "    print(f\"   Czas trwania: {(full_data['timestamp'].max() - full_data['timestamp'].min()).total_seconds() / 60:.2f} minut\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ WCZYTYWANIE DANYCH ZAKO≈ÉCZONE POMY≈öLNIE!\")\n",
        "else:\n",
        "    print(\"‚ùå Nie wczytano ≈ºadnych danych!\")\n",
        "    raise ValueError(\"Brak danych do analizy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 3: SEGMENTACJA DANYCH (SLIDING WINDOWS)\n",
        "\n",
        "Tworzymy okna czasowe i wyciƒÖgamy statystyczne cechy z ka≈ºdego okna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 3: SEGMENTACJA DANYCH (SLIDING WINDOWS)\n",
            "================================================================================\n",
            "  Rozmiar okna: 5 sekund (160 pr√≥bek)\n",
            "  Krok: 2.5 sekund (80 pr√≥bek)\n",
            "  Overlap: 50.0%\n",
            "\n",
            "üîß Wykonujƒô segmentacjƒô sliding window...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "PODSUMOWANIE SEGMENTACJI\n",
            "================================================================================\n",
            "‚úÖ Segmentacja zako≈Ñczona!\n",
            "   Liczba okien: 5754\n",
            "   Liczba cech: 60\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PRZED USUNIƒòCIEM 'unknown':\n",
            "--------------------------------------------------------------------------------\n",
            "   unknown     : 5631 pr√≥bek ( 97.9%)\n",
            "   baseline    :   80 pr√≥bek (  1.4%)\n",
            "   stress      :   26 pr√≥bek (  0.5%)\n",
            "   amusement   :   17 pr√≥bek (  0.3%)\n",
            "\n",
            "üìä Liczba okien po usuniƒôciu 'unknown': 123\n",
            "   Usuniƒôto: 5631 okien z etykietƒÖ 'unknown'\n",
            "\n",
            "üìä Rozk≈Çad klas PRZED agregacjƒÖ:\n",
            "label\n",
            "baseline     80\n",
            "stress       26\n",
            "amusement    17\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "AGREGACJA KLAS: amusement + stress ‚Üí emotion\n",
            "================================================================================\n",
            "   ‚úÖ Agregacja wykonana: amusement + stress ‚Üí emotion\n",
            "   ‚úÖ Utworzono groups z kolumny 'subject': 123 element√≥w\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PO AGREGACJI:\n",
            "--------------------------------------------------------------------------------\n",
            "   baseline    :   80 pr√≥bek ( 65.0%)\n",
            "   emotion     :   43 pr√≥bek ( 35.0%)\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PER SUBJECT PO AGREGACJI:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  S2:\n",
            "    baseline    :   13 pr√≥bek ( 61.9%)\n",
            "    emotion     :    8 pr√≥bek ( 38.1%)\n",
            "\n",
            "  S3:\n",
            "    baseline    :   13 pr√≥bek ( 65.0%)\n",
            "    emotion     :    7 pr√≥bek ( 35.0%)\n",
            "\n",
            "  S4:\n",
            "    baseline    :   13 pr√≥bek ( 65.0%)\n",
            "    emotion     :    7 pr√≥bek ( 35.0%)\n",
            "\n",
            "  S5:\n",
            "    baseline    :   13 pr√≥bek ( 65.0%)\n",
            "    emotion     :    7 pr√≥bek ( 35.0%)\n",
            "\n",
            "  S6:\n",
            "    baseline    :   14 pr√≥bek ( 70.0%)\n",
            "    emotion     :    6 pr√≥bek ( 30.0%)\n",
            "\n",
            "  S7:\n",
            "    baseline    :   14 pr√≥bek ( 63.6%)\n",
            "    emotion     :    8 pr√≥bek ( 36.4%)\n",
            "\n",
            "================================================================================\n",
            "WERYFIKACJA KLAS PO SEGMENTACJI I AGREGACJI\n",
            "================================================================================\n",
            "   Unikalne klasy: ['baseline' 'emotion']\n",
            "   Liczba klas: 2\n",
            "   ‚úÖ Mamy 2 klas - OK dla SMOTE\n",
            "   ‚úÖ Klasy: baseline, emotion\n",
            "   üìä Balance ratio (przed SMOTE): 0.5375\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 3: SEGMENTACJA DANYCH (SLIDING WINDOWS)\n",
        "# ============================================================================\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'full_data' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 2!\")\n",
        "    raise NameError(\"full_data nie jest zdefiniowane - uruchom najpierw KROK 2\")\n",
        "\n",
        "# Parametry segmentacji\n",
        "WINDOW_SIZE_SECONDS = 5  # Rozmiar okna w sekundach\n",
        "STEP_SIZE_SECONDS = 2.5  # Krok (50% overlap)\n",
        "WINDOW_SIZE = int(WINDOW_SIZE_SECONDS * TARGET_FS)  # Rozmiar okna w pr√≥bkach\n",
        "STEP_SIZE = int(STEP_SIZE_SECONDS * TARGET_FS)  # Krok w pr√≥bkach\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 3: SEGMENTACJA DANYCH (SLIDING WINDOWS)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Rozmiar okna: {WINDOW_SIZE_SECONDS} sekund ({WINDOW_SIZE} pr√≥bek)\")\n",
        "print(f\"  Krok: {STEP_SIZE_SECONDS} sekund ({STEP_SIZE} pr√≥bek)\")\n",
        "print(f\"  Overlap: {(1 - STEP_SIZE_SECONDS/WINDOW_SIZE_SECONDS)*100:.1f}%\")\n",
        "\n",
        "# Funkcje do ekstrakcji cech\n",
        "def compute_rms(signal):\n",
        "    \"\"\"Oblicza RMS (Root Mean Square)\"\"\"\n",
        "    return np.sqrt(np.mean(signal**2))\n",
        "\n",
        "def compute_kurtosis(signal):\n",
        "    \"\"\"Oblicza kurtozƒô\"\"\"\n",
        "    if len(signal) < 4:\n",
        "        return 0.0\n",
        "    return stats.kurtosis(signal, nan_policy='omit')\n",
        "\n",
        "def compute_skewness(signal):\n",
        "    \"\"\"Oblicza sko≈õno≈õƒá\"\"\"\n",
        "    if len(signal) < 3:\n",
        "        return 0.0\n",
        "    return stats.skew(signal, nan_policy='omit')\n",
        "\n",
        "def compute_rmssd(signal):\n",
        "    \"\"\"Oblicza RMSSD (Root Mean Square of Successive Differences) - dla HRV\"\"\"\n",
        "    if len(signal) < 2:\n",
        "        return 0.0\n",
        "    diff = np.diff(signal)\n",
        "    return np.sqrt(np.mean(diff**2))\n",
        "\n",
        "def compute_slope(signal):\n",
        "    \"\"\"Oblicza nachylenie (slope) - trend liniowy\"\"\"\n",
        "    if len(signal) < 2:\n",
        "        return 0.0\n",
        "    x = np.arange(len(signal))\n",
        "    coeffs = np.polyfit(x, signal, 1)\n",
        "    return coeffs[0]\n",
        "\n",
        "def compute_respiration_rate(signal, fs=TARGET_FS):\n",
        "    \"\"\"Oblicza tempo oddechu (dla sygna≈Çu respiracji)\"\"\"\n",
        "    if len(signal) < int(fs * 2):  # Minimum 2 sekundy\n",
        "        return 0.0\n",
        "    # Znajd≈∫ peaki (uproszczone)\n",
        "    from scipy.signal import find_peaks\n",
        "    peaks, _ = find_peaks(signal, distance=int(fs * 0.5))  # Minimum 0.5s miƒôdzy peakami\n",
        "    if len(peaks) < 2:\n",
        "        return 0.0\n",
        "    # Oblicz ≈õredni czas miƒôdzy peakami\n",
        "    peak_intervals = np.diff(peaks) / fs\n",
        "    avg_interval = np.mean(peak_intervals)\n",
        "    if avg_interval > 0:\n",
        "        return 60.0 / avg_interval  # Oddechy na minutƒô\n",
        "    return 0.0\n",
        "\n",
        "def extract_features_from_window(window_data):\n",
        "    \"\"\"WyciƒÖga cechy statystyczne z okna\"\"\"\n",
        "    features = {}\n",
        "    \n",
        "    # Kolumny sygna≈Ç√≥w (pomijamy timestamp, phase, label, subject)\n",
        "    signal_cols = [col for col in window_data.columns \n",
        "                   if col not in [\"timestamp\", \"phase\", \"label\", \"subject\"]]\n",
        "    \n",
        "    for col in signal_cols:\n",
        "        signal = window_data[col].values\n",
        "        signal_clean = signal[~np.isnan(signal)]\n",
        "        \n",
        "        if len(signal_clean) == 0:\n",
        "            # Je≈õli wszystkie warto≈õci sƒÖ NaN, ustaw wszystkie cechy na 0\n",
        "            features[f\"{col}_mean\"] = 0.0\n",
        "            features[f\"{col}_std\"] = 0.0\n",
        "            features[f\"{col}_min\"] = 0.0\n",
        "            features[f\"{col}_max\"] = 0.0\n",
        "            features[f\"{col}_range\"] = 0.0\n",
        "            features[f\"{col}_rms\"] = 0.0\n",
        "            features[f\"{col}_kurtosis\"] = 0.0\n",
        "            features[f\"{col}_skewness\"] = 0.0\n",
        "            features[f\"{col}_rmssd\"] = 0.0\n",
        "            features[f\"{col}_slope\"] = 0.0\n",
        "            continue\n",
        "        \n",
        "        # Podstawowe statystyki\n",
        "        features[f\"{col}_mean\"] = np.mean(signal_clean)\n",
        "        features[f\"{col}_std\"] = np.std(signal_clean) if len(signal_clean) > 1 else 0.0\n",
        "        features[f\"{col}_min\"] = np.min(signal_clean)\n",
        "        features[f\"{col}_max\"] = np.max(signal_clean)\n",
        "        features[f\"{col}_range\"] = features[f\"{col}_max\"] - features[f\"{col}_min\"]\n",
        "        \n",
        "        # Zaawansowane cechy\n",
        "        features[f\"{col}_rms\"] = compute_rms(signal_clean)\n",
        "        features[f\"{col}_kurtosis\"] = compute_kurtosis(signal_clean)\n",
        "        features[f\"{col}_skewness\"] = compute_skewness(signal_clean)\n",
        "        features[f\"{col}_rmssd\"] = compute_rmssd(signal_clean)\n",
        "        features[f\"{col}_slope\"] = compute_slope(signal_clean)\n",
        "        \n",
        "        # Tempo oddechu (tylko dla kolumn zwiƒÖzanych z oddechem)\n",
        "        if \"resp\" in col.lower() or \"breath\" in col.lower():\n",
        "            features[f\"{col}_respiration_rate\"] = compute_respiration_rate(signal_clean)\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Segmentacja sliding window\n",
        "print(f\"\\nüîß Wykonujƒô segmentacjƒô sliding window...\")\n",
        "\n",
        "segmented_data = []\n",
        "groups = []  # Dla subject-wise split\n",
        "\n",
        "for subject in full_data[\"subject\"].unique():\n",
        "    subject_data = full_data[full_data[\"subject\"] == subject].copy()\n",
        "    subject_data = subject_data.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    \n",
        "    # Segmentacja\n",
        "    n_samples = len(subject_data)\n",
        "    for start_idx in range(0, n_samples - WINDOW_SIZE + 1, STEP_SIZE):\n",
        "        end_idx = start_idx + WINDOW_SIZE\n",
        "        window = subject_data.iloc[start_idx:end_idx].copy()\n",
        "        \n",
        "        # WyciƒÖgnij cechy\n",
        "        features = extract_features_from_window(window)\n",
        "        \n",
        "        # Etykieta okna (mode z okna)\n",
        "        label_counts = window[\"label\"].value_counts()\n",
        "        window_label = label_counts.index[0] if len(label_counts) > 0 else \"unknown\"\n",
        "        \n",
        "        # Dodaj metadane\n",
        "        features[\"label\"] = window_label\n",
        "        features[\"subject\"] = subject\n",
        "        features[\"window_start\"] = start_idx\n",
        "        features[\"window_end\"] = end_idx\n",
        "        \n",
        "        segmented_data.append(features)\n",
        "        groups.append(subject)\n",
        "\n",
        "# Stw√≥rz DataFrame z segmentowanych danych\n",
        "segmented_df = pd.DataFrame(segmented_data)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"PODSUMOWANIE SEGMENTACJI\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"‚úÖ Segmentacja zako≈Ñczona!\")\n",
        "print(f\"   Liczba okien: {len(segmented_df)}\")\n",
        "print(f\"   Liczba cech: {len([col for col in segmented_df.columns if col not in ['label', 'subject', 'window_start', 'window_end']])}\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas przed usuniƒôciem \"unknown\"\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS PRZED USUNIƒòCIEM 'unknown':\")\n",
        "print(\"-\" * 80)\n",
        "class_dist_before_clean = segmented_df[\"label\"].value_counts()\n",
        "for label in class_dist_before_clean.index:\n",
        "    count = class_dist_before_clean[label]\n",
        "    pct = (count / len(segmented_df) * 100) if len(segmented_df) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Usu≈Ñ okna z etykietƒÖ \"unknown\"\n",
        "segmented_df = segmented_df[segmented_df[\"label\"] != \"unknown\"].copy()\n",
        "print(f\"\\nüìä Liczba okien po usuniƒôciu 'unknown': {len(segmented_df)}\")\n",
        "print(f\"   Usuniƒôto: {len(segmented_data) - len(segmented_df)} okien z etykietƒÖ 'unknown'\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas przed agregacjƒÖ\n",
        "print(f\"\\nüìä Rozk≈Çad klas PRZED agregacjƒÖ:\")\n",
        "class_dist_before_agg = segmented_df[\"label\"].value_counts()\n",
        "print(class_dist_before_agg)\n",
        "\n",
        "# ‚ö†Ô∏è WA≈ªNE: Agregacja klas (amusement + stress ‚Üí emotion)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"AGREGACJA KLAS: amusement + stress ‚Üí emotion\")\n",
        "print(f\"{'='*80}\")\n",
        "segmented_df[\"label\"] = segmented_df[\"label\"].replace({\n",
        "    \"amusement\": \"emotion\",\n",
        "    \"stress\": \"emotion\"\n",
        "})\n",
        "print(f\"   ‚úÖ Agregacja wykonana: amusement + stress ‚Üí emotion\")\n",
        "\n",
        "# U≈ºyj kolumny 'subject' z segmented_df jako groups (najprostsze i najbardziej niezawodne)\n",
        "if 'subject' in segmented_df.columns:\n",
        "    groups = segmented_df['subject'].tolist()\n",
        "    print(f\"   ‚úÖ Utworzono groups z kolumny 'subject': {len(groups)} element√≥w\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è OSTRZE≈ªENIE: Brak kolumny 'subject' w segmented_df!\")\n",
        "    raise ValueError(\"Brak kolumny 'subject' w segmented_df - nie mo≈ºna utworzyƒá groups\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas po agregacji\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS PO AGREGACJI:\")\n",
        "print(\"-\" * 80)\n",
        "class_dist_seg = segmented_df[\"label\"].value_counts()\n",
        "for label in class_dist_seg.index:\n",
        "    count = class_dist_seg[label]\n",
        "    pct = (count / len(segmented_df) * 100) if len(segmented_df) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas per subject po agregacji\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS PER SUBJECT PO AGREGACJI:\")\n",
        "print(\"-\" * 80)\n",
        "for subject in segmented_df[\"subject\"].unique():\n",
        "    subject_data = segmented_df[segmented_df[\"subject\"] == subject]\n",
        "    print(f\"\\n  {subject}:\")\n",
        "    label_dist = subject_data[\"label\"].value_counts()\n",
        "    for label in label_dist.index:\n",
        "        count = label_dist[label]\n",
        "        pct = (count / len(subject_data) * 100) if len(subject_data) > 0 else 0\n",
        "        print(f\"    {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Weryfikacja: czy mamy obie klasy (baseline i emotion)\n",
        "unique_labels = segmented_df[\"label\"].unique()\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"WERYFIKACJA KLAS PO SEGMENTACJI I AGREGACJI\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"   Unikalne klasy: {unique_labels}\")\n",
        "print(f\"   Liczba klas: {len(unique_labels)}\")\n",
        "\n",
        "if len(unique_labels) < 2:\n",
        "    print(f\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Tylko {len(unique_labels)} klas po segmentacji!\")\n",
        "    print(f\"   Musimy mieƒá co najmniej 2 klasy (baseline i emotion) dla SMOTE!\")\n",
        "    print(f\"   Sprawd≈∫ wczytywanie faz i mapowanie PHASE_TO_CLASS.\")\n",
        "    print(f\"\\nüìä DIAGNOSTYKA:\")\n",
        "    print(f\"   - Sprawd≈∫ czy fazy sƒÖ poprawnie wczytywane z plik√≥w *_quest.csv\")\n",
        "    print(f\"   - Sprawd≈∫ czy mapowanie PHASE_TO_CLASS jest poprawne\")\n",
        "    print(f\"   - Sprawd≈∫ czy assign_phase_labels dzia≈Ça poprawnie\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Mamy {len(unique_labels)} klas - OK dla SMOTE\")\n",
        "    print(f\"   ‚úÖ Klasy: {', '.join(unique_labels)}\")\n",
        "    \n",
        "    # Sprawd≈∫ balance ratio przed SMOTE\n",
        "    if len(unique_labels) == 2:\n",
        "        counts = [class_dist_seg[label] for label in unique_labels]\n",
        "        balance_ratio = min(counts) / max(counts) if max(counts) > 0 else 0\n",
        "        print(f\"   üìä Balance ratio (przed SMOTE): {balance_ratio:.4f}\")\n",
        "        if balance_ratio < 0.5:\n",
        "            print(f\"   ‚ö†Ô∏è OSTRZE≈ªENIE: Silna nier√≥wnowaga klas (balance ratio < 0.5)\")\n",
        "            print(f\"      SMOTE bƒôdzie musia≈Ç wygenerowaƒá du≈ºo syntetycznych pr√≥bek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 4: ENCODING I SKALOWANIE CECH\n",
        "\n",
        "Kodujemy etykiety i skalujemy cechy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 4: ENCODING I SKALOWANIE CECH\n",
            "================================================================================\n",
            "\n",
            "üìä Kszta≈Çt danych:\n",
            "   X: (123, 60)\n",
            "   y: 123 pr√≥bek\n",
            "\n",
            "‚úÖ LabelEncoder:\n",
            "   Klasy: ['baseline' 'emotion']\n",
            "   Kodowanie: {'baseline': 0, 'emotion': 1}\n",
            "\n",
            "‚úÖ StandardScaler:\n",
            "   Cechy przeskalowane: 60\n",
            "   Przyk≈Çadowe warto≈õci (pierwsze 5 cech, pierwsze 3 pr√≥bki):\n",
            "   acc_x_mean  acc_x_std  acc_x_min  acc_x_max  acc_x_range\n",
            "2    0.746109  -0.743730   1.082446   0.096562    -0.773286\n",
            "3    0.752501  -0.765521   1.087307   0.096423    -0.777279\n",
            "4    0.746653  -0.778669   1.101748   0.095018    -0.790038\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 4: ENCODING I SKALOWANIE CECH\n",
        "# ============================================================================\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'segmented_df' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 3!\")\n",
        "    raise NameError(\"segmented_df nie jest zdefiniowane - uruchom najpierw KROK 3\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 4: ENCODING I SKALOWANIE CECH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Przygotuj dane\n",
        "feature_cols = [col for col in segmented_df.columns \n",
        "                if col not in [\"label\", \"subject\", \"window_start\", \"window_end\"]]\n",
        "X = segmented_df[feature_cols].copy()\n",
        "y = segmented_df[\"label\"].copy()\n",
        "\n",
        "# Usu≈Ñ kolumny z samymi NaN\n",
        "X = X.dropna(axis=1, how='all')\n",
        "\n",
        "# Wype≈Çnij pozosta≈Çe NaN zerami\n",
        "X = X.fillna(0.0)\n",
        "\n",
        "print(f\"\\nüìä Kszta≈Çt danych:\")\n",
        "print(f\"   X: {X.shape}\")\n",
        "print(f\"   y: {len(y)} pr√≥bek\")\n",
        "\n",
        "# LabelEncoder dla targetu\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(f\"\\n‚úÖ LabelEncoder:\")\n",
        "print(f\"   Klasy: {label_encoder.classes_}\")\n",
        "print(f\"   Kodowanie: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")\n",
        "\n",
        "# StandardScaler dla cech\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
        "\n",
        "print(f\"\\n‚úÖ StandardScaler:\")\n",
        "print(f\"   Cechy przeskalowane: {X_scaled.shape[1]}\")\n",
        "print(f\"   Przyk≈Çadowe warto≈õci (pierwsze 5 cech, pierwsze 3 pr√≥bki):\")\n",
        "print(X_scaled.iloc[:3, :5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 5: PODZIA≈Å TRAIN/TEST - SUBJECT-WISE SPLIT\n",
        "\n",
        "‚ö†Ô∏è **WA≈ªNE**: Ca≈Çe dane jednej osoby trafiajƒÖ albo do train, albo do test. Nie dzielimy okien z tej samej osoby miƒôdzy train i test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 5: PODZIA≈Å TRAIN/TEST - SUBJECT-WISE SPLIT\n",
            "================================================================================\n",
            "‚ö†Ô∏è WA≈ªNE: Ca≈Çe dane jednej osoby trafiajƒÖ albo do train, albo do test\n",
            "‚ö†Ô∏è WA≈ªNE: Nie dzielimy okien z tej samej osoby miƒôdzy train i test\n",
            "\n",
            "üìä Weryfikacja danych przed split:\n",
            "   X_scaled shape: (123, 60)\n",
            "   y_encoded length: 123\n",
            "   groups length: 123\n",
            "   ‚úÖ groups skonwertowany na numpy array: (123,)\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PER SUBJECT (przed split):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  S2:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    8 pr√≥bek\n",
            "\n",
            "  S3:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S4:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S5:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S6:\n",
            "    baseline    :   14 pr√≥bek\n",
            "    emotion     :    6 pr√≥bek\n",
            "\n",
            "  S7:\n",
            "    baseline    :   14 pr√≥bek\n",
            "    emotion     :    8 pr√≥bek\n",
            "\n",
            "================================================================================\n",
            "STRATIFIED SUBJECT-WISE SPLIT\n",
            "================================================================================\n",
            "‚ö†Ô∏è WA≈ªNE: Upewniamy siƒô, ≈ºe w train i test sƒÖ obecne obie klasy!\n",
            "‚ö†Ô∏è WA≈ªNE: W train muszƒÖ byƒá co najmniej 2 klasy (wymagane dla SMOTE)!\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PER SUBJECT (przed split):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  S2:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    8 pr√≥bek\n",
            "\n",
            "  S3:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S4:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S5:\n",
            "    baseline    :   13 pr√≥bek\n",
            "    emotion     :    7 pr√≥bek\n",
            "\n",
            "  S6:\n",
            "    baseline    :   14 pr√≥bek\n",
            "    emotion     :    6 pr√≥bek\n",
            "\n",
            "  S7:\n",
            "    baseline    :   14 pr√≥bek\n",
            "    emotion     :    8 pr√≥bek\n",
            "\n",
            "üîç Szukam najlepszego podzia≈Çu (testujƒô 100 r√≥≈ºnych podzia≈Ç√≥w)...\n",
            "\n",
            "‚úÖ Znaleziono najlepszy podzia≈Ç:\n",
            "   Score: 36\n",
            "   Train subjects: ['S4', 'S5', 'S6', 'S7'] (4 subject√≥w)\n",
            "   Test subjects: ['S2', 'S3'] (2 subject√≥w)\n",
            "\n",
            "‚úÖ Podzia≈Ç subject-wise:\n",
            "   Train subjects: ['S4', 'S5', 'S6', 'S7'] (4 subject√≥w)\n",
            "   Test subjects: ['S2', 'S3'] (2 subject√≥w)\n",
            "   ‚úÖ Train i test subjects sƒÖ roz≈ÇƒÖczne - OK\n",
            "\n",
            "üìä Rozk≈Çad klas w TRAIN:\n",
            "   baseline    :   54 pr√≥bek ( 65.9%)\n",
            "   emotion     :   28 pr√≥bek ( 34.1%)\n",
            "\n",
            "üìä Rozk≈Çad klas w TEST:\n",
            "   baseline    :   26 pr√≥bek ( 63.4%)\n",
            "   emotion     :   15 pr√≥bek ( 36.6%)\n",
            "\n",
            "üìä SZCZEG√ì≈ÅOWE SPRAWDZENIE LICZBY PR√ìBEK PER KLASƒò:\n",
            "--------------------------------------------------------------------------------\n",
            "TRAIN:\n",
            "   baseline     (kod 0):   54 pr√≥bek\n",
            "   emotion      (kod 1):   28 pr√≥bek\n",
            "\n",
            "TEST:\n",
            "   baseline     (kod 0):   26 pr√≥bek\n",
            "   emotion      (kod 1):   15 pr√≥bek\n",
            "\n",
            "‚úÖ WERYFIKACJA KLAS:\n",
            "   Train: 2 klas - ['baseline' 'emotion']\n",
            "   Test: 2 klas - ['baseline' 'emotion']\n",
            "   ‚úÖ Train ma co najmniej 2 klasy - SMOTE mo≈ºe dzia≈Çaƒá\n",
            "\n",
            "‚úÖ Podzia≈Ç zako≈Ñczony:\n",
            "   Train: 82 pr√≥bek\n",
            "   Test: 41 pr√≥bek\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 5: PODZIA≈Å TRAIN/TEST - SUBJECT-WISE SPLIT\n",
        "# ============================================================================\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'X_scaled' not in globals() or 'y_encoded' not in globals() or 'groups' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 3 i KROK 4!\")\n",
        "    raise NameError(\"X_scaled, y_encoded lub groups nie sƒÖ zdefiniowane - uruchom najpierw KROK 3 i KROK 4\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 5: PODZIA≈Å TRAIN/TEST - SUBJECT-WISE SPLIT\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚ö†Ô∏è WA≈ªNE: Ca≈Çe dane jednej osoby trafiajƒÖ albo do train, albo do test\")\n",
        "print(\"‚ö†Ô∏è WA≈ªNE: Nie dzielimy okien z tej samej osoby miƒôdzy train i test\")\n",
        "\n",
        "# Sprawd≈∫ d≈Çugo≈õci i konwertuj groups na numpy array\n",
        "print(f\"\\nüìä Weryfikacja danych przed split:\")\n",
        "print(f\"   X_scaled shape: {X_scaled.shape}\")\n",
        "print(f\"   y_encoded length: {len(y_encoded)}\")\n",
        "print(f\"   groups length: {len(groups)}\")\n",
        "\n",
        "if len(groups) != len(X_scaled) or len(groups) != len(y_encoded):\n",
        "    print(f\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: D≈Çugo≈õci siƒô nie zgadzajƒÖ!\")\n",
        "    print(f\"   X_scaled: {len(X_scaled)}, y_encoded: {len(y_encoded)}, groups: {len(groups)}\")\n",
        "    raise ValueError(\"D≈Çugo≈õci X_scaled, y_encoded i groups muszƒÖ byƒá identyczne!\")\n",
        "\n",
        "# Konwertuj groups na numpy array (wymagane przez GroupShuffleSplit)\n",
        "groups_array = np.array(groups)\n",
        "print(f\"   ‚úÖ groups skonwertowany na numpy array: {groups_array.shape}\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas per subject (przed split)\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS PER SUBJECT (przed split):\")\n",
        "print(\"-\" * 80)\n",
        "unique_subjects = np.unique(groups_array)\n",
        "subject_class_dist = {}\n",
        "for subject in unique_subjects:\n",
        "    subject_mask = groups_array == subject\n",
        "    subject_labels = y_encoded[subject_mask]\n",
        "    subject_dist = pd.Series(label_encoder.inverse_transform(subject_labels)).value_counts()\n",
        "    subject_class_dist[subject] = subject_dist\n",
        "    print(f\"\\n  {subject}:\")\n",
        "    for label in subject_dist.index:\n",
        "        print(f\"    {label:12s}: {subject_dist[label]:4d} pr√≥bek\")\n",
        "\n",
        "# STRATIFIED SUBJECT-WISE SPLIT: Upewnij siƒô, ≈ºe w train i test sƒÖ obecne obie klasy\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"STRATIFIED SUBJECT-WISE SPLIT\")\n",
        "print(f\"{'='*80}\")\n",
        "print(\"‚ö†Ô∏è WA≈ªNE: Upewniamy siƒô, ≈ºe w train i test sƒÖ obecne obie klasy!\")\n",
        "print(\"‚ö†Ô∏è WA≈ªNE: W train muszƒÖ byƒá co najmniej 2 klasy (wymagane dla SMOTE)!\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas per subject (przed split)\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS PER SUBJECT (przed split):\")\n",
        "print(\"-\" * 80)\n",
        "unique_subjects = np.unique(groups_array)\n",
        "subject_class_dist = {}\n",
        "for subject in unique_subjects:\n",
        "    subject_mask = groups_array == subject\n",
        "    subject_labels = y_encoded[subject_mask]\n",
        "    subject_dist = pd.Series(label_encoder.inverse_transform(subject_labels)).value_counts()\n",
        "    subject_class_dist[subject] = subject_dist\n",
        "    print(f\"\\n  {subject}:\")\n",
        "    for label in subject_dist.index:\n",
        "        print(f\"    {label:12s}: {subject_dist[label]:4d} pr√≥bek\")\n",
        "\n",
        "# U≈ºyj GroupShuffleSplit z wieloma pr√≥bami, aby znale≈∫ƒá podzia≈Ç z obiema klasami w train i test\n",
        "gss = GroupShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
        "\n",
        "best_train_idx = None\n",
        "best_test_idx = None\n",
        "best_score = -np.inf\n",
        "best_train_subjects = None\n",
        "best_test_subjects = None\n",
        "\n",
        "print(f\"\\nüîç Szukam najlepszego podzia≈Çu (testujƒô {gss.n_splits} r√≥≈ºnych podzia≈Ç√≥w)...\")\n",
        "\n",
        "for train_idx, test_idx in gss.split(X_scaled, y_encoded, groups=groups_array):\n",
        "    # Sprawd≈∫ czy w train i test sƒÖ obecne obie klasy\n",
        "    train_classes = np.unique(y_encoded[train_idx])\n",
        "    test_classes = np.unique(y_encoded[test_idx])\n",
        "    \n",
        "    # Wszystkie klasy muszƒÖ byƒá w train (wymagane dla SMOTE)\n",
        "    # W test powinna byƒá co najmniej jedna klasa (ale najlepiej obie)\n",
        "    if len(train_classes) >= 2:\n",
        "        # Sprawd≈∫ subjecty w train i test\n",
        "        train_subjects_set = set(groups_array[train_idx])\n",
        "        test_subjects_set = set(groups_array[test_idx])\n",
        "        \n",
        "        # Oblicz \"score\" - preferuj podzia≈Çy z obiema klasami w test i wiƒôcej subject√≥w\n",
        "        score = len(train_classes) * 10 + len(test_classes) * 5 + len(train_subjects_set) + len(test_subjects_set)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_train_idx = train_idx\n",
        "            best_test_idx = test_idx\n",
        "            best_train_subjects = train_subjects_set\n",
        "            best_test_subjects = test_subjects_set\n",
        "\n",
        "# Je≈õli nie znaleziono podzia≈Çu z obiema klasami w train, rzuƒá b≈ÇƒÖd\n",
        "if best_train_idx is None:\n",
        "    print(f\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Nie znaleziono podzia≈Çu z co najmniej 2 klasami w train!\")\n",
        "    print(f\"   To oznacza, ≈ºe dane sƒÖ zbyt niezbalansowane lub subjecty majƒÖ tylko jednƒÖ klasƒô.\")\n",
        "    print(f\"   Sprawd≈∫ rozk≈Çad klas per subject powy≈ºej.\")\n",
        "    raise ValueError(\"Nie mo≈ºna utworzyƒá podzia≈Çu z co najmniej 2 klasami w train - SMOTE nie bƒôdzie dzia≈Çaƒá!\")\n",
        "\n",
        "train_idx = best_train_idx\n",
        "test_idx = best_test_idx\n",
        "\n",
        "print(f\"\\n‚úÖ Znaleziono najlepszy podzia≈Ç:\")\n",
        "print(f\"   Score: {best_score}\")\n",
        "print(f\"   Train subjects: {sorted(best_train_subjects)} ({len(best_train_subjects)} subject√≥w)\")\n",
        "print(f\"   Test subjects: {sorted(best_test_subjects)} ({len(best_test_subjects)} subject√≥w)\")\n",
        "\n",
        "X_train = X_scaled.iloc[train_idx].copy()\n",
        "X_test = X_scaled.iloc[test_idx].copy()\n",
        "y_train = y_encoded[train_idx]\n",
        "y_test = y_encoded[test_idx]\n",
        "groups_train = [groups[i] for i in train_idx]\n",
        "groups_test = [groups[i] for i in test_idx]\n",
        "\n",
        "# Sprawd≈∫ kt√≥re subjecty trafi≈Çy do train/test\n",
        "train_subjects = set(groups_train)\n",
        "test_subjects = set(groups_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Podzia≈Ç subject-wise:\")\n",
        "print(f\"   Train subjects: {sorted(train_subjects)} ({len(train_subjects)} subject√≥w)\")\n",
        "print(f\"   Test subjects: {sorted(test_subjects)} ({len(test_subjects)} subject√≥w)\")\n",
        "\n",
        "# Weryfikacja: train i test subjects sƒÖ roz≈ÇƒÖczne\n",
        "if train_subjects & test_subjects:\n",
        "    print(f\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Train i test subjects siƒô nak≈ÇadajƒÖ!\")\n",
        "    raise ValueError(\"Subject-wise split nie dzia≈Ça poprawnie!\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Train i test subjects sƒÖ roz≈ÇƒÖczne - OK\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas w train i test\n",
        "print(f\"\\nüìä Rozk≈Çad klas w TRAIN:\")\n",
        "train_dist = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "for label in train_dist.index:\n",
        "    count = train_dist[label]\n",
        "    pct = (count / len(y_train) * 100) if len(y_train) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "print(f\"\\nüìä Rozk≈Çad klas w TEST:\")\n",
        "test_dist = pd.Series(label_encoder.inverse_transform(y_test)).value_counts()\n",
        "for label in test_dist.index:\n",
        "    count = test_dist[label]\n",
        "    pct = (count / len(y_test) * 100) if len(y_test) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Sprawdzenie liczby pr√≥bek per klasƒô (u≈ºywajƒÖc kodu u≈ºytkownika)\n",
        "print(f\"\\nüìä SZCZEG√ì≈ÅOWE SPRAWDZENIE LICZBY PR√ìBEK PER KLASƒò:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"TRAIN:\")\n",
        "for label in np.unique(y_train):\n",
        "    label_name = label_encoder.inverse_transform([label])[0]\n",
        "    count = np.sum(y_train == label)\n",
        "    print(f\"   {label_name:12s} (kod {label}): {count:4d} pr√≥bek\")\n",
        "\n",
        "print(\"\\nTEST:\")\n",
        "for label in np.unique(y_test):\n",
        "    label_name = label_encoder.inverse_transform([label])[0]\n",
        "    count = np.sum(y_test == label)\n",
        "    print(f\"   {label_name:12s} (kod {label}): {count:4d} pr√≥bek\")\n",
        "\n",
        "# Weryfikacja: czy w train sƒÖ co najmniej 2 klasy (wymagane dla SMOTE)\n",
        "train_unique_classes = np.unique(y_train)\n",
        "test_unique_classes = np.unique(y_test)\n",
        "\n",
        "print(f\"\\n‚úÖ WERYFIKACJA KLAS:\")\n",
        "print(f\"   Train: {len(train_unique_classes)} klas - {label_encoder.inverse_transform(train_unique_classes)}\")\n",
        "print(f\"   Test: {len(test_unique_classes)} klas - {label_encoder.inverse_transform(test_unique_classes)}\")\n",
        "\n",
        "if len(train_unique_classes) < 2:\n",
        "    print(f\"\\n‚ö†Ô∏è OSTRZE≈ªENIE: Tylko {len(train_unique_classes)} klas w train!\")\n",
        "    print(f\"   SMOTE wymaga co najmniej 2 klas. Balansowanie mo≈ºe nie dzia≈Çaƒá.\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Train ma co najmniej 2 klasy - SMOTE mo≈ºe dzia≈Çaƒá\")\n",
        "\n",
        "print(f\"\\n‚úÖ Podzia≈Ç zako≈Ñczony:\")\n",
        "print(f\"   Train: {len(X_train)} pr√≥bek\")\n",
        "print(f\"   Test: {len(X_test)} pr√≥bek\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 6: BALANSOWANIE DANYCH W TRENINGU (SMOTE)\n",
        "\n",
        "Zastosujemy SMOTE **TYLKO na train**. Test pozostaje niezmieniony.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 6: BALANSOWANIE DANYCH W TRENINGU (SMOTE)\n",
            "================================================================================\n",
            "‚ö†Ô∏è WA≈ªNE: SMOTE TYLKO na train, test pozostaje niezmieniony!\n",
            "\n",
            "üìä Rozk≈Çad klas PRZED SMOTE (train):\n",
            "   baseline    :   54 pr√≥bek ( 65.9%)\n",
            "   emotion     :   28 pr√≥bek ( 34.1%)\n",
            "\n",
            "üîß Wykonujƒô SMOTE...\n",
            "   Liczba klas: 2\n",
            "   Klasy: ['baseline' 'emotion']\n",
            "‚úÖ SMOTE.fit_resample() wykonany pomy≈õlnie!\n",
            "\n",
            "üìä WERYFIKACJA SMOTE:\n",
            "   Train przed SMOTE: 82 pr√≥bek\n",
            "   Train po SMOTE: 108 pr√≥bek\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS PO SMOTE (train) - SZCZEG√ì≈ÅOWO:\n",
            "--------------------------------------------------------------------------------\n",
            "   baseline     (kod 0):   54 pr√≥bek ( 50.0%)\n",
            "   emotion      (kod 1):   54 pr√≥bek ( 50.0%)\n",
            "\n",
            "üìä Balance ratio: 1.0000\n",
            "   ‚úÖ‚úÖ‚úÖ IDEALNY BALANS! Klasy sƒÖ zbalansowane (balance ratio >= 0.95)!\n",
            "\n",
            "‚úÖ SMOTE zako≈Ñczony pomy≈õlnie!\n",
            "\n",
            "üìä Rozk≈Çad klas PO SMOTE (train):\n",
            "   baseline    :   54 pr√≥bek ( 50.0%)\n",
            "   emotion     :   54 pr√≥bek ( 50.0%)\n",
            "\n",
            "üìä Balance ratio: 1.0000\n",
            "   ‚úÖ‚úÖ‚úÖ IDEALNY BALANS! baseline i emotion/stress/amusement majƒÖ tyle samo pr√≥bek!\n",
            "\n",
            "üìä Rozk≈Çad klas w TEST (niezmieniony, bez SMOTE):\n",
            "   baseline    :   26 pr√≥bek ( 63.4%)\n",
            "   emotion     :   15 pr√≥bek ( 36.6%)\n",
            "\n",
            "‚úÖ Test pozostaje niezbalansowany - to jest poprawne dla realnej ewaluacji!\n",
            "\n",
            "üìä PODSUMOWANIE:\n",
            "   Train przed SMOTE: 82 pr√≥bek, 2 klas\n",
            "   Train po SMOTE: 108 pr√≥bek, 2 klas\n",
            "   Test: 41 pr√≥bek, 2 klas\n",
            "Klasa          object\n",
            "Przed SMOTE     int64\n",
            "Po SMOTE        int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 6: BALANSOWANIE DANYCH W TRENINGU (SMOTE)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 6: BALANSOWANIE DANYCH W TRENINGU (SMOTE)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚ö†Ô∏è WA≈ªNE: SMOTE TYLKO na train, test pozostaje niezmieniony!\")\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'X_train' not in globals() or 'y_train' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 4 i KROK 5!\")\n",
        "    raise NameError(\"X_train, y_train nie sƒÖ zdefiniowane - uruchom najpierw KROK 4 i KROK 5\")\n",
        "\n",
        "if 'label_encoder' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 4!\")\n",
        "    raise NameError(\"label_encoder nie jest zdefiniowany - uruchom najpierw KROK 4\")\n",
        "\n",
        "if 'y_test' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 5!\")\n",
        "    raise NameError(\"y_test nie jest zdefiniowane - uruchom najpierw KROK 5\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas przed SMOTE\n",
        "print(f\"\\nüìä Rozk≈Çad klas PRZED SMOTE (train):\")\n",
        "train_dist_before = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "for label in train_dist_before.index:\n",
        "    count = train_dist_before[label]\n",
        "    pct = (count / len(y_train) * 100) if len(y_train) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Sprawd≈∫ czy mamy wiƒôcej ni≈º jednƒÖ klasƒô (SMOTE wymaga co najmniej 2 klas)\n",
        "unique_classes = np.unique(y_train)\n",
        "n_classes = len(unique_classes)\n",
        "\n",
        "if n_classes < 2:\n",
        "    print(f\"\\n‚ö†Ô∏è OSTRZE≈ªENIE: Tylko {n_classes} klas w train - SMOTE nie mo≈ºe dzia≈Çaƒá!\")\n",
        "    print(f\"   Klasy w train: {label_encoder.inverse_transform(unique_classes)}\")\n",
        "    print(f\"   SMOTE wymaga co najmniej 2 klas. U≈ºywam danych bez balansowania.\")\n",
        "    X_train_bal = X_train.copy() if isinstance(X_train, pd.DataFrame) else X_train\n",
        "    y_train_bal = y_train.copy()\n",
        "elif not IMBLEARN_AVAILABLE:\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: imbalanced-learn nie jest dostƒôpny!\")\n",
        "    print(\"   Zainstaluj: pip install imbalanced-learn\")\n",
        "    X_train_bal = X_train.copy() if isinstance(X_train, pd.DataFrame) else X_train\n",
        "    y_train_bal = y_train.copy()\n",
        "else:\n",
        "    # Konwertuj X_train na numpy array je≈õli jest DataFrame\n",
        "    if isinstance(X_train, pd.DataFrame):\n",
        "        X_train_array = X_train.values\n",
        "    else:\n",
        "        X_train_array = X_train\n",
        "    \n",
        "    # SMOTE wymaga co najmniej 2 klas - to ju≈º sprawdzili≈õmy wcze≈õniej\n",
        "    if n_classes >= 2:\n",
        "        # Zastosuj SMOTE\n",
        "        print(f\"\\nüîß Wykonujƒô SMOTE...\")\n",
        "        print(f\"   Liczba klas: {n_classes}\")\n",
        "        print(f\"   Klasy: {label_encoder.inverse_transform(unique_classes)}\")\n",
        "        \n",
        "        # Upewnij siƒô, ≈ºe X_train jest numpy array (SMOTE wymaga numpy array)\n",
        "        X_train_for_smote = X_train_array\n",
        "        \n",
        "        try:\n",
        "            # U≈ºyj prostego SMOTE (zgodnie z przyk≈Çadem u≈ºytkownika)\n",
        "            from imblearn.over_sampling import SMOTE\n",
        "            smote = SMOTE(random_state=42)\n",
        "            X_train_bal_array, y_train_bal = smote.fit_resample(X_train_for_smote, y_train)\n",
        "            \n",
        "            print(f\"‚úÖ SMOTE.fit_resample() wykonany pomy≈õlnie!\")\n",
        "            \n",
        "            # Konwertuj z powrotem na DataFrame je≈õli X_train by≈Ç DataFrame\n",
        "            if isinstance(X_train, pd.DataFrame):\n",
        "                X_train_bal = pd.DataFrame(X_train_bal_array, columns=X_train.columns)\n",
        "            else:\n",
        "                X_train_bal = X_train_bal_array\n",
        "            \n",
        "            # Weryfikacja SMOTE - sprawd≈∫ rozk≈Çad klas po SMOTE\n",
        "            print(f\"\\nüìä WERYFIKACJA SMOTE:\")\n",
        "            print(f\"   Train przed SMOTE: {len(X_train)} pr√≥bek\")\n",
        "            print(f\"   Train po SMOTE: {len(X_train_bal)} pr√≥bek\")\n",
        "            \n",
        "            # Sprawd≈∫ rozk≈Çad klas po SMOTE (u≈ºywajƒÖc kodu u≈ºytkownika)\n",
        "            print(f\"\\nüìä ROZK≈ÅAD KLAS PO SMOTE (train) - SZCZEG√ì≈ÅOWO:\")\n",
        "            print(\"-\" * 80)\n",
        "            for label in np.unique(y_train_bal):\n",
        "                label_name = label_encoder.inverse_transform([label])[0]\n",
        "                count = np.sum(y_train_bal == label)\n",
        "                pct = (count / len(y_train_bal) * 100) if len(y_train_bal) > 0 else 0\n",
        "                print(f\"   {label_name:12s} (kod {label}): {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "            \n",
        "            # Weryfikacja balansu\n",
        "            unique_labels_after = np.unique(y_train_bal)\n",
        "            if len(unique_labels_after) == 2:\n",
        "                counts = [np.sum(y_train_bal == label) for label in unique_labels_after]\n",
        "                balance_ratio = min(counts) / max(counts)\n",
        "                print(f\"\\nüìä Balance ratio: {balance_ratio:.4f}\")\n",
        "                if balance_ratio >= 0.95:\n",
        "                    print(f\"   ‚úÖ‚úÖ‚úÖ IDEALNY BALANS! Klasy sƒÖ zbalansowane (balance ratio >= 0.95)!\")\n",
        "                elif balance_ratio >= 0.8:\n",
        "                    print(f\"   ‚úÖ Dobry balans (balance ratio >= 0.8)\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è Czƒô≈õciowy balans (balance ratio < 0.8)\")\n",
        "            \n",
        "            print(f\"\\n‚úÖ SMOTE zako≈Ñczony pomy≈õlnie!\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå B≈ÅƒÑD podczas SMOTE: {e}\")\n",
        "            print(f\"   U≈ºywam danych bez balansowania.\")\n",
        "            X_train_bal = X_train.copy() if isinstance(X_train, pd.DataFrame) else X_train\n",
        "            y_train_bal = y_train.copy()\n",
        "    \n",
        "# Sprawd≈∫ rozk≈Çad klas po SMOTE (lub bez SMOTE je≈õli nie by≈Ço mo≈ºliwe)\n",
        "print(f\"\\nüìä Rozk≈Çad klas PO SMOTE (train):\")\n",
        "train_dist_after = pd.Series(label_encoder.inverse_transform(y_train_bal)).value_counts()\n",
        "for label in train_dist_after.index:\n",
        "    count = train_dist_after[label]\n",
        "    pct = (count / len(y_train_bal) * 100) if len(y_train_bal) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "# Sprawd≈∫ balance ratio (tylko je≈õli mamy wiƒôcej ni≈º jednƒÖ klasƒô)\n",
        "if len(train_dist_after) >= 2:\n",
        "    balance_ratio = min(train_dist_after.values) / max(train_dist_after.values)\n",
        "    print(f\"\\nüìä Balance ratio: {balance_ratio:.4f}\")\n",
        "    \n",
        "    baseline_count = train_dist_after.get('baseline', 0)\n",
        "    emotion_count = train_dist_after.get('emotion', 0) if 'emotion' in train_dist_after.index else 0\n",
        "    stress_count = train_dist_after.get('stress', 0) if 'stress' in train_dist_after.index else 0\n",
        "    amusement_count = train_dist_after.get('amusement', 0) if 'amusement' in train_dist_after.index else 0\n",
        "    \n",
        "    if baseline_count > 0 and (emotion_count > 0 or stress_count > 0 or amusement_count > 0):\n",
        "        minority_count = emotion_count + stress_count + amusement_count\n",
        "        if baseline_count == minority_count:\n",
        "            print(f\"   ‚úÖ‚úÖ‚úÖ IDEALNY BALANS! baseline i emotion/stress/amusement majƒÖ tyle samo pr√≥bek!\")\n",
        "        elif balance_ratio >= 0.95:\n",
        "            print(f\"   ‚úÖ‚úÖ‚úÖ KLASY SƒÑ ZBALANSOWANE (balance ratio >= 0.95)!\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è Klasy sƒÖ czƒô≈õciowo zbalansowane\")\n",
        "elif len(train_dist_after) == 1:\n",
        "    print(f\"\\n‚ö†Ô∏è OSTRZE≈ªENIE: Tylko jedna klasa w train po SMOTE - balansowanie nie by≈Ço mo≈ºliwe\")\n",
        "\n",
        "# Weryfikacja: test pozostaje niezmieniony\n",
        "print(f\"\\nüìä Rozk≈Çad klas w TEST (niezmieniony, bez SMOTE):\")\n",
        "test_dist_unchanged = pd.Series(label_encoder.inverse_transform(y_test)).value_counts()\n",
        "for label in test_dist_unchanged.index:\n",
        "    count = test_dist_unchanged[label]\n",
        "    pct = (count / len(y_test) * 100) if len(y_test) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "\n",
        "print(f\"\\n‚úÖ Test pozostaje niezbalansowany - to jest poprawne dla realnej ewaluacji!\")\n",
        "\n",
        "# Weryfikacja ko≈Ñcowa\n",
        "print(f\"\\nüìä PODSUMOWANIE:\")\n",
        "print(f\"   Train przed SMOTE: {len(X_train)} pr√≥bek, {len(np.unique(y_train))} klas\")\n",
        "print(f\"   Train po SMOTE: {len(X_train_bal)} pr√≥bek, {len(np.unique(y_train_bal))} klas\")\n",
        "print(f\"   Test: {len(y_test)} pr√≥bek, {len(np.unique(y_test))} klas\")\n",
        "print(comparison_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 7: WIZUALIZACJA I ANALIZA DANYCH\n",
        "\n",
        "Wizualizujemy rozk≈Çad klas, statystyki opisowe, cechy i balans po SMOTE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 7: WIZUALIZACJA I ANALIZA DANYCH\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "1Ô∏è‚É£ SPRAWDZENIE ROZK≈ÅADU KLAS PO PODZIALE\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='label', ylabel='count'>"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Rozk≈Çad klas w Train i Test')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Klasa')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Liczba pr√≥bek')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x17c472120>"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '54'), Text(0, 3, '28')]"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '26'), Text(0, 3, '15')]"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Procentowy rozk≈Çad klas w Train i Test')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Klasa')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Procent pr√≥bek (%)')"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x31d212e40>"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '65.9%'), Text(0, 3, '34.1%')]"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '63.4%'), Text(0, 3, '36.6%')]"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä LICZBA PR√ìBEK PER KLASƒò:\n",
            "--------------------------------------------------------------------------------\n",
            "TRAIN:\n",
            "   baseline    :   54 pr√≥bek\n",
            "   emotion     :   28 pr√≥bek\n",
            "\n",
            "TEST:\n",
            "   baseline    :   26 pr√≥bek\n",
            "   emotion     :   15 pr√≥bek\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 7: WIZUALIZACJA I ANALIZA DANYCH\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 7: WIZUALIZACJA I ANALIZA DANYCH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'X_train' not in globals() or 'y_train' not in globals() or 'X_test' not in globals() or 'y_test' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 5 i KROK 6!\")\n",
        "    raise NameError(\"X_train, y_train, X_test, y_test nie sƒÖ zdefiniowane\")\n",
        "\n",
        "if 'X_train_bal' not in globals() or 'y_train_bal' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 6 (SMOTE)!\")\n",
        "    raise NameError(\"X_train_bal, y_train_bal nie sƒÖ zdefiniowane\")\n",
        "\n",
        "# 1Ô∏è‚É£ SPRAWDZENIE ROZK≈ÅADU KLAS PO PODZIALE\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"1Ô∏è‚É£ SPRAWDZENIE ROZK≈ÅADU KLAS PO PODZIALE\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Przygotuj dane do wizualizacji\n",
        "train_labels_df = pd.DataFrame({\n",
        "    'label': label_encoder.inverse_transform(y_train),\n",
        "    'set': 'Train'\n",
        "})\n",
        "test_labels_df = pd.DataFrame({\n",
        "    'label': label_encoder.inverse_transform(y_test),\n",
        "    'set': 'Test'\n",
        "})\n",
        "labels_df = pd.concat([train_labels_df, test_labels_df], ignore_index=True)\n",
        "\n",
        "# Wykres s≈Çupkowy liczby pr√≥bek w train i test dla ka≈ºdej klasy\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Wykres 1: Por√≥wnanie train vs test\n",
        "sns.countplot(data=labels_df, x='label', hue='set', ax=axes[0])\n",
        "axes[0].set_title('Rozk≈Çad klas w Train i Test', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Klasa', fontsize=12)\n",
        "axes[0].set_ylabel('Liczba pr√≥bek', fontsize=12)\n",
        "axes[0].legend(title='Zbi√≥r')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in axes[0].containers:\n",
        "    axes[0].bar_label(container, fmt='%d', rotation=0, padding=3)\n",
        "\n",
        "# Wykres 2: Procentowy rozk≈Çad\n",
        "train_pct = pd.Series(label_encoder.inverse_transform(y_train)).value_counts(normalize=True) * 100\n",
        "test_pct = pd.Series(label_encoder.inverse_transform(y_test)).value_counts(normalize=True) * 100\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Train': train_pct,\n",
        "    'Test': test_pct\n",
        "}).fillna(0)\n",
        "comparison_df.plot(kind='bar', ax=axes[1], rot=0, width=0.8)\n",
        "axes[1].set_title('Procentowy rozk≈Çad klas w Train i Test', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Klasa', fontsize=12)\n",
        "axes[1].set_ylabel('Procent pr√≥bek (%)', fontsize=12)\n",
        "axes[1].legend(title='Zbi√≥r')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container, fmt='%.1f%%', rotation=0, padding=3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wy≈õwietl liczby pr√≥bek\n",
        "print(f\"\\nüìä LICZBA PR√ìBEK PER KLASƒò:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"TRAIN:\")\n",
        "train_counts = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "for label in train_counts.index:\n",
        "    print(f\"   {label:12s}: {train_counts[label]:4d} pr√≥bek\")\n",
        "print(\"\\nTEST:\")\n",
        "test_counts = pd.Series(label_encoder.inverse_transform(y_test)).value_counts()\n",
        "for label in test_counts.index:\n",
        "    print(f\"   {label:12s}: {test_counts[label]:4d} pr√≥bek\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "2Ô∏è‚É£ STATYSTYKI OPISOWE\n",
            "================================================================================\n",
            "\n",
            "üìä BALANCE RATIO (przed SMOTE):\n",
            "   Balance ratio = min / max = 28 / 54 = 0.5185\n",
            "   Klasa wiƒôkszo≈õciowa: baseline (54 pr√≥bek)\n",
            "   Klasa mniejszo≈õciowa: emotion (28 pr√≥bek)\n",
            "\n",
            "üìä BALANCE RATIO (po SMOTE):\n",
            "   Balance ratio = min / max = 54 / 54 = 1.0000\n",
            "   Klasa wiƒôkszo≈õciowa: baseline (54 pr√≥bek)\n",
            "   Klasa mniejszo≈õciowa: baseline (54 pr√≥bek)\n",
            "\n",
            "üìä STATYSTYKI OPISOWE CECH:\n",
            "--------------------------------------------------------------------------------\n",
            "   Train shape: (82, 60)\n",
            "   Test shape: (41, 60)\n",
            "   Train (po SMOTE) shape: (108, 60)\n",
            "\n",
            "üìä STATYSTYKI DLA PRZYK≈ÅADOWYCH CECH (pierwsze 10):\n",
            "--------------------------------------------------------------------------------\n",
            "                count      mean       std       min       25%       50%  \\\n",
            "acc_x_mean       82.0  0.048685  0.946139 -1.458405 -0.640204 -0.048435   \n",
            "acc_x_std        82.0 -0.167155  0.988893 -0.794712 -0.756888 -0.696232   \n",
            "acc_x_min        82.0  0.191348  0.974458 -2.377571 -0.695230  0.399755   \n",
            "acc_x_max        82.0 -0.054366  0.912658 -1.492697 -0.484264 -0.327835   \n",
            "acc_x_range      82.0 -0.201484  0.924752 -0.796706 -0.763844 -0.677642   \n",
            "acc_x_rms        82.0 -0.200131  1.098925 -1.678095 -1.362892 -0.072776   \n",
            "acc_x_kurtosis   82.0 -0.009926  0.991886 -0.499398 -0.386788 -0.281463   \n",
            "acc_x_skewness   82.0  0.014780  0.988744 -4.451020 -0.238760  0.014307   \n",
            "acc_x_rmssd      82.0 -0.277650  0.731041 -0.728198 -0.657787 -0.585920   \n",
            "acc_x_slope      82.0  0.070561  0.893602 -2.242241 -0.191628 -0.173138   \n",
            "\n",
            "                     75%       max  \n",
            "acc_x_mean      0.708935  1.644163  \n",
            "acc_x_std       0.170665  3.346450  \n",
            "acc_x_min       0.623303  1.771928  \n",
            "acc_x_max       0.713325  2.037421  \n",
            "acc_x_range     0.048357  3.306872  \n",
            "acc_x_rms       0.785231  1.437291  \n",
            "acc_x_kurtosis -0.098742  6.665897  \n",
            "acc_x_skewness  0.307432  2.808241  \n",
            "acc_x_rmssd    -0.217418  3.312475  \n",
            "acc_x_slope     0.004905  3.512836  \n"
          ]
        }
      ],
      "source": [
        "# 2Ô∏è‚É£ STATYSTYKI OPISOWE\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"2Ô∏è‚É£ STATYSTYKI OPISOWE\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Balance ratio przed SMOTE\n",
        "train_counts = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "if len(train_counts) >= 2:\n",
        "    balance_ratio_before = min(train_counts.values) / max(train_counts.values)\n",
        "    print(f\"\\nüìä BALANCE RATIO (przed SMOTE):\")\n",
        "    print(f\"   Balance ratio = min / max = {min(train_counts.values)} / {max(train_counts.values)} = {balance_ratio_before:.4f}\")\n",
        "    print(f\"   Klasa wiƒôkszo≈õciowa: {train_counts.idxmax()} ({max(train_counts.values)} pr√≥bek)\")\n",
        "    print(f\"   Klasa mniejszo≈õciowa: {train_counts.idxmin()} ({min(train_counts.values)} pr√≥bek)\")\n",
        "\n",
        "# Balance ratio po SMOTE\n",
        "if 'y_train_bal' in globals():\n",
        "    train_bal_counts = pd.Series(label_encoder.inverse_transform(y_train_bal)).value_counts()\n",
        "    if len(train_bal_counts) >= 2:\n",
        "        balance_ratio_after = min(train_bal_counts.values) / max(train_bal_counts.values)\n",
        "        print(f\"\\nüìä BALANCE RATIO (po SMOTE):\")\n",
        "        print(f\"   Balance ratio = min / max = {min(train_bal_counts.values)} / {max(train_bal_counts.values)} = {balance_ratio_after:.4f}\")\n",
        "        print(f\"   Klasa wiƒôkszo≈õciowa: {train_bal_counts.idxmax()} ({max(train_bal_counts.values)} pr√≥bek)\")\n",
        "        print(f\"   Klasa mniejszo≈õciowa: {train_bal_counts.idxmin()} ({min(train_bal_counts.values)} pr√≥bek)\")\n",
        "\n",
        "# Statystyki opisowe cech\n",
        "print(f\"\\nüìä STATYSTYKI OPISOWE CECH:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"   Train shape: {X_train.shape}\")\n",
        "print(f\"   Test shape: {X_test.shape}\")\n",
        "if 'X_train_bal' in globals():\n",
        "    print(f\"   Train (po SMOTE) shape: {X_train_bal.shape}\")\n",
        "\n",
        "# Wybierz kilka przyk≈Çadowych cech do wy≈õwietlenia statystyk\n",
        "if isinstance(X_train, pd.DataFrame):\n",
        "    feature_cols = X_train.columns.tolist()\n",
        "    n_features_to_show = min(10, len(feature_cols))\n",
        "    sample_features = feature_cols[:n_features_to_show]\n",
        "    \n",
        "    print(f\"\\nüìä STATYSTYKI DLA PRZYK≈ÅADOWYCH CECH (pierwsze {n_features_to_show}):\")\n",
        "    print(\"-\" * 80)\n",
        "    stats_df = X_train[sample_features].describe().T\n",
        "    print(stats_df)\n",
        "else:\n",
        "    print(f\"\\nüìä STATYSTYKI DLA WSZYSTKICH CECH:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"   ≈örednia: {np.mean(X_train, axis=0)[:5]}...\")\n",
        "    print(f\"   Odchylenie std: {np.std(X_train, axis=0)[:5]}...\")\n",
        "    print(f\"   Min: {np.min(X_train, axis=0)[:5]}...\")\n",
        "    print(f\"   Max: {np.max(X_train, axis=0)[:5]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "3Ô∏è‚É£ WIZUALIZACJA CECH\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Wybierz kilka cech do wizualizacji\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X_train, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m      8\u001b[0m     feature_cols \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      9\u001b[0m     n_features_to_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_cols))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "# 3Ô∏è‚É£ WIZUALIZACJA CECH\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"3Ô∏è‚É£ WIZUALIZACJA CECH\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Wybierz kilka cech do wizualizacji\n",
        "if isinstance(X_train, pd.DataFrame):\n",
        "    feature_cols = X_train.columns.tolist()\n",
        "    n_features_to_plot = min(6, len(feature_cols))\n",
        "    features_to_plot = feature_cols[:n_features_to_plot]\n",
        "    \n",
        "    # Histogramy dla wybranych cech\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature in enumerate(features_to_plot):\n",
        "        if idx < len(axes):\n",
        "            X_train[feature].hist(bins=50, ax=axes[idx], alpha=0.7, label='Train')\n",
        "            if isinstance(X_test, pd.DataFrame):\n",
        "                X_test[feature].hist(bins=50, ax=axes[idx], alpha=0.7, label='Test')\n",
        "            axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
        "            axes[idx].set_xlabel('Warto≈õƒá', fontsize=10)\n",
        "            axes[idx].set_ylabel('Czƒôsto≈õƒá', fontsize=10)\n",
        "            axes[idx].legend()\n",
        "            axes[idx].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Ukryj puste subploty\n",
        "    for idx in range(len(features_to_plot), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Histogramy wybranych cech (Train vs Test)', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Boxploty dla wybranych cech\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature in enumerate(features_to_plot):\n",
        "        if idx < len(axes):\n",
        "            data_to_plot = [X_train[feature].dropna(), X_test[feature].dropna() if isinstance(X_test, pd.DataFrame) else X_test[:, feature_cols.index(feature)]]\n",
        "            axes[idx].boxplot(data_to_plot, labels=['Train', 'Test'])\n",
        "            axes[idx].set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
        "            axes[idx].set_ylabel('Warto≈õƒá', fontsize=10)\n",
        "            axes[idx].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Ukryj puste subploty\n",
        "    for idx in range(len(features_to_plot), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Boxploty wybranych cech (Train vs Test)', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Heatmapa korelacji (tylko dla pierwszych 20 cech, ≈ºeby nie by≈Ço za du≈ºo)\n",
        "    n_features_corr = min(20, len(feature_cols))\n",
        "    features_for_corr = feature_cols[:n_features_corr]\n",
        "    \n",
        "    print(f\"\\nüìä HEATMAPA KORELACJI (pierwsze {n_features_corr} cech):\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    corr_matrix = X_train[features_for_corr].corr()\n",
        "    plt.figure(figsize=(14, 12))\n",
        "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
        "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title(f'Macierz korelacji cech (Train, pierwsze {n_features_corr} cech)', \n",
        "              fontsize=14, fontweight='bold', pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"   ‚úÖ Wizualizacja cech zako≈Ñczona\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è X_train nie jest DataFrame - pomijam szczeg√≥≈Çowe wizualizacje cech\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "4Ô∏è‚É£ WIZUALIZACJA BALANSU PO SMOTE\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Por√≥wnanie liczby pr√≥bek w train przed i po SMOTE\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_before_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_train))\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      8\u001b[0m train_after_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_train_bal))\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Przygotuj dane do wizualizacji\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# 4Ô∏è‚É£ WIZUALIZACJA BALANSU PO SMOTE\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"4Ô∏è‚É£ WIZUALIZACJA BALANSU PO SMOTE\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Por√≥wnanie liczby pr√≥bek w train przed i po SMOTE\n",
        "train_before_counts = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "train_after_counts = pd.Series(label_encoder.inverse_transform(y_train_bal)).value_counts()\n",
        "\n",
        "# Przygotuj dane do wizualizacji\n",
        "comparison_data = []\n",
        "for label in train_before_counts.index:\n",
        "    comparison_data.append({\n",
        "        'Klasa': label,\n",
        "        'Przed SMOTE': train_before_counts[label],\n",
        "        'Po SMOTE': train_after_counts.get(label, 0)\n",
        "    })\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Funkcja konwertujƒÖca kolumny na int\n",
        "def convert_to_int(df):\n",
        "    df_copy = df.copy()\n",
        "    for col in df_copy.columns:\n",
        "        if col != 'Klasa':  # Pomijamy kolumnƒô 'Klasa' (nie numeryczna)\n",
        "            # Najpierw konwertujemy na liczby (float), co rozwiƒÖzuje problem string√≥w\n",
        "            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
        "            # Zamieniamy NaN na 0\n",
        "            df_copy[col] = df_copy[col].fillna(0)\n",
        "            # ZaokrƒÖglamy do najbli≈ºszej liczby ca≈Çkowitej i zmieniamy typ na int\n",
        "            df_copy[col] = df_copy[col].round(0).astype(int)\n",
        "    return df_copy\n",
        "\n",
        "# Zastosowanie funkcji do DataFrame\n",
        "comparison_df = convert_to_int(comparison_df)\n",
        "\n",
        "# Sprawdzenie wynik√≥w\n",
        "print(f\"\\nüìä TYPY DANYCH W comparison_df:\")\n",
        "print(comparison_df.dtypes)\n",
        "print(f\"\\nüìä PIERWSZE WIERSZE comparison_df:\")\n",
        "print(comparison_df.head())\n",
        "\n",
        "# Wykres s≈Çupkowy\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Wykres 1: Liczby bezwzglƒôdne\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.35\n",
        "axes[0].bar(x - width/2, comparison_df['Przed SMOTE'], width, label='Przed SMOTE', alpha=0.8)\n",
        "axes[0].bar(x + width/2, comparison_df['Po SMOTE'], width, label='Po SMOTE', alpha=0.8)\n",
        "axes[0].set_xlabel('Klasa', fontsize=12)\n",
        "axes[0].set_ylabel('Liczba pr√≥bek', fontsize=12)\n",
        "axes[0].set_title('Liczba pr√≥bek przed i po SMOTE', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(comparison_df['Klasa'])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Dodaj warto≈õci na s≈Çupkach (naprawione obliczanie maksimum)\n",
        "max_value = max(comparison_df['Przed SMOTE'].max(), comparison_df['Po SMOTE'].max())\n",
        "for i, row in comparison_df.iterrows():\n",
        "    przed_val = int(row['Przed SMOTE'])\n",
        "    po_val = int(row['Po SMOTE'])\n",
        "    axes[0].text(i - width/2, przed_val + max_value * 0.01, \n",
        "                 f\"{przed_val}\", ha='center', va='bottom', fontsize=9)\n",
        "    axes[0].text(i + width/2, po_val + max_value * 0.01, \n",
        "                 f\"{po_val}\", ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Wykres 2: Procenty\n",
        "train_before_pct = train_before_counts / len(y_train) * 100\n",
        "train_after_pct = train_after_counts / len(y_train_bal) * 100\n",
        "pct_comparison_df = pd.DataFrame({\n",
        "    'Przed SMOTE': train_before_pct,\n",
        "    'Po SMOTE': train_after_pct\n",
        "}).fillna(0)\n",
        "pct_comparison_df.plot(kind='bar', ax=axes[1], rot=0, width=0.8)\n",
        "axes[1].set_xlabel('Klasa', fontsize=12)\n",
        "axes[1].set_ylabel('Procent pr√≥bek (%)', fontsize=12)\n",
        "axes[1].set_title('Procentowy rozk≈Çad klas przed i po SMOTE', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container, fmt='%.1f%%', rotation=0, padding=3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wy≈õwietl szczeg√≥≈Çy\n",
        "print(f\"\\nüìä SZCZEG√ì≈ÅOWE POR√ìWNANIE:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"PRZED SMOTE:\")\n",
        "for label in train_before_counts.index:\n",
        "    count = train_before_counts[label]\n",
        "    pct = (count / len(y_train) * 100) if len(y_train) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "print(f\"\\nPO SMOTE:\")\n",
        "for label in train_after_counts.index:\n",
        "    count = train_after_counts[label]\n",
        "    pct = (count / len(y_train_bal) * 100) if len(y_train_bal) > 0 else 0\n",
        "    print(f\"   {label:12s}: {count:4d} pr√≥bek ({pct:5.1f}%)\")\n",
        "print(f\"\\n   Train przed SMOTE: {len(y_train)} pr√≥bek\")\n",
        "print(f\"   Train po SMOTE: {len(y_train_bal)} pr√≥bek\")\n",
        "print(f\"   Dodano: {len(y_train_bal) - len(y_train)} syntetycznych pr√≥bek\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "5Ô∏è‚É£ ANALIZA PER SUBJECT\n",
            "================================================================================\n",
            "   ‚ö†Ô∏è groups_train lub groups_test nie sƒÖ dostƒôpne - pomijam analizƒô per subject\n"
          ]
        }
      ],
      "source": [
        "# 5Ô∏è‚É£ ANALIZA PER SUBJECT\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"5Ô∏è‚É£ ANALIZA PER SUBJECT\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Sprawd≈∫ rozk≈Çad klas per subject w train i test\n",
        "if 'groups_train' in globals() and 'groups_test' in globals():\n",
        "    # Przygotuj dane per subject\n",
        "    train_subjects_list = groups_train if isinstance(groups_train, list) else list(groups_train)\n",
        "    test_subjects_list = groups_test if isinstance(groups_test, list) else list(groups_test)\n",
        "    \n",
        "    # Train per subject\n",
        "    train_subject_df = pd.DataFrame({\n",
        "        'subject': train_subjects_list,\n",
        "        'label': label_encoder.inverse_transform(y_train)\n",
        "    })\n",
        "    \n",
        "    # Test per subject\n",
        "    test_subject_df = pd.DataFrame({\n",
        "        'subject': test_subjects_list,\n",
        "        'label': label_encoder.inverse_transform(y_test)\n",
        "    })\n",
        "    \n",
        "    # Wykres per subject\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Train per subject\n",
        "    train_subject_counts = train_subject_df.groupby(['subject', 'label']).size().unstack(fill_value=0)\n",
        "    train_subject_counts.plot(kind='bar', ax=axes[0], rot=0, width=0.8)\n",
        "    axes[0].set_title('Rozk≈Çad klas per subject - TRAIN', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Subject', fontsize=12)\n",
        "    axes[0].set_ylabel('Liczba pr√≥bek', fontsize=12)\n",
        "    axes[0].legend(title='Klasa', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Test per subject\n",
        "    test_subject_counts = test_subject_df.groupby(['subject', 'label']).size().unstack(fill_value=0)\n",
        "    test_subject_counts.plot(kind='bar', ax=axes[1], rot=0, width=0.8)\n",
        "    axes[1].set_title('Rozk≈Çad klas per subject - TEST', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Subject', fontsize=12)\n",
        "    axes[1].set_ylabel('Liczba pr√≥bek', fontsize=12)\n",
        "    axes[1].legend(title='Klasa', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Wy≈õwietl szczeg√≥≈Çy per subject\n",
        "    print(f\"\\nüìä ROZK≈ÅAD KLAS PER SUBJECT:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"TRAIN:\")\n",
        "    for subject in sorted(train_subject_df['subject'].unique()):\n",
        "        subject_data = train_subject_df[train_subject_df['subject'] == subject]\n",
        "        label_dist = subject_data['label'].value_counts()\n",
        "        print(f\"\\n  {subject}:\")\n",
        "        for label in label_dist.index:\n",
        "            print(f\"    {label:12s}: {label_dist[label]:4d} pr√≥bek\")\n",
        "    \n",
        "    print(f\"\\nTEST:\")\n",
        "    for subject in sorted(test_subject_df['subject'].unique()):\n",
        "        subject_data = test_subject_df[test_subject_df['subject'] == subject]\n",
        "        label_dist = subject_data['label'].value_counts()\n",
        "        print(f\"\\n  {subject}:\")\n",
        "        for label in label_dist.index:\n",
        "            print(f\"    {label:12s}: {label_dist[label]:4d} pr√≥bek\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è groups_train lub groups_test nie sƒÖ dostƒôpne - pomijam analizƒô per subject\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 8: TRENOWANIE MODELI ML\n",
        "\n",
        "Trenujemy modele: Logistic Regression, Random Forest, XGBoost, SVM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 8: TRENOWANIE MODELI ML\n",
            "================================================================================\n",
            "\n",
            "‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 6 (SMOTE)!\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "X_train_bal, y_train_bal nie sƒÖ zdefiniowane",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train_bal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train_bal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 6 (SMOTE)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train_bal, y_train_bal nie sƒÖ zdefiniowane\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Konwertuj na numpy array je≈õli potrzeba\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X_train_bal, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n",
            "\u001b[0;31mNameError\u001b[0m: X_train_bal, y_train_bal nie sƒÖ zdefiniowane"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 8: TRENOWANIE MODELI ML\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 8: TRENOWANIE MODELI ML\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'X_train_bal' not in globals() or 'y_train_bal' not in globals():\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 6 (SMOTE)!\")\n",
        "    raise NameError(\"X_train_bal, y_train_bal nie sƒÖ zdefiniowane\")\n",
        "\n",
        "# Konwertuj na numpy array je≈õli potrzeba\n",
        "if isinstance(X_train_bal, pd.DataFrame):\n",
        "    X_train_bal_array = X_train_bal.values\n",
        "    X_test_array = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
        "else:\n",
        "    X_train_bal_array = X_train_bal\n",
        "    X_test_array = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
        "\n",
        "print(f\"\\nüìä PRZYGOTOWANIE DANYCH:\")\n",
        "print(f\"   X_train_bal shape: {X_train_bal_array.shape}\")\n",
        "print(f\"   y_train_bal shape: {y_train_bal.shape}\")\n",
        "print(f\"   X_test shape: {X_test_array.shape}\")\n",
        "print(f\"   y_test shape: {y_test.shape}\")\n",
        "\n",
        "# S≈Çownik do przechowywania wynik√≥w modeli\n",
        "results = {}\n",
        "\n",
        "# 1. Logistic Regression\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"1. LOGISTIC REGRESSION\")\n",
        "print(f\"{'='*80}\")\n",
        "try:\n",
        "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42, n_jobs=-1)\n",
        "    print(\"   üîß Trenujƒô model...\")\n",
        "    lr.fit(X_train_bal_array, y_train_bal)\n",
        "    y_pred_lr = lr.predict(X_test_array)\n",
        "    \n",
        "    acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "    bal_acc_lr = balanced_accuracy_score(y_test, y_pred_lr)\n",
        "    macro_f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
        "    cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "    \n",
        "    results['LogisticRegression'] = {\n",
        "        'model': lr,\n",
        "        'y_pred': y_pred_lr,\n",
        "        'accuracy': acc_lr,\n",
        "        'balanced_accuracy': bal_acc_lr,\n",
        "        'macro_f1': macro_f1_lr,\n",
        "        'confusion_matrix': cm_lr,\n",
        "        'classification_report': classification_report(y_test, y_pred_lr, \n",
        "                                                         target_names=label_encoder.classes_, \n",
        "                                                         output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "    print(f\"      Accuracy: {acc_lr:.4f}\")\n",
        "    print(f\"      Balanced Accuracy: {bal_acc_lr:.4f}\")\n",
        "    print(f\"      Macro F1: {macro_f1_lr:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
        "\n",
        "# 2. Random Forest\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"2. RANDOM FOREST\")\n",
        "print(f\"{'='*80}\")\n",
        "try:\n",
        "    rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, \n",
        "                                random_state=42, n_jobs=-1, max_depth=10)\n",
        "    print(\"   üîß Trenujƒô model...\")\n",
        "    rf.fit(X_train_bal_array, y_train_bal)\n",
        "    y_pred_rf = rf.predict(X_test_array)\n",
        "    \n",
        "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "    bal_acc_rf = balanced_accuracy_score(y_test, y_pred_rf)\n",
        "    macro_f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
        "    cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "    \n",
        "    results['RandomForest'] = {\n",
        "        'model': rf,\n",
        "        'y_pred': y_pred_rf,\n",
        "        'accuracy': acc_rf,\n",
        "        'balanced_accuracy': bal_acc_rf,\n",
        "        'macro_f1': macro_f1_rf,\n",
        "        'confusion_matrix': cm_rf,\n",
        "        'classification_report': classification_report(y_test, y_pred_rf, \n",
        "                                                       target_names=label_encoder.classes_, \n",
        "                                                       output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "    print(f\"      Accuracy: {acc_rf:.4f}\")\n",
        "    print(f\"      Balanced Accuracy: {bal_acc_rf:.4f}\")\n",
        "    print(f\"      Macro F1: {macro_f1_rf:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
        "\n",
        "# 3. XGBoost\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"3. XGBOOST\")\n",
        "print(f\"{'='*80}\")\n",
        "if XGBOOST_AVAILABLE:\n",
        "    try:\n",
        "        xgb = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
        "        print(\"   üîß Trenujƒô model...\")\n",
        "        xgb.fit(X_train_bal_array, y_train_bal)\n",
        "        y_pred_xgb = xgb.predict(X_test_array)\n",
        "        \n",
        "        acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "        bal_acc_xgb = balanced_accuracy_score(y_test, y_pred_xgb)\n",
        "        macro_f1_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
        "        cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "        \n",
        "        results['XGBoost'] = {\n",
        "            'model': xgb,\n",
        "            'y_pred': y_pred_xgb,\n",
        "            'accuracy': acc_xgb,\n",
        "            'balanced_accuracy': bal_acc_xgb,\n",
        "            'macro_f1': macro_f1_xgb,\n",
        "            'confusion_matrix': cm_xgb,\n",
        "            'classification_report': classification_report(y_test, y_pred_xgb, \n",
        "                                                           target_names=label_encoder.classes_, \n",
        "                                                           output_dict=True)\n",
        "        }\n",
        "        \n",
        "        print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "        print(f\"      Accuracy: {acc_xgb:.4f}\")\n",
        "        print(f\"      Balanced Accuracy: {bal_acc_xgb:.4f}\")\n",
        "        print(f\"      Macro F1: {macro_f1_xgb:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è XGBoost niedostƒôpny - pomijam\")\n",
        "\n",
        "# 4. SVM\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"4. SVM\")\n",
        "print(f\"{'='*80}\")\n",
        "try:\n",
        "    svm = SVC(class_weight='balanced', random_state=42, probability=True)\n",
        "    print(\"   üîß Trenujƒô model...\")\n",
        "    svm.fit(X_train_bal_array, y_train_bal)\n",
        "    y_pred_svm = svm.predict(X_test_array)\n",
        "    \n",
        "    acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "    bal_acc_svm = balanced_accuracy_score(y_test, y_pred_svm)\n",
        "    macro_f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
        "    cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "    \n",
        "    results['SVM'] = {\n",
        "        'model': svm,\n",
        "        'y_pred': y_pred_svm,\n",
        "        'accuracy': acc_svm,\n",
        "        'balanced_accuracy': bal_acc_svm,\n",
        "        'macro_f1': macro_f1_svm,\n",
        "        'confusion_matrix': cm_svm,\n",
        "        'classification_report': classification_report(y_test, y_pred_svm, \n",
        "                                                        target_names=label_encoder.classes_, \n",
        "                                                        output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "    print(f\"      Accuracy: {acc_svm:.4f}\")\n",
        "    print(f\"      Balanced Accuracy: {bal_acc_svm:.4f}\")\n",
        "    print(f\"      Macro F1: {macro_f1_svm:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
        "\n",
        "# 5. Ensemble Voting Classifier\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"5. ENSEMBLE VOTING CLASSIFIER\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "try:\n",
        "    from sklearn.ensemble import VotingClassifier\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    \n",
        "    # Tworzymy pojedyncze modele\n",
        "    logreg_ensemble = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
        "    rf_ensemble = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
        "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "    \n",
        "    # ≈ÅƒÖczymy je w VotingClassifier (soft voting - u≈ºywamy prawdopodobie≈Ñstw)\n",
        "    ensemble = VotingClassifier(\n",
        "        estimators=[('logreg', logreg_ensemble), ('rf', rf_ensemble), ('knn', knn)],\n",
        "        voting='soft'  # soft - ≈õrednie prawdopodobie≈Ñstwa, hard - g≈Çosowanie wiƒôkszo≈õciowe\n",
        "    )\n",
        "    \n",
        "    print(\"   üîß Trenujƒô ensemble model...\")\n",
        "    print(\"      Sk≈Çadniki: LogisticRegression + RandomForest + KNeighborsClassifier\")\n",
        "    print(\"      Voting: soft (≈õrednie prawdopodobie≈Ñstwa)\")\n",
        "    ensemble.fit(X_train_bal_array, y_train_bal)\n",
        "    y_pred_ensemble = ensemble.predict(X_test_array)\n",
        "    \n",
        "    acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "    bal_acc_ensemble = balanced_accuracy_score(y_test, y_pred_ensemble)\n",
        "    macro_f1_ensemble = f1_score(y_test, y_pred_ensemble, average='macro')\n",
        "    cm_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
        "    \n",
        "    results['Ensemble'] = {\n",
        "        'model': ensemble,\n",
        "        'y_pred': y_pred_ensemble,\n",
        "        'accuracy': acc_ensemble,\n",
        "        'balanced_accuracy': bal_acc_ensemble,\n",
        "        'macro_f1': macro_f1_ensemble,\n",
        "        'confusion_matrix': cm_ensemble,\n",
        "        'classification_report': classification_report(y_test, y_pred_ensemble, \n",
        "                                                        target_names=label_encoder.classes_, \n",
        "                                                        output_dict=True)\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "    print(f\"      Accuracy: {acc_ensemble:.4f}\")\n",
        "    print(f\"      Balanced Accuracy: {bal_acc_ensemble:.4f}\")\n",
        "    print(f\"      Macro F1: {macro_f1_ensemble:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå B≈ÇƒÖd: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 6. LSTM (Time Series Model)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"6. LSTM (TIME SERIES MODEL)\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    try:\n",
        "        # Przygotowanie danych dla LSTM\n",
        "        # LSTM wymaga danych w formacie (samples, timesteps, features)\n",
        "        # Poniewa≈º mamy ju≈º statystyczne cechy z okien, traktujemy ka≈ºdƒÖ pr√≥bkƒô jako sekwencjƒô d≈Çugo≈õci 1\n",
        "        # Reshape: (samples, features) -> (samples, 1, features)\n",
        "        X_train_lstm = X_train_bal_array.reshape(X_train_bal_array.shape[0], 1, X_train_bal_array.shape[1])\n",
        "        X_test_lstm = X_test_array.reshape(X_test_array.shape[0], 1, X_test_array.shape[1])\n",
        "        \n",
        "        # Konwersja etykiet do kategorii (one-hot encoding dla LSTM)\n",
        "        n_classes = len(np.unique(y_train_bal))\n",
        "        y_train_lstm = to_categorical(y_train_bal, num_classes=n_classes)\n",
        "        y_test_lstm = to_categorical(y_test, num_classes=n_classes)\n",
        "        \n",
        "        print(f\"   üìä Przygotowanie danych dla LSTM:\")\n",
        "        print(f\"      X_train_lstm shape: {X_train_lstm.shape} (samples, timesteps=1, features)\")\n",
        "        print(f\"      X_test_lstm shape: {X_test_lstm.shape}\")\n",
        "        print(f\"      y_train_lstm shape: {y_train_lstm.shape} (one-hot encoded)\")\n",
        "        print(f\"      y_test_lstm shape: {y_test_lstm.shape}\")\n",
        "        \n",
        "        # Budowa modelu LSTM\n",
        "        print(f\"   üîß Budujƒô model LSTM...\")\n",
        "        lstm_model = Sequential([\n",
        "            LSTM(64, activation='relu', input_shape=(1, X_train_bal_array.shape[1]), return_sequences=True),\n",
        "            Dropout(0.3),\n",
        "            LSTM(32, activation='relu', return_sequences=False),\n",
        "            Dropout(0.3),\n",
        "            BatchNormalization(),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(n_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        # Kompilacja modelu\n",
        "        lstm_model.compile(\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        \n",
        "        print(f\"   üìã Architektura modelu:\")\n",
        "        lstm_model.summary()\n",
        "        \n",
        "        # Callback dla early stopping\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        # Trenowanie modelu\n",
        "        print(f\"   üîß Trenujƒô model LSTM...\")\n",
        "        print(f\"      Epochs: 50, Batch size: 16, Validation split: 0.2\")\n",
        "        \n",
        "        history = lstm_model.fit(\n",
        "            X_train_lstm, y_train_lstm,\n",
        "            epochs=50,\n",
        "            batch_size=16,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0  # Wy≈ÇƒÖcz szczeg√≥≈Çowe logi podczas treningu\n",
        "        )\n",
        "        \n",
        "        # Predykcja\n",
        "        y_pred_proba_lstm = lstm_model.predict(X_test_lstm, verbose=0)\n",
        "        y_pred_lstm = np.argmax(y_pred_proba_lstm, axis=1)\n",
        "        \n",
        "        # Oblicz metryki\n",
        "        acc_lstm = accuracy_score(y_test, y_pred_lstm)\n",
        "        bal_acc_lstm = balanced_accuracy_score(y_test, y_pred_lstm)\n",
        "        macro_f1_lstm = f1_score(y_test, y_pred_lstm, average='macro')\n",
        "        cm_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
        "        \n",
        "        results['LSTM'] = {\n",
        "            'model': lstm_model,\n",
        "            'y_pred': y_pred_lstm,\n",
        "            'accuracy': acc_lstm,\n",
        "            'balanced_accuracy': bal_acc_lstm,\n",
        "            'macro_f1': macro_f1_lstm,\n",
        "            'confusion_matrix': cm_lstm,\n",
        "            'classification_report': classification_report(y_test, y_pred_lstm, \n",
        "                                                           target_names=label_encoder.classes_, \n",
        "                                                           output_dict=True),\n",
        "            'history': history.history  # Historia treningu dla wizualizacji\n",
        "        }\n",
        "        \n",
        "        print(f\"   ‚úÖ Trenowanie zako≈Ñczone!\")\n",
        "        print(f\"      Accuracy: {acc_lstm:.4f}\")\n",
        "        print(f\"      Balanced Accuracy: {bal_acc_lstm:.4f}\")\n",
        "        print(f\"      Macro F1: {macro_f1_lstm:.4f}\")\n",
        "        print(f\"      Liczba epok: {len(history.history['loss'])}\")\n",
        "        \n",
        "        # Wizualizacja historii treningu\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "        \n",
        "        # Loss\n",
        "        axes[0].plot(history.history['loss'], label='Train Loss', marker='o')\n",
        "        axes[0].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Loss')\n",
        "        axes[0].set_title('LSTM Training History - Loss')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Accuracy\n",
        "        axes[1].plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
        "        axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Accuracy')\n",
        "        axes[1].set_title('LSTM Training History - Accuracy')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå B≈ÇƒÖd podczas trenowania LSTM: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è TensorFlow/Keras niedostƒôpny - pomijam LSTM\")\n",
        "    print(f\"   üí° Zainstaluj: pip install tensorflow\")\n",
        "\n",
        "print(f\"\\n‚úÖ Trenowanie wszystkich modeli zako≈Ñczone!\")\n",
        "print(f\"   Wytrenowano {len(results)} modeli\")\n",
        "\n",
        "# ============================================================================\n",
        "# WYB√ìR TOP 10 NAJWA≈ªNIEJSZYCH CECH (dla Streamlit app)\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"WYB√ìR TOP 10 NAJWA≈ªNIEJSZYCH CECH\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Pobierz feature importance z RandomForest lub XGBoost\n",
        "top_10_features = None\n",
        "feature_importance_dict = None\n",
        "\n",
        "# Spr√≥buj z RandomForest\n",
        "if 'RandomForest' in results:\n",
        "    try:\n",
        "        rf_model = results['RandomForest']['model']\n",
        "        if hasattr(rf_model, 'feature_importances_'):\n",
        "            feature_importance = rf_model.feature_importances_\n",
        "            feature_names_list = X_train.columns.tolist() if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
        "            \n",
        "            # Stw√≥rz DataFrame z importance\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names_list,\n",
        "                'importance': feature_importance\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            \n",
        "            # Wybierz top 10\n",
        "            top_10_features = importance_df.head(10)['feature'].tolist()\n",
        "            feature_importance_dict = dict(zip(importance_df['feature'], importance_df['importance']))\n",
        "            \n",
        "            print(f\"\\n‚úÖ U≈ºyto RandomForest do wyboru top 10 cech\")\n",
        "            print(f\"\\nüìä TOP 10 NAJWA≈ªNIEJSZYCH CECH:\")\n",
        "            print(\"-\" * 80)\n",
        "            for i, feat in enumerate(top_10_features, 1):\n",
        "                importance_val = feature_importance_dict[feat]\n",
        "                print(f\"   {i:2d}. {feat:30s}: {importance_val:.6f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è B≈ÇƒÖd przy RandomForest: {e}\")\n",
        "\n",
        "# Je≈õli RandomForest nie zadzia≈Ça≈Ç, spr√≥buj z XGBoost\n",
        "if top_10_features is None and 'XGBoost' in results:\n",
        "    try:\n",
        "        xgb_model = results['XGBoost']['model']\n",
        "        if hasattr(xgb_model, 'feature_importances_'):\n",
        "            feature_importance = xgb_model.feature_importances_\n",
        "            feature_names_list = X_train.columns.tolist() if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
        "            \n",
        "            # Stw√≥rz DataFrame z importance\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names_list,\n",
        "                'importance': feature_importance\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            \n",
        "            # Wybierz top 10\n",
        "            top_10_features = importance_df.head(10)['feature'].tolist()\n",
        "            feature_importance_dict = dict(zip(importance_df['feature'], importance_df['importance']))\n",
        "            \n",
        "            print(f\"\\n‚úÖ U≈ºyto XGBoost do wyboru top 10 cech\")\n",
        "            print(f\"\\nüìä TOP 10 NAJWA≈ªNIEJSZYCH CECH:\")\n",
        "            print(\"-\" * 80)\n",
        "            for i, feat in enumerate(top_10_features, 1):\n",
        "                importance_val = feature_importance_dict[feat]\n",
        "                print(f\"   {i:2d}. {feat:30s}: {importance_val:.6f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è B≈ÇƒÖd przy XGBoost: {e}\")\n",
        "\n",
        "# Je≈õli ≈ºaden model nie zadzia≈Ça≈Ç, u≈ºyj pierwszych 10 cech\n",
        "if top_10_features is None:\n",
        "    feature_names_list = X_train.columns.tolist() if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
        "    top_10_features = feature_names_list[:10]\n",
        "    print(f\"\\n‚ö†Ô∏è Nie mo≈ºna pobraƒá feature importance - u≈ºywam pierwszych 10 cech\")\n",
        "    print(f\"   Top 10 cech: {top_10_features}\")\n",
        "\n",
        "# Zapisz top 10 cech do zmiennej globalnej\n",
        "globals()['top_10_features'] = top_10_features\n",
        "globals()['feature_importance_dict'] = feature_importance_dict\n",
        "\n",
        "print(f\"\\n‚úÖ Top 10 cech wybrane i zapisane!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 9: EWALUACJA MODELI\n",
        "\n",
        "Por√≥wnujemy wyniki wszystkich modeli: Accuracy, Balanced Accuracy, Macro F1, Confusion Matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 9: EWALUACJA MODELI\n",
            "================================================================================\n",
            "\n",
            "‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 8 (trenowanie modeli)!\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "results nie sƒÖ zdefiniowane",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 8 (trenowanie modeli)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults nie sƒÖ zdefiniowane\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 1. Por√≥wnanie metryk globalnych\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: results nie sƒÖ zdefiniowane"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 9: EWALUACJA MODELI\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 9: EWALUACJA MODELI\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'results' not in globals() or len(results) == 0:\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 8 (trenowanie modeli)!\")\n",
        "    raise NameError(\"results nie sƒÖ zdefiniowane\")\n",
        "\n",
        "# 1. Por√≥wnanie metryk globalnych\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"1. POR√ìWNANIE METRYK GLOBALNYCH\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "metrics_summary = []\n",
        "for model_name, result in results.items():\n",
        "    metrics_summary.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': result['accuracy'],\n",
        "        'Balanced Accuracy': result['balanced_accuracy'],\n",
        "        'Macro F1': result['macro_f1']\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "print(f\"\\nüìä METRYKI WSZYSTKICH MODELI:\")\n",
        "print(\"-\" * 80)\n",
        "print(metrics_df.to_string(index=False))\n",
        "\n",
        "# Tabela z por√≥wnaniem modeli (z zaokrƒÖgleniem do 4 miejsc po przecinku)\n",
        "metrics_df_rounded = metrics_df.round(4)\n",
        "metrics_df_rounded = metrics_df_rounded.set_index('Model')\n",
        "print(f\"\\nüìä TABELA POR√ìWNAWCZA MODELI (zaokrƒÖglone do 4 miejsc):\")\n",
        "print(\"-\" * 80)\n",
        "display(metrics_df_rounded)\n",
        "\n",
        "# Wizualizacja metryk - wykres s≈Çupkowy (pionowy)\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(metrics_df))\n",
        "width = 0.25\n",
        "ax.bar(x - width, metrics_df['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
        "ax.bar(x, metrics_df['Balanced Accuracy'], width, label='Balanced Accuracy', alpha=0.8)\n",
        "ax.bar(x + width, metrics_df['Macro F1'], width, label='Macro F1', alpha=0.8)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Por√≥wnanie metryk globalnych wszystkich modeli', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_df['Model'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.set_ylim([0, 1.1])\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for i, row in metrics_df.iterrows():\n",
        "    ax.text(i - width, row['Accuracy'] + 0.01, f\"{row['Accuracy']:.3f}\", \n",
        "            ha='center', va='bottom', fontsize=8)\n",
        "    ax.text(i, row['Balanced Accuracy'] + 0.01, f\"{row['Balanced Accuracy']:.3f}\", \n",
        "            ha='center', va='bottom', fontsize=8)\n",
        "    ax.text(i + width, row['Macro F1'] + 0.01, f\"{row['Macro F1']:.3f}\", \n",
        "            ha='center', va='bottom', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wizualizacja metryk - wykres s≈Çupkowy (poziomy, jak w przyk≈Çadzie u≈ºytkownika)\n",
        "metrics_df_plot = metrics_df.set_index('Model')\n",
        "metrics_df_plot.plot(kind=\"bar\", figsize=(12, 6), rot=45)\n",
        "plt.title(\"Por√≥wnanie modeli: Accuracy, Balanced Accuracy, Macro F1\", fontsize=14, fontweight='bold')\n",
        "plt.ylabel(\"Warto≈õƒá metryki\", fontsize=12)\n",
        "plt.xlabel(\"Model\", fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend(title=\"Metryka\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in plt.gca().containers:\n",
        "    plt.gca().bar_label(container, fmt='%.3f', rotation=90, padding=3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Confusion Matrices\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"2. CONFUSION MATRICES\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "n_models = len(results)\n",
        "fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))\n",
        "if n_models == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, (model_name, result) in enumerate(results.items()):\n",
        "    cm = result['confusion_matrix']\n",
        "    # Normalizacja confusion matrix (procenty)\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    # Heatmap\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
        "                xticklabels=label_encoder.classes_, \n",
        "                yticklabels=label_encoder.classes_,\n",
        "                ax=axes[idx], cbar_kws={'label': 'Procent'})\n",
        "    axes[idx].set_title(f'{model_name}\\nConfusion Matrix (normalized)', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_ylabel('True Label', fontsize=11)\n",
        "    axes[idx].set_xlabel('Predicted Label', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Wy≈õwietl confusion matrices jako liczby\n",
        "print(f\"\\nüìä CONFUSION MATRICES (liczby bezwzglƒôdne):\")\n",
        "print(\"-\" * 80)\n",
        "for model_name, result in results.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    cm = result['confusion_matrix']\n",
        "    cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
        "    print(cm_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "3. PER-CLASS PRECISION I RECALL\n",
            "================================================================================\n",
            "\n",
            "üìä PRECISION PER CLASS:\n",
            "--------------------------------------------------------------------------------\n",
            "Model     Ensemble  LogisticRegression  RandomForest       SVM   XGBoost\n",
            "Class                                                                   \n",
            "baseline  0.882353            0.909091      0.709677  0.714286  0.705882\n",
            "emotion   0.541667            0.684211      0.600000  0.538462  0.714286\n",
            "\n",
            "üìä RECALL PER CLASS:\n",
            "--------------------------------------------------------------------------------\n",
            "Model     Ensemble  LogisticRegression  RandomForest       SVM   XGBoost\n",
            "Class                                                                   \n",
            "baseline  0.576923            0.769231      0.846154  0.769231  0.923077\n",
            "emotion   0.866667            0.866667      0.400000  0.466667  0.333333\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Class'>"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Precision')"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Per-Class Precision - wy≈ºsze = lepsze')"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x31d1d7bc0>"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 1.1)"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.882'), Text(0, 3, '0.542')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.909'), Text(0, 3, '0.684')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.710'), Text(0, 3, '0.600')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.714'), Text(0, 3, '0.538')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.706'), Text(0, 3, '0.714')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Class'>"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Recall (Sensitivity)')"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Per-Class Recall (Sensitivity) - wy≈ºsze = lepsze')"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x3198a6db0>"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 1.1)"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.577'), Text(0, 3, '0.867')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.769'), Text(0, 3, '0.867')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.846'), Text(0, 3, '0.400')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.769'), Text(0, 3, '0.467')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 3, '0.923'), Text(0, 3, '0.333')]"
            ]
          },
          "execution_count": 410,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "4. SZCZEG√ì≈ÅOWE RAPORTY KLASYFIKACJI\n",
            "================================================================================\n",
            "\n",
            "LogisticRegression:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    baseline       0.91      0.77      0.83        26\n",
            "     emotion       0.68      0.87      0.76        15\n",
            "\n",
            "    accuracy                           0.80        41\n",
            "   macro avg       0.80      0.82      0.80        41\n",
            "weighted avg       0.83      0.80      0.81        41\n",
            "\n",
            "\n",
            "RandomForest:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    baseline       0.71      0.85      0.77        26\n",
            "     emotion       0.60      0.40      0.48        15\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.65      0.62      0.63        41\n",
            "weighted avg       0.67      0.68      0.67        41\n",
            "\n",
            "\n",
            "XGBoost:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    baseline       0.71      0.92      0.80        26\n",
            "     emotion       0.71      0.33      0.45        15\n",
            "\n",
            "    accuracy                           0.71        41\n",
            "   macro avg       0.71      0.63      0.63        41\n",
            "weighted avg       0.71      0.71      0.67        41\n",
            "\n",
            "\n",
            "SVM:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    baseline       0.71      0.77      0.74        26\n",
            "     emotion       0.54      0.47      0.50        15\n",
            "\n",
            "    accuracy                           0.66        41\n",
            "   macro avg       0.63      0.62      0.62        41\n",
            "weighted avg       0.65      0.66      0.65        41\n",
            "\n",
            "\n",
            "Ensemble:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    baseline       0.88      0.58      0.70        26\n",
            "     emotion       0.54      0.87      0.67        15\n",
            "\n",
            "    accuracy                           0.68        41\n",
            "   macro avg       0.71      0.72      0.68        41\n",
            "weighted avg       0.76      0.68      0.69        41\n",
            "\n",
            "\n",
            "================================================================================\n",
            "5. WYB√ìR NAJLEPSZEGO MODELU\n",
            "================================================================================\n",
            "\n",
            "üèÜ NAJLEPSZY MODEL (wed≈Çug Balanced Accuracy): LogisticRegression\n",
            "   Balanced Accuracy: 0.8179\n",
            "   Macro F1: 0.7990\n",
            "   Accuracy: 0.8049\n",
            "\n",
            "‚úÖ EWALUACJA ZAKO≈ÉCZONA!\n"
          ]
        }
      ],
      "source": [
        "# 3. Per-class Precision i Recall\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"3. PER-CLASS PRECISION I RECALL\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Zbierz dane per-class\n",
        "precision_data = []\n",
        "recall_data = []\n",
        "\n",
        "for model_name, result in results.items():\n",
        "    report = result['classification_report']\n",
        "    for label in label_encoder.classes_:\n",
        "        if label in report:\n",
        "            precision_data.append({\n",
        "                'Model': model_name,\n",
        "                'Class': label,\n",
        "                'Precision': report[label]['precision']\n",
        "            })\n",
        "            recall_data.append({\n",
        "                'Model': model_name,\n",
        "                'Class': label,\n",
        "                'Recall': report[label]['recall']\n",
        "            })\n",
        "\n",
        "precision_df = pd.DataFrame(precision_data)\n",
        "recall_df = pd.DataFrame(recall_data)\n",
        "\n",
        "precision_pivot = precision_df.pivot(index='Class', columns='Model', values='Precision')\n",
        "recall_pivot = recall_df.pivot(index='Class', columns='Model', values='Recall')\n",
        "\n",
        "print(f\"\\nüìä PRECISION PER CLASS:\")\n",
        "print(\"-\" * 80)\n",
        "print(precision_pivot.to_string())\n",
        "\n",
        "print(f\"\\nüìä RECALL PER CLASS:\")\n",
        "print(\"-\" * 80)\n",
        "print(recall_pivot.to_string())\n",
        "\n",
        "# Wizualizacja Precision i Recall\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "precision_pivot.plot(kind='bar', ax=axes[0], rot=0, width=0.8)\n",
        "axes[0].set_ylabel('Precision', fontsize=12)\n",
        "axes[0].set_title('Per-Class Precision - wy≈ºsze = lepsze', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].set_ylim([0, 1.1])\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in axes[0].containers:\n",
        "    axes[0].bar_label(container, fmt='%.3f', rotation=90, padding=3)\n",
        "\n",
        "recall_pivot.plot(kind='bar', ax=axes[1], rot=0, width=0.8)\n",
        "axes[1].set_ylabel('Recall (Sensitivity)', fontsize=12)\n",
        "axes[1].set_title('Per-Class Recall (Sensitivity) - wy≈ºsze = lepsze', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].set_ylim([0, 1.1])\n",
        "# Dodaj warto≈õci na s≈Çupkach\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container, fmt='%.3f', rotation=90, padding=3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Szczeg√≥≈Çowe raporty klasyfikacji\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"4. SZCZEG√ì≈ÅOWE RAPORTY KLASYFIKACJI\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "for model_name, result in results.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(classification_report(y_test, result['y_pred'], \n",
        "                                 target_names=label_encoder.classes_))\n",
        "\n",
        "# 5. Wyb√≥r najlepszego modelu\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"5. WYB√ìR NAJLEPSZEGO MODELU\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Znajd≈∫ najlepszy model wed≈Çug Balanced Accuracy\n",
        "best_model_name = max(results.keys(), key=lambda k: results[k]['balanced_accuracy'])\n",
        "best_result = results[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ NAJLEPSZY MODEL (wed≈Çug Balanced Accuracy): {best_model_name}\")\n",
        "print(f\"   Balanced Accuracy: {best_result['balanced_accuracy']:.4f}\")\n",
        "print(f\"   Macro F1: {best_result['macro_f1']:.4f}\")\n",
        "print(f\"   Accuracy: {best_result['accuracy']:.4f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ EWALUACJA ZAKO≈ÉCZONA!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KROK 10: PRZYGOTOWANIE WYNIK√ìW DLA STREAMLIT APP\n",
        "\n",
        "Zbieramy wszystkie wyniki analizy w strukturze gotowej do u≈ºycia w aplikacji Streamlit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KROK 10: PRZYGOTOWANIE WYNIK√ìW DLA STREAMLIT APP\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Wyniki zapisane do: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/results/analysis_results.json\n",
            "‚úÖ Label encoder zapisany do: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/results/label_encoder.pkl\n",
            "‚úÖ Scaler zapisany do: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/results/scaler.pkl\n",
            "‚úÖ Najlepszy model (LogisticRegression) zapisany do: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/results/best_model_logisticregression.pkl\n",
            "\n",
            "================================================================================\n",
            "PODSUMOWANIE WYNIK√ìW ANALIZY\n",
            "================================================================================\n",
            "\n",
            "üìä INFORMACJE O DANYCH:\n",
            "   Liczba pr√≥bek train (przed SMOTE): 82\n",
            "   Liczba pr√≥bek train (po SMOTE): 108\n",
            "   Liczba pr√≥bek test: 41\n",
            "   Liczba cech: 60\n",
            "   Liczba klas: 2\n",
            "   Klasy: baseline, emotion\n",
            "\n",
            "üìä ROZK≈ÅAD KLAS:\n",
            "   Train (przed SMOTE): {'baseline': 54, 'emotion': 28}\n",
            "   Train (po SMOTE): {'baseline': 54, 'emotion': 54}\n",
            "   Test: {'baseline': 26, 'emotion': 15}\n",
            "\n",
            "üìä METRYKI MODELI:\n",
            "\n",
            "   LogisticRegression:\n",
            "      Accuracy: 0.8049\n",
            "      Balanced Accuracy: 0.8179\n",
            "      Macro F1: 0.7990\n",
            "\n",
            "   RandomForest:\n",
            "      Accuracy: 0.6829\n",
            "      Balanced Accuracy: 0.6231\n",
            "      Macro F1: 0.6260\n",
            "\n",
            "   XGBoost:\n",
            "      Accuracy: 0.7073\n",
            "      Balanced Accuracy: 0.6282\n",
            "      Macro F1: 0.6273\n",
            "\n",
            "   SVM:\n",
            "      Accuracy: 0.6585\n",
            "      Balanced Accuracy: 0.6179\n",
            "      Macro F1: 0.6204\n",
            "\n",
            "   Ensemble:\n",
            "      Accuracy: 0.6829\n",
            "      Balanced Accuracy: 0.7218\n",
            "      Macro F1: 0.6822\n",
            "\n",
            "üèÜ NAJLEPSZY MODEL: LogisticRegression\n",
            "   Balanced Accuracy: 0.8179\n",
            "   Macro F1: 0.7990\n",
            "\n",
            "üìä LABEL ENCODER MAPPING:\n",
            "   baseline: 0\n",
            "   emotion: 1\n",
            "\n",
            "‚úÖ Wszystkie wyniki gotowe do u≈ºycia w Streamlit!\n",
            "   Pliki zapisane w: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/results\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KROK 10: PRZYGOTOWANIE WYNIK√ìW DLA STREAMLIT APP\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KROK 10: PRZYGOTOWANIE WYNIK√ìW DLA STREAMLIT APP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá zmiennych\n",
        "if 'results' not in globals() or len(results) == 0:\n",
        "    print(\"\\n‚ùå‚ùå‚ùå B≈ÅƒÑD: Najpierw uruchom KROK 8 i KROK 9!\")\n",
        "    raise NameError(\"results nie sƒÖ zdefiniowane\")\n",
        "\n",
        "# ===============================================================_=============\n",
        "# 1. ZBIERZ WSZYSTKIE WYNIKI ANALIZY\n",
        "# ============================================================================\n",
        "\n",
        "analysis_results = {\n",
        "    # Informacje o danych\n",
        "    'data_info': {\n",
        "        'n_train_before_smote': len(y_train) if 'y_train' in globals() else 0,\n",
        "        'n_train_after_smote': len(y_train_bal) if 'y_train_bal' in globals() else 0,\n",
        "        'n_test': len(y_test) if 'y_test' in globals() else 0,\n",
        "        'n_features': X_train.shape[1] if 'X_train' in globals() else 0,\n",
        "        'n_classes': len(label_encoder.classes_) if 'label_encoder' in globals() else 0,\n",
        "        'classes': label_encoder.classes_.tolist() if 'label_encoder' in globals() else [],\n",
        "    },\n",
        "    \n",
        "    # Rozk≈Çad klas przed SMOTE\n",
        "    'class_distribution_before_smote': {},\n",
        "    \n",
        "    # Rozk≈Çad klas po SMOTE\n",
        "    'class_distribution_after_smote': {},\n",
        "    \n",
        "    # Rozk≈Çad klas w test\n",
        "    'class_distribution_test': {},\n",
        "    \n",
        "    # Metryki modeli\n",
        "    'model_metrics': {},\n",
        "    \n",
        "    # Confusion matrices\n",
        "    'confusion_matrices': {},\n",
        "    \n",
        "    # Per-class metrics (precision, recall, f1)\n",
        "    'per_class_metrics': {},\n",
        "    \n",
        "    # Najlepszy model\n",
        "    'best_model': None,\n",
        "    \n",
        "    # Label encoder info\n",
        "    'label_encoder_mapping': {},\n",
        "}\n",
        "\n",
        "# Rozk≈Çad klas przed SMOTE\n",
        "if 'y_train' in globals():\n",
        "    train_before_dist = pd.Series(label_encoder.inverse_transform(y_train)).value_counts()\n",
        "    analysis_results['class_distribution_before_smote'] = {\n",
        "        label: int(count) for label, count in train_before_dist.items()\n",
        "    }\n",
        "\n",
        "# Rozk≈Çad klas po SMOTE\n",
        "if 'y_train_bal' in globals():\n",
        "    train_after_dist = pd.Series(label_encoder.inverse_transform(y_train_bal)).value_counts()\n",
        "    analysis_results['class_distribution_after_smote'] = {\n",
        "        label: int(count) for label, count in train_after_dist.items()\n",
        "    }\n",
        "\n",
        "# Rozk≈Çad klas w test\n",
        "if 'y_test' in globals():\n",
        "    test_dist = pd.Series(label_encoder.inverse_transform(y_test)).value_counts()\n",
        "    analysis_results['class_distribution_test'] = {\n",
        "        label: int(count) for label, count in test_dist.items()\n",
        "    }\n",
        "\n",
        "# Label encoder mapping\n",
        "if 'label_encoder' in globals():\n",
        "    analysis_results['label_encoder_mapping'] = {\n",
        "        label: int(code) for label, code in zip(label_encoder.classes_, range(len(label_encoder.classes_)))\n",
        "    }\n",
        "\n",
        "# Metryki i wyniki dla ka≈ºdego modelu\n",
        "for model_name, result in results.items():\n",
        "    # Metryki globalne\n",
        "    analysis_results['model_metrics'][model_name] = {\n",
        "        'accuracy': float(result['accuracy']),\n",
        "        'balanced_accuracy': float(result['balanced_accuracy']),\n",
        "        'macro_f1': float(result['macro_f1']),\n",
        "    }\n",
        "    \n",
        "    # Confusion matrix (konwertuj na listƒô list)\n",
        "    cm = result['confusion_matrix']\n",
        "    analysis_results['confusion_matrices'][model_name] = cm.tolist()\n",
        "    \n",
        "    # Per-class metrics\n",
        "    report = result['classification_report']\n",
        "    analysis_results['per_class_metrics'][model_name] = {}\n",
        "    for label in label_encoder.classes_:\n",
        "        if label in report:\n",
        "            analysis_results['per_class_metrics'][model_name][label] = {\n",
        "                'precision': float(report[label]['precision']),\n",
        "                'recall': float(report[label]['recall']),\n",
        "                'f1_score': float(report[label]['f1-score']),\n",
        "                'support': int(report[label]['support'])\n",
        "            }\n",
        "\n",
        "# Najlepszy model (wed≈Çug Balanced Accuracy)\n",
        "if len(results) > 0:\n",
        "    best_model_name = max(results.keys(), key=lambda k: results[k]['balanced_accuracy'])\n",
        "    analysis_results['best_model'] = {\n",
        "        'name': best_model_name,\n",
        "        'accuracy': float(results[best_model_name]['accuracy']),\n",
        "        'balanced_accuracy': float(results[best_model_name]['balanced_accuracy']),\n",
        "        'macro_f1': float(results[best_model_name]['macro_f1']),\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# 2. ZAPISZ WYNIKI DO PLIKU (dla Streamlit)\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Utw√≥rz folder dla wynik√≥w je≈õli nie istnieje\n",
        "results_dir = PROJECT_ROOT / \"results\"\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Zapisz wyniki do JSON\n",
        "results_json_path = results_dir / \"analysis_results.json\"\n",
        "with open(results_json_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(analysis_results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Wyniki zapisane do: {results_json_path}\")\n",
        "\n",
        "# Zapisz label encoder (dla u≈ºycia w Streamlit)\n",
        "import pickle\n",
        "label_encoder_path = results_dir / \"label_encoder.pkl\"\n",
        "with open(label_encoder_path, 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(f\"‚úÖ Label encoder zapisany do: {label_encoder_path}\")\n",
        "\n",
        "# Zapisz scaler (je≈õli bƒôdzie potrzebny w Streamlit)\n",
        "if 'scaler' in globals():\n",
        "    scaler_path = results_dir / \"scaler.pkl\"\n",
        "    with open(scaler_path, 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "    print(f\"‚úÖ Scaler zapisany do: {scaler_path}\")\n",
        "\n",
        "# Zapisz najlepszy model (opcjonalnie)\n",
        "if analysis_results['best_model']:\n",
        "    best_model_name = analysis_results['best_model']['name']\n",
        "    if best_model_name in results:\n",
        "        best_model_path = results_dir / f\"best_model_{best_model_name.lower()}.pkl\"\n",
        "        with open(best_model_path, 'wb') as f:\n",
        "            pickle.dump(results[best_model_name]['model'], f)\n",
        "        print(f\"‚úÖ Najlepszy model ({best_model_name}) zapisany do: {best_model_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. WY≈öWIETL PODSUMOWANIE WYNIK√ìW\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"PODSUMOWANIE WYNIK√ìW ANALIZY\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nüìä INFORMACJE O DANYCH:\")\n",
        "print(f\"   Liczba pr√≥bek train (przed SMOTE): {analysis_results['data_info']['n_train_before_smote']}\")\n",
        "print(f\"   Liczba pr√≥bek train (po SMOTE): {analysis_results['data_info']['n_train_after_smote']}\")\n",
        "print(f\"   Liczba pr√≥bek test: {analysis_results['data_info']['n_test']}\")\n",
        "print(f\"   Liczba cech: {analysis_results['data_info']['n_features']}\")\n",
        "print(f\"   Liczba klas: {analysis_results['data_info']['n_classes']}\")\n",
        "print(f\"   Klasy: {', '.join(analysis_results['data_info']['classes'])}\")\n",
        "\n",
        "print(f\"\\nüìä ROZK≈ÅAD KLAS:\")\n",
        "print(f\"   Train (przed SMOTE): {analysis_results['class_distribution_before_smote']}\")\n",
        "print(f\"   Train (po SMOTE): {analysis_results['class_distribution_after_smote']}\")\n",
        "print(f\"   Test: {analysis_results['class_distribution_test']}\")\n",
        "\n",
        "print(f\"\\nüìä METRYKI MODELI:\")\n",
        "for model_name, metrics in analysis_results['model_metrics'].items():\n",
        "    print(f\"\\n   {model_name}:\")\n",
        "    print(f\"      Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"      Balanced Accuracy: {metrics['balanced_accuracy']:.4f}\")\n",
        "    print(f\"      Macro F1: {metrics['macro_f1']:.4f}\")\n",
        "\n",
        "if analysis_results['best_model']:\n",
        "    print(f\"\\nüèÜ NAJLEPSZY MODEL: {analysis_results['best_model']['name']}\")\n",
        "    print(f\"   Balanced Accuracy: {analysis_results['best_model']['balanced_accuracy']:.4f}\")\n",
        "    print(f\"   Macro F1: {analysis_results['best_model']['macro_f1']:.4f}\")\n",
        "\n",
        "print(f\"\\nüìä LABEL ENCODER MAPPING:\")\n",
        "for label, code in analysis_results['label_encoder_mapping'].items():\n",
        "    print(f\"   {label}: {code}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Wszystkie wyniki gotowe do u≈ºycia w Streamlit!\")\n",
        "print(f\"   Pliki zapisane w: {results_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PRZYK≈ÅAD U≈ªYCIA W STREAMLIT\n",
        "\n",
        "Poni≈ºej znajduje siƒô przyk≈Çad kodu Streamlit, kt√≥ry mo≈ºna u≈ºyƒá do wy≈õwietlenia wynik√≥w.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Klasa          object\n",
            "Przed SMOTE     int64\n",
            "Po SMOTE        int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(comparison_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GENEROWANIE PLIK√ìW DLA STREAMLIT APP\n",
        "\n",
        "Ta kom√≥rka generuje wszystkie potrzebne pliki do uruchomienia aplikacji Streamlit:\n",
        "- `analysis_results.json` - wyniki analizy\n",
        "- `label_encoder.pkl` - encoder etykiet  \n",
        "- `streamlit_app.py` - kod aplikacji Streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "GENEROWANIE PLIK√ìW DLA STREAMLIT APP\n",
            "================================================================================\n",
            "\n",
            "üìä Sprawdzanie dostƒôpno≈õci danych...\n",
            "   ‚úÖ Znaleziono s≈Çownik 'results'\n",
            "   ‚úÖ Dostƒôpne modele w results: LogisticRegression, RandomForest, XGBoost, SVM, Ensemble\n",
            "   ‚úÖ Wszystkie potrzebne dane sƒÖ dostƒôpne\n",
            "\n",
            "üìä Generowanie predykcji...\n",
            "   ‚úÖ LogisticRegression: u≈ºywam istniejƒÖcych predykcji\n",
            "   ‚úÖ RandomForest: u≈ºywam istniejƒÖcych predykcji\n",
            "   ‚úÖ XGBoost: u≈ºywam istniejƒÖcych predykcji\n",
            "   ‚úÖ SVM: u≈ºywam istniejƒÖcych predykcji\n",
            "   ‚úÖ Ensemble: u≈ºywam istniejƒÖcych predykcji\n",
            "\n",
            "üìä Obliczanie metryk...\n",
            "   ‚úÖ LogisticRegression: Accuracy=0.8049, Balanced Accuracy=0.8179, Macro F1=0.7990\n",
            "   ‚úÖ RandomForest: Accuracy=0.6829, Balanced Accuracy=0.6231, Macro F1=0.6260\n",
            "   ‚úÖ XGBoost: Accuracy=0.7073, Balanced Accuracy=0.6282, Macro F1=0.6273\n",
            "   ‚úÖ SVM: Accuracy=0.6585, Balanced Accuracy=0.6179, Macro F1=0.6204\n",
            "   ‚úÖ Ensemble: Accuracy=0.6829, Balanced Accuracy=0.7218, Macro F1=0.6822\n",
            "\n",
            "================================================================================\n",
            "üìä SZCZEG√ì≈ÅOWE POR√ìWNANIE WSZYSTKICH MODELI\n",
            "================================================================================\n",
            "\n",
            "üìã Tabela por√≥wnawcza wszystkich modeli:\n",
            "--------------------------------------------------------------------------------\n",
            "                    accuracy  balanced_accuracy  macro_f1\n",
            "LogisticRegression    0.8049             0.8179    0.7990\n",
            "Ensemble              0.6829             0.7218    0.6822\n",
            "XGBoost               0.7073             0.6282    0.6273\n",
            "RandomForest          0.6829             0.6231    0.6260\n",
            "SVM                   0.6585             0.6179    0.6204\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üèÜ RANKING MODELI:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1Ô∏è‚É£ Ranking wed≈Çug Balanced Accuracy:\n",
            "   ü•á LogisticRegression  : 0.8179\n",
            "   ü•à Ensemble            : 0.7218\n",
            "   ü•â XGBoost             : 0.6282\n",
            "   4. RandomForest        : 0.6231\n",
            "   5. SVM                 : 0.6179\n",
            "\n",
            "2Ô∏è‚É£ Ranking wed≈Çug Macro F1:\n",
            "   ü•á LogisticRegression  : 0.7990\n",
            "   ü•à Ensemble            : 0.6822\n",
            "   ü•â XGBoost             : 0.6273\n",
            "   4. RandomForest        : 0.6260\n",
            "   5. SVM                 : 0.6204\n",
            "\n",
            "3Ô∏è‚É£ Ranking wed≈Çug Accuracy:\n",
            "   ü•á LogisticRegression  : 0.8049\n",
            "   ü•à XGBoost             : 0.7073\n",
            "   ü•â Ensemble            : 0.6829\n",
            "   4. RandomForest        : 0.6829\n",
            "   5. SVM                 : 0.6585\n",
            "\n",
            "4Ô∏è‚É£ Ranking wed≈Çug Combined Score (≈õrednia z Balanced Accuracy i Macro F1):\n",
            "   ü•á LogisticRegression  : 0.8085 (BA: 0.8179, F1: 0.7990)\n",
            "   ü•à Ensemble            : 0.7020 (BA: 0.7218, F1: 0.6822)\n",
            "   ü•â XGBoost             : 0.6278 (BA: 0.6282, F1: 0.6273)\n",
            "   4. RandomForest        : 0.6245 (BA: 0.6231, F1: 0.6260)\n",
            "   5. SVM                 : 0.6191 (BA: 0.6179, F1: 0.6204)\n",
            "\n",
            "================================================================================\n",
            "üèÜ NAJLEPSZY MODEL (wed≈Çug Combined Score): LogisticRegression\n",
            "================================================================================\n",
            "   üìä Balanced Accuracy: 0.8179\n",
            "   üìä Macro F1:          0.7990\n",
            "   üìä Accuracy:          0.8049\n",
            "   üìä Combined Score:    0.8085\n",
            "\n",
            "üìä Por√≥wnanie z innymi modeli:\n",
            "   Ensemble            : BA r√≥≈ºnica: +0.0962, F1 r√≥≈ºnica: +0.1168\n",
            "   XGBoost             : BA r√≥≈ºnica: +0.1897, F1 r√≥≈ºnica: +0.1717\n",
            "\n",
            "üìä Obliczanie per-class metrics...\n",
            "   ‚úÖ LogisticRegression: obliczono per-class metrics dla 2 klas\n",
            "   ‚úÖ RandomForest: obliczono per-class metrics dla 2 klas\n",
            "   ‚úÖ XGBoost: obliczono per-class metrics dla 2 klas\n",
            "   ‚úÖ SVM: obliczono per-class metrics dla 2 klas\n",
            "   ‚úÖ Ensemble: obliczono per-class metrics dla 2 klas\n",
            "\n",
            "üìä Obliczanie rozk≈Çad√≥w klas...\n",
            "\n",
            "üìä Tworzenie struktury danych...\n",
            "\n",
            "üíæ Zapis plik√≥w...\n",
            "   ‚úÖ Zapisano: results/analysis_results.json\n",
            "   ‚úÖ Zapisano: results/label_encoder.pkl\n",
            "\n",
            "üìù Generowanie kodu Streamlit...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7763"
            ]
          },
          "execution_count": 413,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Zapisano: results/streamlit_app.py\n",
            "\n",
            "================================================================================\n",
            "‚úÖ WSZYSTKIE PLIKI WYGENEROWANE POMY≈öLNIE!\n",
            "================================================================================\n",
            "\n",
            "üìÅ Lokalizacja plik√≥w: /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/notebooks/results\n",
            "   ‚úÖ analysis_results.json\n",
            "   ‚úÖ label_encoder.pkl\n",
            "   ‚úÖ streamlit_app.py\n",
            "\n",
            "üìä Podsumowanie wynik√≥w:\n",
            "   - Liczba pr√≥bek train (po SMOTE): 108\n",
            "   - Liczba pr√≥bek test: 41\n",
            "   - Liczba cech: 60\n",
            "   - Liczba klas: 2\n",
            "   - Klasy: baseline, emotion\n",
            "\n",
            "üèÜ Najlepszy model: LogisticRegression\n",
            "   - Balanced Accuracy: 0.8179\n",
            "   - Macro F1: 0.7990\n",
            "\n",
            "================================================================================\n",
            "üìã INSTRUKCJA URUCHOMIENIA STREAMLIT\n",
            "================================================================================\n",
            "\n",
            "1. Otw√≥rz terminal w folderze projektu:\n",
            "   cd \"/Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/notebooks\"\n",
            "\n",
            "2. Uruchom aplikacjƒô Streamlit:\n",
            "   streamlit run results/streamlit_app.py\n",
            "\n",
            "3. Aplikacja otworzy siƒô automatycznie w przeglƒÖdarce\n",
            "   (zwykle pod adresem: http://localhost:8501)\n",
            "\n",
            "4. Je≈õli pliki sƒÖ w innym miejscu, mo≈ºesz uruchomiƒá z folderu results:\n",
            "   cd results\n",
            "   streamlit run streamlit_app.py\n",
            "\n",
            "üí° UWAGA: Upewnij siƒô, ≈ºe masz zainstalowany streamlit:\n",
            "   pip install streamlit\n",
            "\n",
            "\n",
            "‚úÖ Gotowe! Mo≈ºesz teraz uruchomiƒá aplikacjƒô Streamlit.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GENEROWANIE PLIK√ìW DLA STREAMLIT APP\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"GENEROWANIE PLIK√ìW DLA STREAMLIT APP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, balanced_accuracy_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. SPRAWD≈π DOSTƒòPNO≈öƒÜ DANYCH I MODELI\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Sprawdzanie dostƒôpno≈õci danych...\")\n",
        "\n",
        "# Sprawd≈∫ czy mamy modele w results lub bezpo≈õrednio\n",
        "has_models = False\n",
        "models_to_use = {}\n",
        "\n",
        "if 'results' in globals() and isinstance(results, dict):\n",
        "    print(\"   ‚úÖ Znaleziono s≈Çownik 'results'\")\n",
        "    # Sprawd≈∫ dostƒôpne modele\n",
        "    available_models = [k for k in results.keys() if isinstance(results[k], dict) and 'model' in results[k]]\n",
        "    if available_models:\n",
        "        print(f\"   ‚úÖ Dostƒôpne modele w results: {', '.join(available_models)}\")\n",
        "        has_models = True\n",
        "        for model_name in available_models:\n",
        "            if 'model' in results[model_name]:\n",
        "                models_to_use[model_name] = results[model_name]['model']\n",
        "    elif 'RandomForest' in results and 'XGBoost' in results:\n",
        "        # Sprawd≈∫ czy mamy predykcje\n",
        "        if 'y_pred' in results.get('RandomForest', {}) and 'y_pred' in results.get('XGBoost', {}):\n",
        "            print(\"   ‚úÖ U≈ºywam istniejƒÖcych predykcji z results\")\n",
        "            has_models = True\n",
        "\n",
        "# Sprawd≈∫ bezpo≈õrednie zmienne\n",
        "if not has_models:\n",
        "    if 'rf_model' in globals() and 'xgb_model' in globals():\n",
        "        print(\"   ‚úÖ Znaleziono rf_model i xgb_model\")\n",
        "        models_to_use['RandomForest'] = rf_model\n",
        "        models_to_use['XGBoost'] = xgb_model\n",
        "        has_models = True\n",
        "\n",
        "if not has_models:\n",
        "    print(\"   ‚ùå B≈ÅƒÑD: Nie znaleziono modeli!\")\n",
        "    print(\"   üí° Upewnij siƒô, ≈ºe uruchomi≈Çe≈õ kom√≥rkƒô z trenowaniem modeli (KROK 8)\")\n",
        "    raise NameError(\"Brak dostƒôpnych modeli\")\n",
        "\n",
        "# Sprawd≈∫ dane testowe\n",
        "required_data = ['X_test', 'y_test', 'label_encoder']\n",
        "missing_data = [var for var in required_data if var not in globals()]\n",
        "if missing_data:\n",
        "    print(f\"   ‚ùå B≈ÅƒÑD: BrakujƒÖce dane: {', '.join(missing_data)}\")\n",
        "    raise NameError(f\"BrakujƒÖce dane: {', '.join(missing_data)}\")\n",
        "\n",
        "# Sprawd≈∫ dane treningowe (dla rozk≈Çad√≥w klas)\n",
        "if 'y_train_bal' in globals() and y_train_bal is not None:\n",
        "    y_train_for_after = y_train_bal\n",
        "    if 'y_train' in globals() and y_train is not None:\n",
        "        y_train_for_before = y_train\n",
        "    else:\n",
        "        y_train_for_before = y_train_bal\n",
        "        print(\"   ‚ö†Ô∏è UWAGA: y_train nie jest dostƒôpne - u≈ºywam y_train_bal dla 'przed SMOTE'\")\n",
        "elif 'y_train' in globals() and y_train is not None:\n",
        "    y_train_for_before = y_train\n",
        "    y_train_for_after = y_train\n",
        "    print(\"   ‚ö†Ô∏è UWAGA: y_train_bal nie jest dostƒôpne - u≈ºywam y_train dla obu przypadk√≥w\")\n",
        "else:\n",
        "    print(\"   ‚ùå B≈ÅƒÑD: Brak danych treningowych (y_train lub y_train_bal)!\")\n",
        "    raise NameError(\"Brak danych treningowych\")\n",
        "\n",
        "print(\"   ‚úÖ Wszystkie potrzebne dane sƒÖ dostƒôpne\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. GENERUJ PREDYKCJE (je≈õli potrzeba)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Generowanie predykcji...\")\n",
        "predictions = {}\n",
        "\n",
        "# Sprawd≈∫ czy mamy ju≈º predykcje w results\n",
        "if 'results' in globals() and isinstance(results, dict):\n",
        "    # Najpierw sprawd≈∫ wszystkie modele w results\n",
        "    for model_name in results.keys():\n",
        "        if isinstance(results[model_name], dict) and 'y_pred' in results[model_name]:\n",
        "            predictions[model_name] = results[model_name]['y_pred']\n",
        "            print(f\"   ‚úÖ {model_name}: u≈ºywam istniejƒÖcych predykcji\")\n",
        "        elif isinstance(results[model_name], dict) and 'model' in results[model_name]:\n",
        "            # Je≈õli mamy model, ale nie ma predykcji, wygeneruj je\n",
        "            predictions[model_name] = results[model_name]['model'].predict(X_test)\n",
        "            print(f\"   ‚úÖ {model_name}: wygenerowano predykcje z modelu\")\n",
        "    \n",
        "    # Je≈õli nie mamy RandomForest lub XGBoost, spr√≥buj je znale≈∫ƒá\n",
        "    for model_name in ['RandomForest', 'XGBoost']:\n",
        "        if model_name not in predictions:\n",
        "            if model_name in models_to_use:\n",
        "                predictions[model_name] = models_to_use[model_name].predict(X_test)\n",
        "                print(f\"   ‚úÖ {model_name}: wygenerowano predykcje\")\n",
        "else:\n",
        "    # Generuj predykcje z modeli\n",
        "    for model_name, model in models_to_use.items():\n",
        "        predictions[model_name] = model.predict(X_test)\n",
        "        print(f\"   ‚úÖ {model_name}: wygenerowano {len(predictions[model_name])} predykcji\")\n",
        "\n",
        "# Upewnij siƒô, ≈ºe mamy predykcje dla przynajmniej RandomForest lub XGBoost\n",
        "if 'RandomForest' not in predictions and 'XGBoost' not in predictions:\n",
        "    if len(predictions) == 0:\n",
        "        print(\"   ‚ùå B≈ÅƒÑD: Brak predykcji dla ≈ºadnego modelu!\")\n",
        "        raise NameError(\"Brak predykcji dla modeli\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è UWAGA: U≈ºywam dostƒôpnych modeli: {', '.join(predictions.keys())}\")\n",
        "        # U≈ºyj pierwszego dostƒôpnego modelu jako g≈Ç√≥wnego\n",
        "        if 'RandomForest' not in predictions:\n",
        "            first_model = list(predictions.keys())[0]\n",
        "            predictions['RandomForest'] = predictions[first_model]\n",
        "            print(f\"   ‚ÑπÔ∏è U≈ºywam {first_model} jako RandomForest\")\n",
        "        if 'XGBoost' not in predictions:\n",
        "            if len(predictions) > 1:\n",
        "                second_model = list(predictions.keys())[1]\n",
        "                predictions['XGBoost'] = predictions[second_model]\n",
        "                print(f\"   ‚ÑπÔ∏è U≈ºywam {second_model} jako XGBoost\")\n",
        "            else:\n",
        "                # Je≈õli mamy tylko jeden model, u≈ºyj go dla obu\n",
        "                predictions['XGBoost'] = predictions['RandomForest']\n",
        "                print(f\"   ‚ÑπÔ∏è U≈ºywam tego samego modelu dla XGBoost\")\n",
        "\n",
        "y_pred_rf = np.array(predictions['RandomForest'])\n",
        "y_pred_xgb = np.array(predictions['XGBoost'])\n",
        "\n",
        "# ============================================================================\n",
        "# 3. OBLICZ METRYKI DLA WSZYSTKICH MODELI\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Obliczanie metryk...\")\n",
        "\n",
        "# Oblicz metryki dla wszystkich dostƒôpnych modeli\n",
        "all_metrics = {}\n",
        "all_per_class_reports = {}\n",
        "all_confusion_matrices = {}\n",
        "\n",
        "for model_name, y_pred in predictions.items():\n",
        "    y_pred_array = np.array(y_pred)\n",
        "    all_metrics[model_name] = {\n",
        "        'accuracy': float(accuracy_score(y_test, y_pred_array)),\n",
        "        'balanced_accuracy': float(balanced_accuracy_score(y_test, y_pred_array)),\n",
        "        'macro_f1': float(f1_score(y_test, y_pred_array, average='macro'))\n",
        "    }\n",
        "    all_per_class_reports[model_name] = classification_report(\n",
        "        y_test, y_pred_array, \n",
        "        target_names=label_encoder.classes_, \n",
        "        output_dict=True\n",
        "    )\n",
        "    all_confusion_matrices[model_name] = confusion_matrix(y_test, y_pred_array).tolist()\n",
        "    print(f\"   ‚úÖ {model_name}: Accuracy={all_metrics[model_name]['accuracy']:.4f}, \"\n",
        "          f\"Balanced Accuracy={all_metrics[model_name]['balanced_accuracy']:.4f}, \"\n",
        "          f\"Macro F1={all_metrics[model_name]['macro_f1']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SZCZEG√ì≈ÅOWE POR√ìWNANIE MODELI I WYB√ìR NAJLEPSZEGO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä SZCZEG√ì≈ÅOWE POR√ìWNANIE WSZYSTKICH MODELI\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Utw√≥rz DataFrame z metrykami dla ≈Çatwego por√≥wnania\n",
        "metrics_df = pd.DataFrame(all_metrics).T\n",
        "metrics_df = metrics_df.round(4)\n",
        "metrics_df = metrics_df.sort_values('balanced_accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nüìã Tabela por√≥wnawcza wszystkich modeli:\")\n",
        "print(\"-\" * 80)\n",
        "print(metrics_df.to_string())\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Ranking dla ka≈ºdej metryki\n",
        "print(\"\\nüèÜ RANKING MODELI:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Ranking wed≈Çug Balanced Accuracy\n",
        "print(\"\\n1Ô∏è‚É£ Ranking wed≈Çug Balanced Accuracy:\")\n",
        "ba_ranking = metrics_df.sort_values('balanced_accuracy', ascending=False)\n",
        "for i, (model, row) in enumerate(ba_ranking.iterrows(), 1):\n",
        "    marker = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else f\"{i}.\"\n",
        "    print(f\"   {marker} {model:20s}: {row['balanced_accuracy']:.4f}\")\n",
        "\n",
        "# Ranking wed≈Çug Macro F1\n",
        "print(\"\\n2Ô∏è‚É£ Ranking wed≈Çug Macro F1:\")\n",
        "f1_ranking = metrics_df.sort_values('macro_f1', ascending=False)\n",
        "for i, (model, row) in enumerate(f1_ranking.iterrows(), 1):\n",
        "    marker = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else f\"{i}.\"\n",
        "    print(f\"   {marker} {model:20s}: {row['macro_f1']:.4f}\")\n",
        "\n",
        "# Ranking wed≈Çug Accuracy\n",
        "print(\"\\n3Ô∏è‚É£ Ranking wed≈Çug Accuracy:\")\n",
        "acc_ranking = metrics_df.sort_values('accuracy', ascending=False)\n",
        "for i, (model, row) in enumerate(acc_ranking.iterrows(), 1):\n",
        "    marker = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else f\"{i}.\"\n",
        "    print(f\"   {marker} {model:20s}: {row['accuracy']:.4f}\")\n",
        "\n",
        "# Oblicz kombinowanƒÖ metrykƒô (≈õrednia z Balanced Accuracy i Macro F1)\n",
        "# To jest bardziej zbalansowany spos√≥b wyboru najlepszego modelu\n",
        "metrics_df['combined_score'] = (metrics_df['balanced_accuracy'] + metrics_df['macro_f1']) / 2\n",
        "metrics_df = metrics_df.sort_values('combined_score', ascending=False)\n",
        "\n",
        "print(\"\\n4Ô∏è‚É£ Ranking wed≈Çug Combined Score (≈õrednia z Balanced Accuracy i Macro F1):\")\n",
        "for i, (model, row) in enumerate(metrics_df.iterrows(), 1):\n",
        "    marker = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else f\"{i}.\"\n",
        "    print(f\"   {marker} {model:20s}: {row['combined_score']:.4f} \"\n",
        "          f\"(BA: {row['balanced_accuracy']:.4f}, F1: {row['macro_f1']:.4f})\")\n",
        "\n",
        "# Wybierz najlepszy model na podstawie kombinacji metryk\n",
        "# U≈ºywamy combined_score jako g≈Ç√≥wnego kryterium, ale sprawdzamy te≈º Balanced Accuracy\n",
        "best_model_name = metrics_df.index[0]\n",
        "best_metrics = all_metrics[best_model_name]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"üèÜ NAJLEPSZY MODEL (wed≈Çug Combined Score): {best_model_name}\")\n",
        "print(\"=\"*80)\n",
        "print(f\"   üìä Balanced Accuracy: {best_metrics['balanced_accuracy']:.4f}\")\n",
        "print(f\"   üìä Macro F1:          {best_metrics['macro_f1']:.4f}\")\n",
        "print(f\"   üìä Accuracy:          {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"   üìä Combined Score:    {metrics_df.loc[best_model_name, 'combined_score']:.4f}\")\n",
        "\n",
        "# Sprawd≈∫ czy sƒÖ inne modele z podobnymi wynikami\n",
        "print(\"\\nüìä Por√≥wnanie z innymi modeli:\")\n",
        "for model_name in metrics_df.index[:3]:  # Top 3\n",
        "    if model_name != best_model_name:\n",
        "        diff_ba = best_metrics['balanced_accuracy'] - all_metrics[model_name]['balanced_accuracy']\n",
        "        diff_f1 = best_metrics['macro_f1'] - all_metrics[model_name]['macro_f1']\n",
        "        print(f\"   {model_name:20s}: BA r√≥≈ºnica: {diff_ba:+.4f}, F1 r√≥≈ºnica: {diff_f1:+.4f}\")\n",
        "\n",
        "# Zachowaj kompatybilno≈õƒá z kodem Streamlit (u≈ºywamy RandomForest i XGBoost jako g≈Ç√≥wne)\n",
        "metrics_rf = all_metrics.get('RandomForest', all_metrics[list(all_metrics.keys())[0]])\n",
        "metrics_xgb = all_metrics.get('XGBoost', all_metrics[list(all_metrics.keys())[-1]])\n",
        "y_pred_rf = np.array(predictions.get('RandomForest', predictions[list(predictions.keys())[0]]))\n",
        "y_pred_xgb = np.array(predictions.get('XGBoost', predictions[list(predictions.keys())[-1]]))\n",
        "\n",
        "# ============================================================================\n",
        "# 4. OBLICZ PER-CLASS METRICS DLA WSZYSTKICH MODELI\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Obliczanie per-class metrics...\")\n",
        "\n",
        "# Per-class metrics dla wszystkich modeli\n",
        "all_per_class_metrics = {}\n",
        "\n",
        "for model_name in all_per_class_reports.keys():\n",
        "    report = all_per_class_reports[model_name]\n",
        "    per_class_dict = {}\n",
        "    for label in label_encoder.classes_:\n",
        "        if label in report:\n",
        "            per_class_dict[label] = {\n",
        "                'precision': float(report[label]['precision']),\n",
        "                'recall': float(report[label]['recall']),\n",
        "                'f1_score': float(report[label]['f1-score']),\n",
        "                'support': int(report[label]['support'])\n",
        "            }\n",
        "    all_per_class_metrics[model_name] = per_class_dict\n",
        "    print(f\"   ‚úÖ {model_name}: obliczono per-class metrics dla {len(per_class_dict)} klas\")\n",
        "\n",
        "# Zachowaj kompatybilno≈õƒá z kodem Streamlit\n",
        "per_class_rf = all_per_class_metrics.get('RandomForest', {})\n",
        "per_class_xgb = all_per_class_metrics.get('XGBoost', {})\n",
        "\n",
        "# ============================================================================\n",
        "# 5. OBLICZ ROZK≈ÅADY KLAS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Obliczanie rozk≈Çad√≥w klas...\")\n",
        "\n",
        "def get_class_distribution(y_data):\n",
        "    \"\"\"Pomocnicza funkcja do obliczania rozk≈Çadu klas\"\"\"\n",
        "    try:\n",
        "        if isinstance(y_data, np.ndarray) and y_data.dtype in [np.int32, np.int64]:\n",
        "            labels = label_encoder.inverse_transform(y_data)\n",
        "        else:\n",
        "            labels = y_data\n",
        "        return pd.Series(labels).value_counts()\n",
        "    except:\n",
        "        return pd.Series(y_data).value_counts()\n",
        "\n",
        "train_before_dist = get_class_distribution(y_train_for_before)\n",
        "train_after_dist = get_class_distribution(y_train_for_after)\n",
        "test_dist = get_class_distribution(y_test)\n",
        "\n",
        "# ============================================================================\n",
        "# 6. TWORZENIE STRUKTURY analysis_results\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìä Tworzenie struktury danych...\")\n",
        "\n",
        "# Sprawd≈∫ liczbƒô cech (u≈ºyj X_test jako fallback je≈õli X_train_bal nie jest dostƒôpny)\n",
        "if 'X_train_bal' in globals() and X_train_bal is not None:\n",
        "    if hasattr(X_train_bal, 'shape'):\n",
        "        n_features = X_train_bal.shape[1]\n",
        "    elif hasattr(X_train_bal, 'columns'):\n",
        "        n_features = len(X_train_bal.columns)\n",
        "    else:\n",
        "        n_features = len(X_train_bal[0]) if len(X_train_bal) > 0 else 0\n",
        "elif 'X_test' in globals() and X_test is not None:\n",
        "    if hasattr(X_test, 'shape'):\n",
        "        n_features = X_test.shape[1]\n",
        "    elif hasattr(X_test, 'columns'):\n",
        "        n_features = len(X_test.columns)\n",
        "    else:\n",
        "        n_features = len(X_test[0]) if len(X_test) > 0 else 0\n",
        "else:\n",
        "    n_features = 0\n",
        "    print(\"   ‚ö†Ô∏è UWAGA: Nie mo≈ºna okre≈õliƒá liczby cech - ustawiono na 0\")\n",
        "\n",
        "analysis_results = {\n",
        "    'data_info': {\n",
        "        'n_train_before_smote': len(y_train_for_before),\n",
        "        'n_train_after_smote': len(y_train_for_after),\n",
        "        'n_test': len(y_test),\n",
        "        'n_features': n_features,\n",
        "        'n_classes': len(label_encoder.classes_),\n",
        "        'classes': list(label_encoder.classes_)\n",
        "    },\n",
        "    'label_encoder_mapping': {\n",
        "        label: int(code) for label, code in zip(label_encoder.classes_, range(len(label_encoder.classes_)))\n",
        "    },\n",
        "    'class_distribution_before_smote': {\n",
        "        label: int(count) for label, count in train_before_dist.items()\n",
        "    },\n",
        "    'class_distribution_after_smote': {\n",
        "        label: int(count) for label, count in train_after_dist.items()\n",
        "    },\n",
        "    'class_distribution_test': {\n",
        "        label: int(count) for label, count in test_dist.items()\n",
        "    },\n",
        "    'model_metrics': all_metrics,  # Wszystkie modele\n",
        "    'confusion_matrices': all_confusion_matrices,  # Wszystkie modele\n",
        "    'per_class_metrics': all_per_class_metrics,  # Wszystkie modele\n",
        "    'best_model': {\n",
        "        'name': best_model_name,\n",
        "        'accuracy': best_metrics['accuracy'],\n",
        "        'balanced_accuracy': best_metrics['balanced_accuracy'],\n",
        "        'macro_f1': best_metrics['macro_f1']\n",
        "    }\n",
        "}\n",
        "\n",
        "# ============================================================================\n",
        "# 7. ZAPIS PLIK√ìW JSON I PICKLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüíæ Zapis plik√≥w...\")\n",
        "\n",
        "# Utworzenie folderu results\n",
        "results_dir = Path(\"results\")\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Zapis JSON\n",
        "results_json_path = results_dir / \"analysis_results.json\"\n",
        "with open(results_json_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(analysis_results, f, indent=4, ensure_ascii=False)\n",
        "print(f\"   ‚úÖ Zapisano: {results_json_path}\")\n",
        "\n",
        "# Zapis label encoder\n",
        "label_encoder_path = results_dir / \"label_encoder.pkl\"\n",
        "with open(label_encoder_path, 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "print(f\"   ‚úÖ Zapisano: {label_encoder_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. GENEROWANIE KODU STREAMLIT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüìù Generowanie kodu Streamlit...\")\n",
        "\n",
        "streamlit_code = '''import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Automatyczne wykrywanie lokalizacji plik√≥w\n",
        "def get_results_dir():\n",
        "    \"\"\"Automatycznie wykrywa lokalizacjƒô folderu results\"\"\"\n",
        "    possible_paths = [\n",
        "        Path.cwd() / \"results\",\n",
        "        Path(__file__).parent / \"results\" if '__file__' in globals() else None,\n",
        "        Path(__file__).parent.parent / \"results\" if '__file__' in globals() else None,\n",
        "    ]\n",
        "    possible_paths = [p for p in possible_paths if p is not None]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if path.exists() and (path / \"analysis_results.json\").exists():\n",
        "            return path\n",
        "    \n",
        "    return Path.cwd() / \"results\"\n",
        "\n",
        "# Wczytaj wyniki analizy\n",
        "@st.cache_data\n",
        "def load_analysis_results():\n",
        "    results_dir = get_results_dir()\n",
        "    results_file = results_dir / \"analysis_results.json\"\n",
        "    if not results_file.exists():\n",
        "        st.error(f\"‚ùå Nie znaleziono pliku: {results_file}\")\n",
        "        st.info(f\"üí° Sprawd≈∫ czy plik istnieje w: {results_dir}\")\n",
        "        st.stop()\n",
        "    with open(results_file, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_label_encoder():\n",
        "    results_dir = get_results_dir()\n",
        "    encoder_file = results_dir / \"label_encoder.pkl\"\n",
        "    if not encoder_file.exists():\n",
        "        st.error(f\"‚ùå Nie znaleziono pliku: {encoder_file}\")\n",
        "        st.info(f\"üí° Sprawd≈∫ czy plik istnieje w: {results_dir}\")\n",
        "        st.stop()\n",
        "    with open(encoder_file, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# Wczytaj dane\n",
        "try:\n",
        "    results = load_analysis_results()\n",
        "    label_encoder = load_label_encoder()\n",
        "    results_dir = get_results_dir()\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå B≈ÇƒÖd podczas wczytywania danych: {e}\")\n",
        "    st.info(f\"üí° Sprawd≈∫ czy pliki znajdujƒÖ siƒô w: {get_results_dir()}\")\n",
        "    st.info(\"üí° Upewnij siƒô, ≈ºe uruchomi≈Çe≈õ kom√≥rkƒô generujƒÖcƒÖ pliki w notebooku!\")\n",
        "    st.stop()\n",
        "\n",
        "# Konfiguracja strony\n",
        "st.set_page_config(page_title=\"WESAD Analysis Results\", layout=\"wide\")\n",
        "st.title(\"üìä Wyniki Analizy Klasyfikacji Emocji - WESAD Dataset\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Sidebar z informacjami\n",
        "with st.sidebar:\n",
        "    st.header(\"üìã Informacje o Analizie\")\n",
        "    st.metric(\"Liczba pr√≥bek train\", results['data_info']['n_train_after_smote'])\n",
        "    st.metric(\"Liczba pr√≥bek test\", results['data_info']['n_test'])\n",
        "    st.metric(\"Liczba cech\", results['data_info']['n_features'])\n",
        "    st.metric(\"Liczba klas\", results['data_info']['n_classes'])\n",
        "    \n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Klasy\")\n",
        "    for label, code in results['label_encoder_mapping'].items():\n",
        "        st.write(f\"**{label}**: {code}\")\n",
        "\n",
        "# Sekcja 1: Rozk≈Çad klas\n",
        "st.header(\"üìä Rozk≈Çad Klas\")\n",
        "col1, col2, col3 = st.columns(3)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"Train (przed SMOTE)\")\n",
        "    df_before = pd.DataFrame(list(results['class_distribution_before_smote'].items()), \n",
        "                            columns=['Klasa', 'Liczba pr√≥bek'])\n",
        "    st.bar_chart(df_before.set_index('Klasa'))\n",
        "    st.dataframe(df_before, use_container_width=True)\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Train (po SMOTE)\")\n",
        "    df_after = pd.DataFrame(list(results['class_distribution_after_smote'].items()), \n",
        "                           columns=['Klasa', 'Liczba pr√≥bek'])\n",
        "    st.bar_chart(df_after.set_index('Klasa'))\n",
        "    st.dataframe(df_after, use_container_width=True)\n",
        "\n",
        "with col3:\n",
        "    st.subheader(\"Test\")\n",
        "    df_test = pd.DataFrame(list(results['class_distribution_test'].items()), \n",
        "                          columns=['Klasa', 'Liczba pr√≥bek'])\n",
        "    st.bar_chart(df_test.set_index('Klasa'))\n",
        "    st.dataframe(df_test, use_container_width=True)\n",
        "\n",
        "# Sekcja 2: Por√≥wnanie modeli\n",
        "st.header(\"üèÜ Por√≥wnanie Modeli\")\n",
        "\n",
        "metrics_df = pd.DataFrame(results['model_metrics']).T\n",
        "metrics_df = metrics_df.round(4)\n",
        "st.subheader(\"Metryki Globalne\")\n",
        "st.dataframe(metrics_df, use_container_width=True)\n",
        "\n",
        "# Wykres por√≥wnawczy\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "metrics_df.plot(kind='bar', ax=ax, rot=45)\n",
        "ax.set_ylabel('Warto≈õƒá metryki')\n",
        "ax.set_title('Por√≥wnanie modeli: Accuracy, Balanced Accuracy, Macro F1')\n",
        "ax.legend(title='Metryka', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.set_ylim(0, 1)\n",
        "plt.tight_layout()\n",
        "st.pyplot(fig)\n",
        "\n",
        "# Sekcja 3: Najlepszy model\n",
        "if results['best_model']:\n",
        "    st.header(\"ü•á Najlepszy Model\")\n",
        "    best = results['best_model']\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    col1.metric(\"Model\", best['name'])\n",
        "    col2.metric(\"Balanced Accuracy\", f\"{best['balanced_accuracy']:.4f}\")\n",
        "    col3.metric(\"Macro F1\", f\"{best['macro_f1']:.4f}\")\n",
        "\n",
        "# Sekcja 4: Confusion Matrices\n",
        "st.header(\"üìà Confusion Matrices\")\n",
        "model_names = list(results['confusion_matrices'].keys())\n",
        "selected_model = st.selectbox(\"Wybierz model:\", model_names)\n",
        "\n",
        "if selected_model:\n",
        "    cm = np.array(results['confusion_matrices'][selected_model])\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
        "                xticklabels=results['data_info']['classes'],\n",
        "                yticklabels=results['data_info']['classes'],\n",
        "                ax=ax, cbar_kws={'label': 'Procent'})\n",
        "    ax.set_title(f'Confusion Matrix - {selected_model}', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    \n",
        "    cm_df = pd.DataFrame(cm, \n",
        "                         index=results['data_info']['classes'],\n",
        "                         columns=results['data_info']['classes'])\n",
        "    st.dataframe(cm_df, use_container_width=True)\n",
        "\n",
        "# Sekcja 5: Per-class metrics\n",
        "st.header(\"üìä Metryki Per-Class\")\n",
        "selected_model_metrics = st.selectbox(\"Wybierz model (dla metryk per-class):\", model_names, key='metrics')\n",
        "\n",
        "if selected_model_metrics and selected_model_metrics in results['per_class_metrics']:\n",
        "    per_class = results['per_class_metrics'][selected_model_metrics]\n",
        "    per_class_df = pd.DataFrame(per_class).T\n",
        "    st.dataframe(per_class_df, use_container_width=True)\n",
        "    \n",
        "    # Wykres Precision i Recall\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    per_class_df[['precision', 'recall']].plot(kind='bar', ax=axes[0], rot=0)\n",
        "    axes[0].set_title('Precision i Recall per Class')\n",
        "    axes[0].set_ylabel('Warto≈õƒá')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3, axis='y')\n",
        "    axes[0].set_ylim(0, 1)\n",
        "    \n",
        "    per_class_df['f1_score'].plot(kind='bar', ax=axes[1], rot=0, color='green')\n",
        "    axes[1].set_title('F1-Score per Class')\n",
        "    axes[1].set_ylabel('F1-Score')\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    axes[1].set_ylim(0, 1)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Sekcja 6: Podsumowanie\n",
        "st.header(\"üìù Podsumowanie\")\n",
        "if results.get('best_model'):\n",
        "    best_name = results['best_model']['name']\n",
        "    best_bal_acc = results['best_model']['balanced_accuracy']\n",
        "    best_macro_f1 = results['best_model']['macro_f1']\n",
        "    best_acc = results['best_model']['accuracy']\n",
        "    summary_text = f\"\"\"### Analiza Klasyfikacji Emocji - WESAD Dataset\n",
        "\n",
        "**Najlepszy model:** {best_name}\n",
        "\n",
        "**Wyniki:**\n",
        "- **Balanced Accuracy:** {best_bal_acc:.4f}\n",
        "- **Macro F1:** {best_macro_f1:.4f}\n",
        "- **Accuracy:** {best_acc:.4f}\n",
        "\n",
        "**Metody:**\n",
        "- Subject-wise split (80% train, 20% test)\n",
        "- SMOTE dla balansowania klas\n",
        "- Agregacja: amusement + stress ‚Üí emotion\n",
        "- Segmentacja: sliding window (5s okna, 50% overlap)\n",
        "\"\"\"\n",
        "else:\n",
        "    summary_text = \"\"\"### Analiza Klasyfikacji Emocji - WESAD Dataset\n",
        "\n",
        "**Najlepszy model:** N/A\n",
        "\n",
        "**Wyniki:**\n",
        "- **Balanced Accuracy:** N/A\n",
        "- **Macro F1:** N/A\n",
        "- **Accuracy:** N/A\n",
        "\n",
        "**Metody:**\n",
        "- Subject-wise split (80% train, 20% test)\n",
        "- SMOTE dla balansowania klas\n",
        "- Agregacja: amusement + stress ‚Üí emotion\n",
        "- Segmentacja: sliding window (5s okna, 50% overlap)\n",
        "\"\"\"\n",
        "st.markdown(summary_text)\n",
        "'''\n",
        "\n",
        "# Zapis kodu Streamlit\n",
        "streamlit_file_path = results_dir / \"streamlit_app.py\"\n",
        "with open(streamlit_file_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(streamlit_code)\n",
        "print(f\"   ‚úÖ Zapisano: {streamlit_file_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 9. PODSUMOWANIE I INSTRUKCJE\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"‚úÖ WSZYSTKIE PLIKI WYGENEROWANE POMY≈öLNIE!\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nüìÅ Lokalizacja plik√≥w: {results_dir.absolute()}\")\n",
        "print(f\"   ‚úÖ analysis_results.json\")\n",
        "print(f\"   ‚úÖ label_encoder.pkl\")\n",
        "print(f\"   ‚úÖ streamlit_app.py\")\n",
        "\n",
        "print(f\"\\nüìä Podsumowanie wynik√≥w:\")\n",
        "print(f\"   - Liczba pr√≥bek train (po SMOTE): {analysis_results['data_info']['n_train_after_smote']}\")\n",
        "print(f\"   - Liczba pr√≥bek test: {analysis_results['data_info']['n_test']}\")\n",
        "print(f\"   - Liczba cech: {analysis_results['data_info']['n_features']}\")\n",
        "print(f\"   - Liczba klas: {analysis_results['data_info']['n_classes']}\")\n",
        "print(f\"   - Klasy: {', '.join(analysis_results['data_info']['classes'])}\")\n",
        "print(f\"\\nüèÜ Najlepszy model: {best_model_name}\")\n",
        "print(f\"   - Balanced Accuracy: {best_metrics['balanced_accuracy']:.4f}\")\n",
        "print(f\"   - Macro F1: {best_metrics['macro_f1']:.4f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"üìã INSTRUKCJA URUCHOMIENIA STREAMLIT\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\"\"\n",
        "1. Otw√≥rz terminal w folderze projektu:\n",
        "   cd \"{Path.cwd()}\"\n",
        "\n",
        "2. Uruchom aplikacjƒô Streamlit:\n",
        "   streamlit run {streamlit_file_path}\n",
        "\n",
        "3. Aplikacja otworzy siƒô automatycznie w przeglƒÖdarce\n",
        "   (zwykle pod adresem: http://localhost:8501)\n",
        "\n",
        "4. Je≈õli pliki sƒÖ w innym miejscu, mo≈ºesz uruchomiƒá z folderu results:\n",
        "   cd results\n",
        "   streamlit run streamlit_app.py\n",
        "\n",
        "üí° UWAGA: Upewnij siƒô, ≈ºe masz zainstalowany streamlit:\n",
        "   pip install streamlit\n",
        "\"\"\")\n",
        "\n",
        "print(f\"\\n‚úÖ Gotowe! Mo≈ºesz teraz uruchomiƒá aplikacjƒô Streamlit.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## INTERAKTYWNA APLIKACJA DO PREDYKCJI - STREAMLIT\n",
        "\n",
        "Ta kom√≥rka generuje interaktywnƒÖ aplikacjƒô Streamlit, kt√≥ra pozwala:\n",
        "- Wprowadziƒá warto≈õci cech (lub wczytaƒá dane z pliku)\n",
        "- Automatycznie obliczyƒá predykcjƒô (emotion vs baseline)\n",
        "- Zobaczyƒá prawdopodobie≈Ñstwa dla ka≈ºdej klasy\n",
        "- Wizualizowaƒá wyniki\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "GENEROWANIE INTERAKTYWNEJ APLIKACJI STREAMLIT DO PREDYKCJI\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Znaleziono najlepszy model: LogisticRegression\n",
            "   U≈ºywam TOP 10 najwa≈ºniejszych cech (z feature importance)\n",
            "   Liczba cech: 10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "17569"
            ]
          },
          "execution_count": 416,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Aplikacja zapisana: results/streamlit_prediction_app.py\n",
            "\n",
            "üíæ Zapisujƒô dodatkowe pliki...\n",
            "   ‚úÖ Scaler zapisany: results/scaler.pkl\n",
            "   ‚úÖ Przyk≈Çadowe dane zapisane: results/example_data.csv (2 pr√≥bek)\n",
            "   ‚úÖ Top 10 cech zapisane do analysis_results.json\n",
            "   ‚úÖ Nazwy cech zaktualizowane w analysis_results.json\n",
            "\n",
            "================================================================================\n",
            "‚úÖ APLIKACJA GOTOWA!\n",
            "================================================================================\n",
            "\n",
            "üìã INSTRUKCJA URUCHOMIENIA (TAKIE SAME JAK DLA streamlit_app.py):\n",
            "\n",
            "üîπ METODA 1: Z folderu results (NAJPROSTSZE)\n",
            "   cd \"/Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/notebooks/results\"\n",
            "   streamlit run streamlit_prediction_app.py\n",
            "\n",
            "üîπ METODA 2: Z pe≈Çnej ≈õcie≈ºki (z dowolnego miejsca)\n",
            "   streamlit run \"/Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/notebooks/results/streamlit_prediction_app.py\"\n",
            "\n",
            "üîπ METODA 3: Z folderu notebooks (je≈õli jeste≈õ w folderze notebooks)\n",
            "   streamlit run results/streamlit_prediction_app.py\n",
            "\n",
            "üìå Aplikacja automatycznie znajdzie pliki w folderze results!\n",
            "   U≈ºywa tych samych plik√≥w co streamlit_app.py:\n",
            "   - analysis_results.json\n",
            "   - label_encoder.pkl\n",
            "   - scaler.pkl\n",
            "   - best_model_*.pkl\n",
            "\n",
            "üåê Aplikacja otworzy siƒô w przeglƒÖdarce pod adresem: http://localhost:8501\n",
            "\n",
            "üí° Funkcjonalno≈õci aplikacji:\n",
            "   ‚úÖ Wprowadzenie warto≈õci cech rƒôcznie\n",
            "   ‚úÖ Wczytanie danych z pliku CSV\n",
            "   ‚úÖ Automatyczna predykcja (emotion vs baseline)\n",
            "   ‚úÖ Wizualizacja prawdopodobie≈Ñstw\n",
            "   ‚úÖ Przyk≈Çadowe dane z testowego zbioru\n",
            "\n",
            "üìÅ Lokalizacja pliku:\n",
            "   /Users/turfian/Downloads/archive (4)/WESAD/wesad-prep/notebooks/results/streamlit_prediction_app.py\n",
            "\n",
            "\n",
            "‚úÖ Gotowe! Mo≈ºesz teraz uruchomiƒá aplikacjƒô predykcji.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# GENEROWANIE INTERAKTYWNEJ APLIKACJI STREAMLIT DO PREDYKCJI\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"GENEROWANIE INTERAKTYWNEJ APLIKACJI STREAMLIT DO PREDYKCJI\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Sprawd≈∫ dostƒôpno≈õƒá danych\n",
        "if 'results' not in globals() or 'best_model_name' not in globals():\n",
        "    print(\"   ‚ùå B≈ÅƒÑD: Najpierw uruchom kom√≥rkƒô z generowaniem plik√≥w (kom√≥rka 28)!\")\n",
        "    raise NameError(\"Brak danych - uruchom najpierw kom√≥rkƒô 28\")\n",
        "\n",
        "# Sprawd≈∫ czy mamy najlepszy model\n",
        "if best_model_name not in results:\n",
        "    print(f\"   ‚ùå B≈ÅƒÑD: Model '{best_model_name}' nie jest dostƒôpny w results!\")\n",
        "    raise NameError(f\"Model {best_model_name} nie jest dostƒôpny\")\n",
        "\n",
        "best_model = results[best_model_name]['model']\n",
        "all_feature_names = X_train.columns.tolist() if hasattr(X_train, 'columns') else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
        "\n",
        "# U≈ºyj top 10 cech je≈õli sƒÖ dostƒôpne, w przeciwnym razie u≈ºyj pierwszych 10\n",
        "if 'top_10_features' in globals() and top_10_features is not None:\n",
        "    feature_names = top_10_features\n",
        "    print(f\"\\n‚úÖ Znaleziono najlepszy model: {best_model_name}\")\n",
        "    print(f\"   U≈ºywam TOP 10 najwa≈ºniejszych cech (z feature importance)\")\n",
        "    print(f\"   Liczba cech: {len(feature_names)}\")\n",
        "else:\n",
        "    feature_names = all_feature_names[:10]  # U≈ºyj pierwszych 10 je≈õli top_10_features nie jest dostƒôpne\n",
        "    print(f\"\\n‚úÖ Znaleziono najlepszy model: {best_model_name}\")\n",
        "    print(f\"   ‚ö†Ô∏è Top 10 cech nie jest dostƒôpne - u≈ºywam pierwszych 10 cech\")\n",
        "    print(f\"   Liczba cech: {len(feature_names)}\")\n",
        "\n",
        "# Kod aplikacji Streamlit\n",
        "streamlit_prediction_app = f'''import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Konfiguracja strony\n",
        "st.set_page_config(\n",
        "    page_title=\"WESAD Emotion Prediction\",\n",
        "    page_icon=\"üß†\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Tytu≈Ç aplikacji\n",
        "st.title(\"üß† Interaktywna Predykcja Emocji - WESAD Dataset\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Funkcja do wczytania modelu i scalera\n",
        "@st.cache_resource\n",
        "def load_model_and_scaler():\n",
        "    \"\"\"Wczytuje najlepszy model i scaler z plik√≥w\"\"\"\n",
        "    results_dir = Path(\"results\")\n",
        "    \n",
        "    # Wczytaj analysis_results.json aby znale≈∫ƒá najlepszy model\n",
        "    results_file = results_dir / \"analysis_results.json\"\n",
        "    if not results_file.exists():\n",
        "        st.error(\"‚ùå Nie znaleziono pliku analysis_results.json\")\n",
        "        st.stop()\n",
        "    \n",
        "    with open(results_file, 'r', encoding='utf-8') as f:\n",
        "        analysis_results = json.load(f)\n",
        "    \n",
        "    best_model_name = analysis_results['best_model']['name']\n",
        "    \n",
        "    # Wczytaj model (zapisz go w kom√≥rce 28)\n",
        "    model_file = results_dir / f\"best_model_{{best_model_name.lower()}}.pkl\"\n",
        "    if not model_file.exists():\n",
        "        st.error(f\"‚ùå Nie znaleziono pliku modelu: {{model_file}}\")\n",
        "        st.info(\"üí° Upewnij siƒô, ≈ºe uruchomi≈Çe≈õ kom√≥rkƒô 28, kt√≥ra zapisuje model!\")\n",
        "        st.stop()\n",
        "    \n",
        "    with open(model_file, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    \n",
        "    # Wczytaj scaler (je≈õli zosta≈Ç zapisany)\n",
        "    scaler_file = results_dir / \"scaler.pkl\"\n",
        "    scaler = None\n",
        "    if scaler_file.exists():\n",
        "        with open(scaler_file, 'rb') as f:\n",
        "            scaler = pickle.load(f)\n",
        "    \n",
        "    # Wczytaj label encoder\n",
        "    encoder_file = results_dir / \"label_encoder.pkl\"\n",
        "    if not encoder_file.exists():\n",
        "        st.error(f\"‚ùå Nie znaleziono pliku label_encoder.pkl\")\n",
        "        st.stop()\n",
        "    \n",
        "    with open(encoder_file, 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "    \n",
        "    # Wczytaj wszystkie nazwy cech (model zosta≈Ç wytrenowany na wszystkich)\n",
        "    n_features = analysis_results['data_info']['n_features']\n",
        "    all_feature_names = analysis_results.get('feature_names', [f'feature_{{i}}' for i in range(n_features)])\n",
        "    \n",
        "    # Wczytaj top 10 cech (tylko do wy≈õwietlenia)\n",
        "    top_10_features = analysis_results.get('top_10_features', [])\n",
        "    if top_10_features and len(top_10_features) == 10:\n",
        "        display_features = top_10_features  # Tylko do wy≈õwietlenia\n",
        "    else:\n",
        "        # Je≈õli nie ma top 10, u≈ºyj pierwszych 10 z wszystkich cech\n",
        "        display_features = all_feature_names[:10] if len(all_feature_names) >= 10 else all_feature_names\n",
        "    \n",
        "    return model, scaler, label_encoder, all_feature_names, display_features, best_model_name\n",
        "\n",
        "# Wczytaj model i scaler\n",
        "try:\n",
        "    model, scaler, label_encoder, all_feature_names, display_features, best_model_name = load_model_and_scaler()\n",
        "    st.sidebar.success(f\"‚úÖ Model za≈Çadowany: {{best_model_name}}\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå B≈ÇƒÖd podczas wczytywania modelu: {{e}}\")\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar z informacjami\n",
        "with st.sidebar:\n",
        "    st.header(\"üìã Informacje\")\n",
        "    st.write(f\"**Model:** {{best_model_name}}\")\n",
        "    st.write(f\"**Wy≈õwietlane cechy:** {{len(display_features)}} (top 10 najwa≈ºniejszych)\")\n",
        "    st.write(f\"**Wszystkie cechy:** {{len(all_feature_names)}}\")\n",
        "    st.write(f\"**Klasy:** {{', '.join(label_encoder.classes_)}}\")\n",
        "    st.markdown(\"---\")\n",
        "    st.header(\"‚ÑπÔ∏è Instrukcja\")\n",
        "    st.write(\"\"\"\n",
        "    1. Wybierz spos√≥b wprowadzenia danych:\n",
        "       - **Rƒôczne wprowadzenie**: Wpisz warto≈õci cech rƒôcznie\n",
        "       - **Wczytaj z pliku**: Wczytaj dane z pliku CSV\n",
        "    2. Kliknij **\"Oblicz predykcjƒô\"**\n",
        "    3. Zobacz wynik i prawdopodobie≈Ñstwa\n",
        "    \"\"\")\n",
        "\n",
        "# Automatyczne wczytanie losowej pr√≥bki z example_data.csv\n",
        "@st.cache_data\n",
        "def load_example_data():\n",
        "    \"\"\"Wczytuje przyk≈Çadowe dane z example_data.csv\"\"\"\n",
        "    results_dir = Path(\"results\")\n",
        "    example_file = results_dir / \"example_data.csv\"\n",
        "    if example_file.exists():\n",
        "        try:\n",
        "            df = pd.read_csv(example_file)\n",
        "            # Usu≈Ñ kolumny z etykietami je≈õli istniejƒÖ\n",
        "            df = df.drop(columns=['true_label', 'true_label_encoded'], errors='ignore')\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "# Wczytaj przyk≈Çadowe dane\n",
        "example_data = load_example_data()\n",
        "\n",
        "# G≈Ç√≥wna sekcja aplikacji\n",
        "st.header(\"üìä Wprowad≈∫ dane do predykcji\")\n",
        "\n",
        "# Automatycznie wczytaj losowƒÖ pr√≥bkƒô je≈õli example_data jest dostƒôpne\n",
        "if example_data is not None and len(example_data) > 0:\n",
        "    # Wybierz losowƒÖ pr√≥bkƒô\n",
        "    if 'random_sample' not in st.session_state:\n",
        "        import random\n",
        "        random_idx = random.randint(0, len(example_data) - 1)\n",
        "        st.session_state['random_sample'] = example_data.iloc[[random_idx]].copy()\n",
        "        st.session_state['random_idx'] = random_idx\n",
        "    \n",
        "    # Wy≈õwietl aktualnƒÖ pr√≥bkƒô (tylko top 10 cech)\n",
        "    st.subheader(\"üìã Losowa pr√≥bka z danych testowych (top 10 najwa≈ºniejszych cech)\")\n",
        "    if all(f in st.session_state['random_sample'].columns for f in display_features):\n",
        "        st.dataframe(st.session_state['random_sample'][display_features], use_container_width=True)\n",
        "    else:\n",
        "        st.dataframe(st.session_state['random_sample'], use_container_width=True)\n",
        "    \n",
        "    # Przycisk do losowania nowej pr√≥bki\n",
        "    if st.button(\"üé≤ Losuj nowƒÖ pr√≥bkƒô\", use_container_width=False):\n",
        "        import random\n",
        "        random_idx = random.randint(0, len(example_data) - 1)\n",
        "        st.session_state['random_sample'] = example_data.iloc[[random_idx]].copy()\n",
        "        st.session_state['random_idx'] = random_idx\n",
        "        st.rerun()\n",
        "    \n",
        "    # U≈ºyj losowej pr√≥bki jako danych wej≈õciowych (wszystkie cechy dla modelu)\n",
        "    feature_values = st.session_state['random_sample'].copy() if len(st.session_state['random_sample']) > 0 else None\n",
        "    \n",
        "    # Przycisk PREDYKCJA na dole\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"üîÆ PREDYKCJA\", type=\"primary\", use_container_width=True, key=\"prediction_button\"):\n",
        "        if feature_values is not None:\n",
        "            try:\n",
        "                # Przygotuj dane - u≈ºyj WSZYSTKICH cech (model zosta≈Ç wytrenowany na wszystkich)\n",
        "                # Uzupe≈Çnij brakujƒÖce cechy warto≈õciami 0.0\n",
        "                full_feature_vector = pd.DataFrame(0.0, index=[0], columns=all_feature_names)\n",
        "                for feat in all_feature_names:\n",
        "                    if feat in feature_values.columns:\n",
        "                        full_feature_vector[feat] = feature_values[feat].values[0]\n",
        "                \n",
        "                # Skaluj dane (je≈õli scaler jest dostƒôpny)\n",
        "                if scaler is not None:\n",
        "                    X_scaled = scaler.transform(full_feature_vector)\n",
        "                else:\n",
        "                    X_scaled = full_feature_vector.values\n",
        "                \n",
        "                # Predykcja\n",
        "                predictions = model.predict(X_scaled)\n",
        "                probabilities = model.predict_proba(X_scaled)\n",
        "                \n",
        "                # Wy≈õwietl wyniki\n",
        "                st.header(\"üéØ Wyniki predykcji\")\n",
        "                \n",
        "                pred_label = label_encoder.inverse_transform([predictions[0]])[0]\n",
        "                \n",
        "                # Wy≈õwietl g≈Ç√≥wny wynik\n",
        "                col1, col2, col3 = st.columns([1, 2, 1])\n",
        "                \n",
        "                with col2:\n",
        "                    if pred_label == \"emotion\":\n",
        "                        st.success(f\"## üé≠ Wynik: **{{pred_label.upper()}}**\")\n",
        "                    else:\n",
        "                        st.info(f\"## üòå Wynik: **{{pred_label.upper()}}**\")\n",
        "                \n",
        "                # Prawdopodobie≈Ñstwa\n",
        "                st.subheader(\"üìä Prawdopodobie≈Ñstwa:\")\n",
        "                \n",
        "                prob_dict = {{}}\n",
        "                for i, class_name in enumerate(label_encoder.classes_):\n",
        "                    prob_dict[class_name] = probabilities[0][i]\n",
        "                \n",
        "                # Wykres s≈Çupkowy prawdopodobie≈Ñstw\n",
        "                fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                classes = list(prob_dict.keys())\n",
        "                probs = list(prob_dict.values())\n",
        "                colors = ['#ff6b6b' if c == 'emotion' else '#4ecdc4' for c in classes]\n",
        "                \n",
        "                bars = ax.bar(classes, probs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "                ax.set_ylabel('Prawdopodobie≈Ñstwo', fontsize=12, fontweight='bold')\n",
        "                ax.set_xlabel('Klasa', fontsize=12, fontweight='bold')\n",
        "                ax.set_title('Prawdopodobie≈Ñstwa predykcji', fontsize=14, fontweight='bold')\n",
        "                ax.set_ylim(0, 1)\n",
        "                ax.grid(True, alpha=0.3, axis='y')\n",
        "                \n",
        "                # Dodaj warto≈õci na s≈Çupkach\n",
        "                for bar, prob_val in zip(bars, probs):\n",
        "                    height = bar.get_height()\n",
        "                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                           f'{{prob_val:.2%}}',\n",
        "                           ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                st.pyplot(fig)\n",
        "                \n",
        "                # Tabela z prawdopodobie≈Ñstwami\n",
        "                prob_df = pd.DataFrame([prob_dict])\n",
        "                st.dataframe(prob_df.T.rename(columns={{0: 'Prawdopodobie≈Ñstwo'}}), use_container_width=True)\n",
        "                \n",
        "            except Exception as e:\n",
        "                st.error(f\"‚ùå B≈ÇƒÖd podczas predykcji: {{e}}\")\n",
        "                st.exception(e)\n",
        "else:\n",
        "    # Je≈õli nie ma example_data, poka≈º standardowy interfejs\n",
        "    st.info(\"üí° Wczytaj dane rƒôcznie lub z pliku CSV\")\n",
        "    \n",
        "    input_method = st.radio(\n",
        "        \"Wybierz spos√≥b wprowadzenia danych:\",\n",
        "        [\"Rƒôczne wprowadzenie\", \"Wczytaj z pliku CSV\"],\n",
        "        horizontal=True\n",
        "    )\n",
        "    \n",
        "    input_data = None\n",
        "    feature_values = None\n",
        "    \n",
        "    if input_method == \"Rƒôczne wprowadzenie\":\n",
        "    st.subheader(\"Wprowad≈∫ warto≈õci cech (top 10 najwa≈ºniejszych)\")\n",
        "    \n",
        "    # Podziel cechy na grupy dla lepszej organizacji\n",
        "    n_display_features = len(display_features)\n",
        "    \n",
        "    # Utw√≥rz kolumny dla lepszego uk≈Çadu\n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    feature_dict = {{}}\n",
        "    \n",
        "    with col1:\n",
        "        st.write(\"**Grupa 1:**\")\n",
        "        for i, feature_name in enumerate(display_features[:n_display_features//2]):\n",
        "            feature_dict[feature_name] = st.number_input(\n",
        "                feature_name,\n",
        "                value=0.0,\n",
        "                step=0.01,\n",
        "                key=f\"feature_{{i}}\"\n",
        "            )\n",
        "    \n",
        "    with col2:\n",
        "        st.write(\"**Grupa 2:**\")\n",
        "        for i, feature_name in enumerate(display_features[n_display_features//2:], start=n_display_features//2):\n",
        "            feature_dict[feature_name] = st.number_input(\n",
        "                feature_name,\n",
        "                value=0.0,\n",
        "                step=0.01,\n",
        "                key=f\"feature_{{i}}\"\n",
        "            )\n",
        "    \n",
        "    # Konwertuj na DataFrame (tylko top 10 cech)\n",
        "    feature_values = pd.DataFrame([feature_dict])\n",
        "    \n",
        "else:\n",
        "    st.subheader(\"Wczytaj dane z pliku CSV\")\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Wybierz plik CSV\",\n",
        "        type=['csv'],\n",
        "        help=\"Plik CSV powinien zawieraƒá kolumny z nazwami cech\"\n",
        "    )\n",
        "    \n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            input_data = pd.read_csv(uploaded_file)\n",
        "            st.success(f\"‚úÖ Wczytano plik: {{uploaded_file.name}}\")\n",
        "            st.write(f\"**Liczba wierszy:** {{len(input_data)}}\")\n",
        "            st.write(f\"**Liczba kolumn:** {{len(input_data.columns)}}\")\n",
        "            \n",
        "            # Sprawd≈∫ czy wszystkie wymagane cechy sƒÖ obecne (tylko top 10 do wy≈õwietlenia)\n",
        "            missing_features = set(display_features) - set(input_data.columns)\n",
        "            if missing_features:\n",
        "                st.warning(f\"‚ö†Ô∏è BrakujƒÖce cechy (top 10): {{', '.join(missing_features)}}\")\n",
        "                st.info(\"üí° U≈ºyj warto≈õci domy≈õlnych (0.0) dla brakujƒÖcych cech\")\n",
        "            \n",
        "            # Wybierz wiersz do predykcji\n",
        "            if len(input_data) > 1:\n",
        "                row_index = st.selectbox(\n",
        "                    \"Wybierz wiersz do predykcji:\",\n",
        "                    range(len(input_data)),\n",
        "                    format_func=lambda x: f\"Wiersz {{x+1}}\"\n",
        "                )\n",
        "                feature_values = input_data.iloc[[row_index]]\n",
        "            else:\n",
        "                feature_values = input_data\n",
        "            \n",
        "            # Wy≈õwietl podglƒÖd danych\n",
        "            st.subheader(\"PodglƒÖd danych:\")\n",
        "            st.dataframe(feature_values, use_container_width=True)\n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå B≈ÇƒÖd podczas wczytywania pliku: {{e}}\")\n",
        "            feature_values = None\n",
        "\n",
        "# Przycisk do predykcji\n",
        "if feature_values is not None:\n",
        "    if st.button(\"üîÆ Oblicz predykcjƒô\", type=\"primary\", use_container_width=True):\n",
        "        try:\n",
        "            # Przygotuj dane\n",
        "            # Uzupe≈Çnij brakujƒÖce cechy warto≈õciami domy≈õlnymi (u≈ºywamy WSZYSTKICH cech)\n",
        "            full_feature_vector = pd.DataFrame(0.0, index=[0], columns=all_feature_names)\n",
        "            for feat in all_feature_names:\n",
        "                if feat in feature_values.columns:\n",
        "                    full_feature_vector[feat] = feature_values[feat].values[0]\n",
        "            \n",
        "            # UporzƒÖdkuj kolumny zgodnie z kolejno≈õciƒÖ all_feature_names\n",
        "            feature_values = full_feature_vector\n",
        "            \n",
        "            # Skaluj dane (je≈õli scaler jest dostƒôpny)\n",
        "            if scaler is not None:\n",
        "                X_scaled = scaler.transform(feature_values)\n",
        "            else:\n",
        "                X_scaled = feature_values.values\n",
        "            \n",
        "            # Predykcja\n",
        "            predictions = model.predict(X_scaled)\n",
        "            probabilities = model.predict_proba(X_scaled)\n",
        "            \n",
        "            # Wy≈õwietl wyniki\n",
        "            st.header(\"üéØ Wyniki predykcji\")\n",
        "            \n",
        "            # Wynik dla ka≈ºdego wiersza\n",
        "            for idx, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
        "                pred_label = label_encoder.inverse_transform([pred])[0]\n",
        "                \n",
        "                # Wy≈õwietl g≈Ç√≥wny wynik\n",
        "                col1, col2, col3 = st.columns([1, 2, 1])\n",
        "                \n",
        "                with col2:\n",
        "                    if pred_label == \"emotion\":\n",
        "                        st.success(f\"## üé≠ Wynik: **{{pred_label.upper()}}**\")\n",
        "                    else:\n",
        "                        st.info(f\"## üòå Wynik: **{{pred_label.upper()}}**\")\n",
        "                \n",
        "                # Prawdopodobie≈Ñstwa\n",
        "                st.subheader(\"üìä Prawdopodobie≈Ñstwa:\")\n",
        "                \n",
        "                prob_dict = {{}}\n",
        "                for i, class_name in enumerate(label_encoder.classes_):\n",
        "                    prob_dict[class_name] = prob[i]\n",
        "                \n",
        "                # Wykres s≈Çupkowy prawdopodobie≈Ñstw\n",
        "                fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                classes = list(prob_dict.keys())\n",
        "                probs = list(prob_dict.values())\n",
        "                colors = ['#ff6b6b' if c == 'emotion' else '#4ecdc4' for c in classes]\n",
        "                \n",
        "                bars = ax.bar(classes, probs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "                ax.set_ylabel('Prawdopodobie≈Ñstwo', fontsize=12, fontweight='bold')\n",
        "                ax.set_xlabel('Klasa', fontsize=12, fontweight='bold')\n",
        "                ax.set_title(f'Prawdopodobie≈Ñstwa predykcji - Wiersz {{idx+1}}', fontsize=14, fontweight='bold')\n",
        "                ax.set_ylim(0, 1)\n",
        "                ax.grid(True, alpha=0.3, axis='y')\n",
        "                \n",
        "                # Dodaj warto≈õci na s≈Çupkach\n",
        "                for bar, prob_val in zip(bars, probs):\n",
        "                    height = bar.get_height()\n",
        "                    ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                           f'{{prob_val:.2%}}',\n",
        "                           ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "                \n",
        "                plt.tight_layout()\n",
        "                st.pyplot(fig)\n",
        "                \n",
        "                # Tabela z prawdopodobie≈Ñstwami\n",
        "                prob_df = pd.DataFrame([prob_dict])\n",
        "                st.dataframe(prob_df.T.rename(columns={{0: 'Prawdopodobie≈Ñstwo'}}), use_container_width=True)\n",
        "                \n",
        "                # Szczeg√≥≈Çowe informacje\n",
        "                with st.expander(\"‚ÑπÔ∏è Szczeg√≥≈Çowe informacje\"):\n",
        "                    st.write(f\"**Predykcja:** {{pred_label}}\")\n",
        "                    st.write(f\"**Pewno≈õƒá:** {{max(prob):.2%}}\")\n",
        "                    st.write(f\"**Wszystkie prawdopodobie≈Ñstwa:**\")\n",
        "                    for class_name, prob_val in prob_dict.items():\n",
        "                        st.write(f\"  - {{class_name}}: {{prob_val:.2%}}\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            st.error(f\"‚ùå B≈ÇƒÖd podczas predykcji: {{e}}\")\n",
        "            st.exception(e)\n",
        "\n",
        "# Sekcja z przyk≈Çadowymi danymi\n",
        "with st.expander(\"üí° Przyk≈Çadowe dane\"):\n",
        "    st.write(\"\"\"\n",
        "    Mo≈ºesz u≈ºyƒá przyk≈Çadowych danych z testowego zbioru danych.\n",
        "    Poni≈ºej znajduje siƒô przyk≈Çad jednej pr√≥bki z danych testowych.\n",
        "    \"\"\")\n",
        "    \n",
        "    if 'X_test' in globals() and len(X_test) > 0:\n",
        "        # Wybierz losowƒÖ pr√≥bkƒô z testowego zbioru\n",
        "        sample_idx = 0  # Mo≈ºesz zmieniƒá na losowƒÖ\n",
        "        sample_data = X_test.iloc[[sample_idx]] if hasattr(X_test, 'iloc') else pd.DataFrame([X_test[sample_idx]])\n",
        "        \n",
        "        st.write(\"**Przyk≈Çadowa pr√≥bka z danych testowych:**\")\n",
        "        st.dataframe(sample_data, use_container_width=True)\n",
        "        \n",
        "        # Pobierz prawdziwƒÖ etykietƒô\n",
        "        if 'y_test' in globals():\n",
        "            true_label = label_encoder.inverse_transform([y_test[sample_idx]])[0]\n",
        "            st.write(f\"**Prawdziwa etykieta:** {{true_label}}\")\n",
        "        \n",
        "        # Przycisk do u≈ºycia przyk≈Çadowych danych\n",
        "        if st.button(\"üìã U≈ºyj przyk≈Çadowych danych\"):\n",
        "            feature_values = sample_data\n",
        "            st.rerun()\n",
        "\n",
        "# Stopka\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "<div style='text-align: center; color: gray;'>\n",
        "    <p>WESAD Emotion Prediction App | Powered by Streamlit</p>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "'''\n",
        "\n",
        "# Zapisz aplikacjƒô\n",
        "results_dir = Path(\"results\")\n",
        "results_dir.mkdir(exist_ok=True)\n",
        "\n",
        "app_file_path = results_dir / \"streamlit_prediction_app.py\"\n",
        "with open(app_file_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(streamlit_prediction_app)\n",
        "\n",
        "print(f\"\\n‚úÖ Aplikacja zapisana: {app_file_path}\")\n",
        "\n",
        "# Zapisz r√≥wnie≈º scaler i nazwy cech do plik√≥w\n",
        "print(\"\\nüíæ Zapisujƒô dodatkowe pliki...\")\n",
        "\n",
        "# Zapis scalera\n",
        "scaler_path = results_dir / \"scaler.pkl\"\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(f\"   ‚úÖ Scaler zapisany: {scaler_path}\")\n",
        "\n",
        "# Zapis przyk≈Çadowych danych z testowego zbioru (dla automatycznego wczytania w aplikacji)\n",
        "if 'X_test' in globals() and X_test is not None:\n",
        "    # Wybierz kilka przyk≈Çadowych pr√≥bek (po jednej z ka≈ºdej klasy)\n",
        "    sample_indices = []\n",
        "    if 'y_test' in globals() and y_test is not None:\n",
        "        unique_classes = np.unique(y_test)\n",
        "        for class_label in unique_classes:\n",
        "            class_indices = np.where(y_test == class_label)[0]\n",
        "            if len(class_indices) > 0:\n",
        "                sample_indices.append(class_indices[0])  # Pierwsza pr√≥bka z ka≈ºdej klasy\n",
        "    else:\n",
        "        # Je≈õli nie ma y_test, we≈∫ pierwsze 3 pr√≥bki\n",
        "        sample_indices = list(range(min(3, len(X_test))))\n",
        "    \n",
        "    # Przygotuj przyk≈Çadowe dane\n",
        "    if hasattr(X_test, 'iloc'):\n",
        "        sample_data = X_test.iloc[sample_indices].copy()\n",
        "    else:\n",
        "        sample_data = pd.DataFrame(X_test[sample_indices])\n",
        "    \n",
        "    # Dodaj informacje o prawdziwych etykietach (je≈õli dostƒôpne)\n",
        "    if 'y_test' in globals() and y_test is not None:\n",
        "        sample_data['true_label'] = [label_encoder.inverse_transform([y_test[idx]])[0] for idx in sample_indices]\n",
        "        sample_data['true_label_encoded'] = [y_test[idx] for idx in sample_indices]\n",
        "    \n",
        "    # Zapisz do CSV\n",
        "    sample_data_path = results_dir / \"example_data.csv\"\n",
        "    sample_data.to_csv(sample_data_path, index=False)\n",
        "    print(f\"   ‚úÖ Przyk≈Çadowe dane zapisane: {sample_data_path} ({len(sample_indices)} pr√≥bek)\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è UWAGA: X_test nie jest dostƒôpne - przyk≈Çadowe dane nie zosta≈Çy zapisane\")\n",
        "\n",
        "# Zapis nazw cech i top 10 cech do analysis_results.json\n",
        "results_json_path = results_dir / \"analysis_results.json\"\n",
        "if results_json_path.exists():\n",
        "    with open(results_json_path, 'r', encoding='utf-8') as f:\n",
        "        analysis_results = json.load(f)\n",
        "    \n",
        "    # Zapisz wszystkie nazwy cech\n",
        "    if 'feature_names' not in analysis_results:\n",
        "        analysis_results['feature_names'] = all_feature_names\n",
        "    \n",
        "    # Zapisz top 10 cech (najwa≈ºniejsze)\n",
        "    if 'top_10_features' in globals() and top_10_features is not None:\n",
        "        analysis_results['top_10_features'] = top_10_features\n",
        "        print(f\"   ‚úÖ Top 10 cech zapisane do analysis_results.json\")\n",
        "    \n",
        "    with open(results_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(analysis_results, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"   ‚úÖ Nazwy cech zaktualizowane w analysis_results.json\")\n",
        "\n",
        "# Zapis najlepszego modelu (je≈õli jeszcze nie zosta≈Ç zapisany)\n",
        "best_model_path = results_dir / f\"best_model_{best_model_name.lower()}.pkl\"\n",
        "if not best_model_path.exists():\n",
        "    with open(best_model_path, 'wb') as f:\n",
        "        pickle.dump(best_model, f)\n",
        "    print(f\"   ‚úÖ Najlepszy model zapisany: {best_model_path}\")\n",
        "\n",
        "# Wy≈õwietl instrukcje (takie same jak dla streamlit_app.py)\n",
        "app_full_path = app_file_path.absolute()\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"‚úÖ APLIKACJA GOTOWA!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nüìã INSTRUKCJA URUCHOMIENIA (TAKIE SAME JAK DLA streamlit_app.py):\")\n",
        "print(f\"\"\"\n",
        "üîπ METODA 1: Z folderu results (NAJPROSTSZE)\n",
        "   cd \"{app_file_path.parent.absolute()}\"\n",
        "   streamlit run streamlit_prediction_app.py\n",
        "\n",
        "üîπ METODA 2: Z pe≈Çnej ≈õcie≈ºki (z dowolnego miejsca)\n",
        "   streamlit run \"{app_full_path}\"\n",
        "\n",
        "üîπ METODA 3: Z folderu notebooks (je≈õli jeste≈õ w folderze notebooks)\n",
        "   streamlit run results/streamlit_prediction_app.py\n",
        "\n",
        "üìå Aplikacja automatycznie znajdzie pliki w folderze results!\n",
        "   U≈ºywa tych samych plik√≥w co streamlit_app.py:\n",
        "   - analysis_results.json\n",
        "   - label_encoder.pkl\n",
        "   - scaler.pkl\n",
        "   - best_model_*.pkl\n",
        "\n",
        "üåê Aplikacja otworzy siƒô w przeglƒÖdarce pod adresem: http://localhost:8501\n",
        "\n",
        "üí° Funkcjonalno≈õci aplikacji:\n",
        "   ‚úÖ Wprowadzenie warto≈õci cech rƒôcznie\n",
        "   ‚úÖ Wczytanie danych z pliku CSV\n",
        "   ‚úÖ Automatyczna predykcja (emotion vs baseline)\n",
        "   ‚úÖ Wizualizacja prawdopodobie≈Ñstw\n",
        "   ‚úÖ Przyk≈Çadowe dane z testowego zbioru\n",
        "\n",
        "üìÅ Lokalizacja pliku:\n",
        "   {app_full_path}\n",
        "\"\"\")\n",
        "\n",
        "print(f\"\\n‚úÖ Gotowe! Mo≈ºesz teraz uruchomiƒá aplikacjƒô predykcji.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
